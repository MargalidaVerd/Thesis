---
title: "TFG"
author: "Margalida Verd Julià"
format: html
editor: visual
---

## Installing data and packages

First, we will install and load the necessary packages for this study. Additionally, we will load the required datasets. The analysis is based on three datasets:

-   **Mortality**: Downloaded from the World Health Organization, this is the primary dataset for the analysis. It contains the number of tuberculosis-related deaths in all countries. However, our study will focus solely on European countries.

-   **Population**: From this dataset, we will extract only the population variable. The source of this data is *Our World in Data*.

-   **GDP per capita**: Similar to the population dataset, we will extract only the *gdp_per_capita* variable. The source of this data is *Data Bank*.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# packages loading

library(tidyverse)
library(readr)
library(dplyr)
library(zoo)
library(feasts)
library(eurostat)
library(leaflet)
library(sf)
library(scales)
library(cowplot)
library(ggthemes)
library(giscoR)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(dplyr)
library(gridExtra)
library(grid)
library(tsibble)
library(tseries)
library(FinTS)
library(fable)
library(vctsfr)
library(fpp2)
library(r2r)
library(Metrics)
library(ggpubr)

```

Let's examine the structure of the datasets:

1.  Mortality:

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# data loading

mortality_dataset <- read.csv("mortality.csv", header = TRUE, colClasses = c("character","character","character","character","double","character","character","character","double","double","double","double"), row.names = NULL) 

colnames(mortality_dataset) <- colnames(mortality_dataset)[2:ncol(mortality_dataset)]
mortality_dataset <- mortality_dataset[1:(ncol(mortality_dataset)-1)]

mortality_dataset %>% 
  glimpse()

unique(mortality_dataset$Age.group)
```

2.  Population

```{r, warning=FALSE, message=FALSE, echo= FALSE}
population_dataset <- read.csv("population.csv", header = TRUE)

population_dataset %>% 
  glimpse()
```

3.  gdp_per_capita

```{r, warning=FALSE, message=FALSE, echo= FALSE}
gdp_per_capita_dataset <- read.csv("gdp_per_capita.csv", header = TRUE)

gdp_per_capita_dataset %>% 
  glimpse()
```

## Cleaning data

As seen, we need to standardize the variables names to merge the tables.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# renaming variables

print("Mortality")

mortality_dataset <- mortality_dataset %>%  
  rename(number_deaths = Number, 
         year = Year, percent_cause_specific_death_rate = Percentage.of.cause.specific.deaths.out.of.total.deaths, age_death_rate = Age.standardized.death.rate.per.100.000.standard.population, death_rate = Death.rate.per.100.000.population, country_name = Country.Name, country_code = Country.Code, region_code = Region.Code, region_name = Region.Name) %>% 
  glimpse() 

print("Population")
population_dataset <- population_dataset %>% 
  rename(population = Population...Sex..all...Age..all...Variant..estimates, country_name = Entity, year = Year) %>% 
  glimpse() 

print("gdp_per_capita")
gdp_per_capita_dataset <- gdp_per_capita_dataset %>% 
  select(3,4,5,7) %>% 
  rename(country_name = Country.Name, country_code = Country.Code, year = Time, gdp_capita = Value) %>% 
  glimpse()

```

The next step is to select the study variables from the mortality dataset. We will exclude `Sex`, `Age.group.code` and `Age.group`.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# Select rows of interest in the mortality dataset

mortality_dataset <- mortality_dataset %>% 
  dplyr::filter(Sex == "All") 

# Delete age variables

mortality_dataset <- mortality_dataset %>% 
  select(1:5,9:12) %>% 
  glimpse()
```

Now, we can merge the remaining two datasets.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# joins

full_dataset <- mortality_dataset %>% 
  left_join(population_dataset, by=c("country_name", "year")) %>% 
  left_join(gdp_per_capita_dataset, by = c("country_code", "year")) %>% 
  dplyr::filter(region_code=="EU") %>% 
  select(1:10,12) %>% 
  rename(country_name = country_name.x) 

full_dataset %>% 
  glimpse()

```

## Chosen countries

First, we will define the criteria for dividing European countries into six distinct regions: North, South, West, East, Central, and the Balkans. The Balkans have been designated as a separate region due to their significant cultural differences from neighboring countries. We will add a new variable to the dataset that specifies the subregion to which each country belongs.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset <- full_dataset %>%
  mutate(subregion = case_when(
    country_name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    country_name %in% c("Spain", "Portugal", "Italy", "Malta", "Greece") ~ "S",
    country_name %in% c("Albania", "Bulgaria", "Romania", "Bosnia and Herzegovina", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    country_name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    country_name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~"E",
    country_name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C" ,TRUE ~ NA_character_), .after = region_name)

```

The map below shows the division that would be used from this point forward.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# Load world map with country boundaries
world <- ne_countries(scale = "medium", returnclass = "sf")

# Filter only European countries
europe <- world %>% 
  filter(continent == "Europe")


# Define the classification
europe <- europe %>%
  mutate(Subregion = case_when(
    name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    name %in% c("Spain", "Portugal", "Italy", "Malta", 
                 "Greece") ~ "S",
    name %in% c("Albania", "Bulgaria", "Romania", "Kosovo", "Bosnia and Herz.", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~ "E",
    name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C",
  ))


ggplot(data = europe) +
  geom_sf(aes(fill = Subregion), color = "black") +
  scale_fill_manual(values = c(
    "N" = "#F5BA6A",    
    "S" = "#4044A8",    
    "W" = "#CC4853",    
    "E" = "#5ED171",   
    "C" = "#F5E973",    
    "B" = "#66B0FA"    
  )) + scale_x_continuous(limits = c(-20, 35)) +
  scale_y_continuous(limits = c(35, 70)) +
  theme_minimal() +
  labs(
       fill = "Subregion") +
  theme(legend.position = "right")
```

We are considering Greece as part of the Southern region due to the cultural differences with the Balkan countries. Now, we would choose a country to represent each European subregion. We will select five European countries to analyze their trends in the number of tuberculosis-related deaths. The selection criteria will ensure that the chosen countries represent different regions of Europe (e.g., North, South, etc.) while also having a sufficient number of time observations to construct a reliable time series. Additionally, we aim to include countries that exhibit distinct trends in tuberculosis mortality, making the study more insightful by allowing for a comparative analysis and accurate forecasting of different patterns.

As a first step, we will address any missing values (NA) in the dataset for the variable Number_Deaths in each selected country. We are going to choose countries that at least have 40 years with data.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  dplyr::select(country_name, number_deaths) %>% 
  na.exclude() %>%  
  group_by(country_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  data.frame() %>% 
  filter(n >= 40)

```

```{r}

full_dataset %>%
  filter(subregion == "C") %>% 
  group_by(country_name) %>%
  summarise(
    number_deaths = sum(!is.na(number_deaths)),
    population  = sum(!is.na(population)),
    gdp_capita  = sum(!is.na(gdp_capita))
  ) %>%
  arrange(desc(number_deaths)) %>%
  data.frame() 

```

Lets study each subregion:

-   **Southern Europe**. Due to the geographical origin of the authors, we will choose Spain as the representative country of this region.

-   **Northern Europe**. We observe that Iceland has 72 out of 74 years with recorded values for the selected variable, making it a suitable choice to represent the North region of Europe.

-   **Western Europe**. As Netherlands is the country with a greatest number of values, it would be our choice for this specific region.

-   **Eastern Europe**. It is noticeable that eastern countries are the ones with a less number of recorded values (most of them have only 40 or less); then, it would be a special region to analyse. Lithuania will represent the Northeast region, with 40 recorded values. Even though there are nearby countries with longer recorded periods, the tendency of Lithuania stands out among the rest, which will make for an interesting analysis.

-   **Central Europe**. Switzerland will be the representative country of the central region. It has 71 recorded values, that will fit perfectly when modeling the time series.

-   **Balkans region**. For the Balkans region, we have selected Romania, which has 60 recorded values. It will be an interesting case of analysis due to its tendency, that is a bit different as the other countries.

The selection criteria prioritize minimizing the number of missing values (NA) while ensuring a diverse representation of different regions in Europe. As we have discussed trends, let's display the trend in tuberculosis-related deaths for the selected countries.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  filter(country_name %in% c( "Spain", "Sweden", "Netherlands", "Switzerland", "Estonia", "Bulgaria")) %>%  
  ggplot(aes(x = year, y = number_deaths, color = country_name)) +  
  geom_line() +
  coord_cartesian(ylim = c(0,2700)) +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries trends")+
  theme(legend.position = "right") +
  ylab("Number of deaths")


```

## Data partitioning utilities

To standardize the modeling process across multiple countries, we define helper structures that facilitate consistent data handling. Specifically, we construct a country_splits hashmap to store the full, training, and testing datasets for each selected country.

The first step is to initialize this structure with the full dataset filtered by country and ordered by year:

```{r, warning=FALSE, message=FALSE}
country_splits <- hashmap()
chosen_countries = c("Spain", "Netherlands", "Sweden", "Switzerland", "Bulgaria", "Estonia")

for (name in chosen_countries) {
  country_splits[[name]][["full"]] <- full_dataset %>% filter(country_name == name) %>%  arrange(year)
}


```

Next, we define the specific number of years to allocate to the testing set for each country. These values were chosen based on the total number of available observations, ensuring approximately 15–20% of the series is reserved for out-of-sample evaluation.

```{r, warning=FALSE, message=FALSE}
test_lengths_per_country = hashmap()

test_lengths_per_country[["Spain"]] = 11
test_lengths_per_country[["Switzerland"]] = 11
test_lengths_per_country[["Sweden"]] = 11
test_lengths_per_country[["Estonia"]] = 11
test_lengths_per_country[["Netherlands"]] = 12
test_lengths_per_country[["Bulgaria"]] = 10
```

Finally, we split the dataset for each country into a training and a testing subset based on the predefined test lengths. This setup is essential for subsequent model fitting and forecast evaluation.

```{r, warning=FALSE, message=FALSE}
for (country in chosen_countries) {
  country_dataset = country_splits[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country[[country]]
  country_splits[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  country_splits[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}

```



## ARIMA model utilities

In this section are presented the different methods for the ARIMA forecast. First of all, new functions to plot the ACF and PACF of the time series are defined, in order to get more visible plots (following the schema of python's library matplt.lib). 

```{r, warning=FALSE, message=FALSE}
custom_acf_plot <- function(ts_data, max_lag = 25) {
  acf_vals <- acf(ts_data, plot = FALSE)
  acf_df <- with(acf_vals, data.frame(
    Lag = lag,
    ACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  acf_df$UCL <- conf
  acf_df$LCL <- -conf
  
  ggplot(acf_df, aes(x = Lag, y = ACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(panel.grid = element_blank()) +
    labs(title = "", x = "Lag", y = "Value")
}

```

```{r, warning=FALSE, message=FALSE}
custom_pacf_plot <- function(ts_data, max_lag = 25) {
  pacf_vals <- pacf(ts_data, plot = FALSE)
  pacf_df <- with(pacf_vals, data.frame(
    Lag = lag,
    PACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  pacf_df$UCL <- conf
  pacf_df$LCL <- -conf
  
  ggplot(pacf_df, aes(x = Lag, y = PACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(panel.grid = element_blank()) +
    labs(title = "", x = "Lag", y = "Value")
}

```

Then, a function to automate the selection of ARIMA models is created. This function systematically evaluates various parameter combinations and reports their corresponding Akaike Information Criterion (AIC) values. This approach allows for an informed and reproducible model selection process, particularly useful when the number of possible $(p,d,q)$ combinations is large and exhaustive testing is impractical.

```{r, warning=FALSE, message=FALSE}

try_all_arima <- function(ar_coef, d_coef, ma_coef, time_series) {
  for (p in ar_coef) {
    for(d in d_coef) {
      for (q in ma_coef) {
        arima_fit <- Arima(time_series, order = c(p, d, q))
        cat("ARIMA(", p, ",", d,"," ,q, ")\n", sep = "")
        print(arima_fit$coef)
        cat("AIC:", AIC(arima_fit), "\n\n")
      }
    }
  }
}
```

This function iterates over all specified combinations of autoregressive, differencing, and moving average orders. For each configuration, it fits an ARIMA model and outputs the estimated parameters along with the AIC value, which serves as the model selection criterion.

Next, we define the get_length function to facilitate quick retrieval of the number of non-missing observations in a specified dataset. Accessing time series lengths manually for each country and subset (full, train, or test) can be cumbersome and error-prone. This utility function simplifies the process by requiring only the country name, the desired subset, and the target variable. It returns the number of valid (non-NA) entries.

```{r, warning=FALSE, message=FALSE}
get_length <- function(country, set, variable) {
  return(length(na.omit(country_splits[[country]][[set]][[variable]])))
}

```

Now, we begin with the core functions defined for the rolling forecast methodology. We begin by defining a model constructor called `fitting_function()`; it takes ARIMA orders $(p,d,q)$ as input and returns a function that fits a model with those parameters to any given time series. 

```{r, warning=FALSE, message=FALSE}
fitting_function <- function(order, use_xreg = FALSE) {
  stopifnot(is.numeric(order) && length(order) == 3)
  if (use_xreg) {
    function(y, xreg) {
      Arima(y, order = order, xreg = as.matrix(xreg))
    }
  } else {
    function(y) Arima(y, order = order)
  }
}
```

The core of the forecasting mechanism is implemented in the function `rolling_forecast()`.

```{r, warning=FALSE, message=FALSE, echo=FALSE}

rolling_forecast_generic <- function(train_series, test_series, order_manual, order_auto, use_xreg = FALSE, xreg_train =
                                       NULL, xreg_test = NULL, horizons = c(1, 3, 5), conf_level = 95) {
  max_steps    <- max(horizons)
  horizons_labels <- paste0("h", horizons)
  test_len     <- length(test_series)

  predictions_matrix <- function() {
    matrix(NA_real_, nrow = test_len, ncol = length(horizons), dimnames = list(NULL, horizons_labels))
    }

  outputs_manual <- list(mean = predictions_matrix(), lower = predictions_matrix(), upper = predictions_matrix())
  outputs_auto   <- list(mean = predictions_matrix(), lower = predictions_matrix(), upper = predictions_matrix())

  fit_manual <- fitting_function(order_manual, use_xreg)
  fit_auto   <- fitting_function(order_auto,   use_xreg)

  rolling_series <- train_series
  if (use_xreg) rolling_xreg <- xreg_train

  for (i in seq_len(test_len)) {
    if (use_xreg) {
      fitted_manual_arima <- fit_manual(rolling_series, rolling_xreg)
      fitted_auto_arima <- fit_auto  (rolling_series, rolling_xreg)

      xreg_forecasting_window <- xreg_test[i:min(i + max_steps - 1, nrow(xreg_test)), , drop = FALSE]

      forecasted_manual <- forecast(fitted_manual_arima, h = nrow(xreg_forecasting_window), xreg = xreg_forecasting_window, level = conf_level)
      forecasted_auto <- forecast(fitted_auto_arima, h = nrow(xreg_forecasting_window), xreg = xreg_forecasting_window, level = conf_level)
    } else {
      fitted_manual_arima <- fit_manual(rolling_series)
      fitted_auto_arima <- fit_auto(rolling_series)

      forecasted_manual <- forecast(fitted_manual_arima, h = max_steps, level = conf_level)
      forecasted_auto <- forecast(fitted_auto_arima, h = max_steps, level = conf_level)
    }
    
    get_level_column <- function(fc_component) {
      if (is.null(dim(fc_component))) return(rep(NA_real_, max_steps))
      level_names <- colnames(fc_component)
      
      lvl_idx <- which(level_names == as.character(conf_level))
      if (length(lvl_idx) == 0) lvl_idx <- 1
      fc_component[, lvl_idx]
    }

    mean_manual  <- forecasted_manual$mean
    lower_manual <- get_level_column(forecasted_manual$lower)
    upper_manual <- get_level_column(forecasted_manual$upper)

    mean_auto  <- forecasted_auto$mean
    lower_auto <- get_level_column(forecasted_auto$lower)
    upper_auto <- get_level_column(forecasted_auto$upper)

    for (h in horizons) {
      idx <- i + h - 1
      if (idx <= test_len) {
        col <- paste0("h", h)
        outputs_manual$mean [idx, col] <- mean_manual[h]
        outputs_manual$lower[idx, col] <- lower_manual[h]
        outputs_manual$upper[idx, col] <- upper_manual[h]

        outputs_auto$mean [idx, col] <- mean_auto[h]
        outputs_auto$lower[idx, col] <- lower_auto[h]
        outputs_auto$upper[idx, col] <- upper_auto[h]
      }
    }

    rolling_series <- c(rolling_series, test_series[i])
    if (use_xreg) rolling_xreg <- rbind(rolling_xreg, xreg_test[i, , drop = FALSE])
  }

  list(manual = outputs_manual, auto = outputs_auto)
}
```

This function simulates a real-time prediction scenario by iteratively refitting the model to an expanding training set. At each iteration, it fits the model to the currently available data and generates forecasts up to a specified horizon (e.g., 1, 3, and 5 years ahead). These predictions are stored in a matrix with dimensions corresponding to the length of the test set and the number of horizons. Importantly, the function only retains the forecasted values that correspond to actual future observations in the test set, ensuring a fair comparison. The following table shows the main idea of the function:
  
```{r, warning=FALSE, message=FALSE, echo=FALSE}
example_tbl <- data.frame(
  Iteration = 1:3,
  Data_used_to_fit = c("1951–2010",
                       "1951–2011",
                       "1951–2012"),
  Forecast_block = c("2011–2015",
                     "2012–2016",
                     "2013–2017"),
  Data_stored = c("h1 → 2011, h3 → 2013, h5 → 2015",
                  "h1 → 2012, h3 → 2014, h5 → 2016",
                  "h1 → 2013, h3 → 2015, h5 → 2017"),
  stringsAsFactors = FALSE
)

print(example_tbl, row.names = FALSE)
```


To visualize the model behavior at different forecast horizons, the function `make_horizon_plots()` creates a series of time series plots. It takes as input the training and testing series, along with two fitting functions (one for the manually specified model and another using `auto.arima()`), and returns separate plots for each forecast horizon (1, 3, and 5 years). In each plot, the actual data are shown in the original scale, alongside the predictions from both models.

```{r, warning=FALSE, message=FALSE}
plot_horizons <- function(test_log_series, forecast_list, horizons = c(1, 3, 5)) {
  
  horizons_labels <- paste0("h", horizons)
  year_vector <- time(test_log_series)
  test_raw <- exp(as.numeric(test_log_series))

  build_long_df <- function(forecasting_matrix, model_label) {
    as.data.frame(forecasting_matrix) %>%
      mutate(year = year_vector) %>%
      pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
      mutate(Value = exp(as.numeric(Value)), Model = model_label)
  }

  df_manual <- build_long_df(forecast_list$manual$mean, "manualARIMA")
  df_auto   <- build_long_df(forecast_list$auto$mean,   "autoARIMA")
  df_obs    <- data.frame(year = year_vector, Horizon = "Observed", Model = "Observed", Value = test_raw)

  plot_df <- bind_rows(df_obs, df_manual, df_auto) %>%
    mutate(Horizon = factor(Horizon, levels = c(horizons_labels, "Observed")))

  col_map <- c(Observed = "#1f77b4", autoARIMA = "#6ba292", manualARIMA = "#ff7f0e")
  lty_map <- c(Observed = "solid",   autoARIMA = "dashed", manualARIMA = "dashed")

  make_single_plot <- function(h_label) {
    ggplot(filter(plot_df, Horizon == h_label | Model == "Observed"),
           aes(x = year, y = Value, colour = Model, linetype = Model)) +
      geom_line(na.rm = TRUE) +
      scale_colour_manual(values = c(Observed = "#1f77b4", autoARIMA = "#6ba292", manualARIMA = "#ff7f0e")) +
      scale_linetype_manual(values = c(Observed = "solid",   autoARIMA = "dashed", manualARIMA = "dashed")) +
      labs(title = "",
           x = "Year", y = "Number of deaths",
           colour = "Series", linetype = "Series") +
      theme_minimal(base_size = 13)
  }

  plots <- lapply(horizons_labels, make_single_plot)
  names(plots) <- horizons_labels
  plots
}
#paste("Forecast horizon:", h_label)

```

In addition to visual inspection, we provide quantitative tools to assess forecast accuracy. The function `compute_accuracy_table()` computes key performance metrics such as Mean Error (ME), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Percentage Error (MPE) and Mean Absolute Percentage Error (MAPE).

```{r, warning=FALSE, message=FALSE}
compute_accuracy_table <- function(test_log, forecast_list, horizons = c(1, 3, 5)) {
  
  horizons_labels <- paste0("h", horizons)
  rows <- list()
  
  test_orig <- exp(test_log)
  
  for (model_name in names(forecast_list)) {
    predicted_log <- forecast_list[[model_name]]$mean
    predicted_orig <- exp(predicted_log)  # ← nombre correcto
    
    for (h_lab in horizons_labels) {
      keep <- !is.na(predicted_orig[, h_lab])
      rows[[paste(model_name, h_lab, sep = "_")]] <- data.frame(
        Model = paste0(ifelse(model_name == "auto", "autoARIMA", "manualARIMA"), "-", h_lab),
        ME    = mean(test_orig[keep] - predicted_orig[keep, h_lab]),
        RMSE  = rmse(test_orig[keep], predicted_orig[keep, h_lab]),
        MAE   = mae (test_orig[keep], predicted_orig[keep, h_lab]),
        MAPE  = mape(test_orig[keep], predicted_orig[keep, h_lab]) * 100,
        row.names = NULL
      )
    }
  }
  
  dplyr::bind_rows(rows)
}
```

Finally, function `run_country_forecast()` helps getting the computed information of a specific country. 

```{r, warning=FALSE, message=FALSE}
run_country_forecast <- function(country, start_year, order_manual,
                                 order_auto, horizons = c(1, 3, 5), use_xreg = FALSE) {
  
  if (use_xreg) {
    
    train_raw <- countries_short[[country]]$train$number_deaths
    test_raw  <- countries_short[[country]]$test$number_deaths

    train_ts <- ts(log(train_raw), start = start_year, frequency = 1)
    test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)

    xreg_train <- as.matrix(data.frame(
      population = ts(log(countries_short[[country]]$train$population), start = start_year, frequency = 1),
      gdp_capita = ts(log(countries_short[[country]]$train$gdp_capita), start = start_year, frequency = 1)
    ))

    xreg_test <- as.matrix(data.frame(
      population = ts(log(countries_short[[country]]$test$population), start = end(train_ts)[1] + 1, frequency = 1),
      gdp_capita = ts(log(countries_short[[country]]$test$gdp_capita), start = end(train_ts)[1] + 1, frequency = 1)
    ))

    fc_list <- rolling_forecast_generic(train_ts, test_ts, order_manual, order_auto,
                                        use_xreg = TRUE, xreg_train = xreg_train, xreg_test = xreg_test,
                                        horizons = horizons)
  } else {
    
    train_raw <- country_splits[[country]]$train$number_deaths
    test_raw  <- country_splits[[country]]$test$number_deaths

    train_ts <- ts(log(train_raw), start = start_year, frequency = 1)
    test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)

    fc_list <- rolling_forecast_generic(train_ts, test_ts, order_manual, order_auto,
                                        use_xreg = FALSE, horizons = horizons)
  }

  accuracy_tbl <- compute_accuracy_table(test_ts, fc_list, horizons = horizons)

  plots <- plot_horizons(test_ts, fc_list, horizons = horizons)

  list(metrics = accuracy_tbl, plots = plots, forecasts = fc_list)
}

```

This function is required in order to get the boundaries of the confidence intervals:

```{r}
calc_exp_bounds <- function(res, model, horizon) {
  model   <- as.character(model)
  horizon <- as.integer(horizon)

  lower_vals <- res$forecasts[[model]][["lower"]][ , horizon]
  lower_vals <- exp(lower_vals[!is.na(lower_vals)])

  upper_vals <- res$forecasts[[model]][["upper"]][ , horizon]
  upper_vals <- exp(upper_vals[!is.na(upper_vals)])

  c(min = min(lower_vals), max = max(upper_vals))
}
```


## ARIMA models

In this section, we analyze the temporal dynamics of tuberculosis-related mortality across the selected European countries using ARIMA models. Each country will be studied individually, beginning with an exploratory analysis of the log-transformed mortality data. Model parameters (p,d,q) will be selected based on empirical diagnostics such as the ACF/PACF plots and the AIC. The adequacy of each model will be verified through residual analysis.

### Spain

We begin our analysis with the Spanish dataset, which spans from 1951 to 2021 and comprises 71 annual observations. Given the long time span and the observed declining trend in raw counts, a logarithmic transformation is applied to stabilize variance and linearize the trend. The figure below shows the log-transformed training time series for tuberculosis mortality in Spain.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain <- ts(log(country_splits[["Spain"]]$train$number_deaths), start = 1951,  frequency = 1)
test_spain <- ts(log(country_splits[["Spain"]]$test$number_deaths), start = 2011,  frequency = 1)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Spain"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Spain"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

In order to formally assess whether the series is stationary, we apply the Augmented Dickey-Fuller (ADF) test:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain)
```

As expected, the high $p$-value indicates that we fail to reject the null hypothesis, which suggests that the series is non-stationary. In this case, applying a first-order difference is recommended.

We can apply the ADF test to the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain %>% diff())
```

The test $p$-value ensures the stationarity of the time series. Now, we check the ACF and PACF of the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_spain %>% diff())
custom_pacf_plot(train_spain %>% diff())

```

Neither the ACF nor the PACF show any ignificant spikes—autocorrelations at higher lags lie well within the confidence bounds. This suggest that the series present no AR or MA structure left after the differences. We first fit the auto.arima model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_spain_auto <- auto.arima(train_spain, test = "adf")

summary(fit_spain_auto)

```
The auto.arima() procedure suggests an ARIMA(0,1,0) specification, indicating that the series follows a random walk without drift. The corresponding AIC is relatively low ($-104.73$), supporting the adequacy of this simple model. Moreover, the in-sample performance is satisfactory, with a root mean squared error (RMSE) of $0.096$ and a mean absolute percentage error (MAPE) below 1% on the log-transformed training set.

Nonetheless, in pursuit of a potentially more flexible and interpretable model, we consider a broader set of ARIMA specifications that include either an AR(1) or MA(1) component. This aims to assess whether a slightly more complex model can better capture the underlying dynamics, or whether the series can indeed be sufficiently described as a random walk process. 

We apply the try_all_arima using $p,q \in \{0,1\}$:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ma_coef = c(0,1)
ar_coef = c(0,1)

try_all_arima(ar_coef, 1, ma_coef, train_spain)
```
The model with the lowest AIC (specifically, with a value of $-100.25$) is the ARIMA($1,1,1$). We proceed with the residuals diagnostics of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_111 <- Arima(train_spain, order = c(1,1,1))
summary(fit_spain_111)
```

First, the auto.arima: 
```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_spain_auto))
```
Just by checking the residuals distribution function on the `checkresiduals` plot, it is clear that the residuals of the autogenerated model do not pass the Shapiro-Wilk normality test. 

Then, the residuals of the manual model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_111 %>% 
  forecast::checkresiduals()

shapiro.test(residuals(fit_spain_111))
```

The residuals of the manual model do not pass neither the normality assumption. However, we proceed with the forecasting step.

First, we validate the accuracy of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arima_spain <- run_country_forecast("Spain", start_year = 1951, order_manual = c(1,1,1),
                          order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = FALSE)

results_arima_spain$metrics   

```

The manual ARIMA model consistently outperforms the automatic specification across all horizons. In particular, it achieves substantially lower RMSE and MAE values, especially for medium- and long-term forecasts. For example, at horizon $h=5$, the manual model yields an RMSE of 36.88 and a MAPE of 11.65%, whereas the automatic model reaches 78.31 and 31.49%, respectively. Moreover, the manual model maintains smaller forecast biases (ME) across horizons, suggesting a more balanced and accurate predictive behavior.

Now, we can plot the forecasting results:
```{r, warning=FALSE, message=FALSE, echo = FALSE}

res$plots
```

Notably, both models tend to slightly overestimate the first forecasted value. Across all three horizons, the manual ARIMA provides more accurate approximations than the automatically selected model. This is particularly evident in the five-step-ahead forecasts, where the autoARIMA overpredicts by up to 50 tuberculosis-related deaths.

```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}

calc_exp_bounds(res, "auto", 1)
calc_exp_bounds(res, "manual", 1)

calc_exp_bounds(res, "auto", 2)
calc_exp_bounds(res, "manual",  2)

calc_exp_bounds(res, "auto",  3)
calc_exp_bounds(res, "manual",  3)
```

### The Netherlands

We study the Netherlands.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_netherlands <- ts(log(country_splits[["Netherlands"]]$train$number_deaths), start = 1950,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Netherlands"]]$full$number_deaths), start = 1950,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Netherlands"]]$full$number_deaths, start = 1950, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_netherlands)
```

The training series is not stationary.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_netherlands %>% diff())
custom_pacf_plot(train_netherlands %>% diff())
```

After apply a first order difference, the series ACF plot shows a significant spike at lag 4, and the PACF plot shows significant spikes at lags 4 and 7. We will begin studying the simplest model and the autogenerate model of auto.arima().

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto <- auto.arima(train_netherlands )
summary(fit_netherlands_auto)
```
The auto generated model is the ARIMA(0,1,0).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_auto))
```

The residuals for the autogenerate model do not satisfy the hypothesis.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ar_coef = c(2,3,4)
ma_coef = c(2,3)
try_all_arima(ar_coef , 1, ma_coef, train_netherlands)

fit_netherlands_213 <- Arima(train_netherlands, order = c(2,1,3))
fit_netherlands_213
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_213 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_213))
```

The residuals of the 2,1,3 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Netherlands", 2,1,3, 1950)
get_error_metrics("Netherlands", 2,1,3, 1950)
```

### Switzerland

We study Switzerland.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_switzerland <- ts(log(country_splits[["Switzerland"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Switzerland"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Switzerland"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ACF and PACF of the log-transformed series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_switzerland)
custom_pacf_plot(train_switzerland)
```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_switzerland)
kpss.test(train_switzerland %>% diff())
```

Notably, the series passes the ADF test without differencing, suggesting stationarity. However, the visual inspection reveals a clear downward trend, which contradicts this result and raises concerns about potential non-stationarity. To clarify this discrepancy, we applied the KPSS test, which assumes stationarity as the null hypothesis. The KPSS result ($p$-value of $0.01$) leads us to reject stationarity, thereby supporting the use of first-order differencing before model fitting. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto <- auto.arima(train_switzerland )
summary(fit_switzerland_auto)
```
The auto generated model is the ARIMA(0,1,1).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_auto))
```

The residuals for the autogenerate model do not satisfy the normality hypothesis.

```{r}
custom_acf_plot(train_switzerland %>% diff())
custom_pacf_plot(train_switzerland %>% diff())
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

p <- c(0,1)
q <- c(0,1)

try_all_arima(p,1,q,train_switzerland)
fit_switzerland_111 <- Arima(train_switzerland, order = c(1,1,1))
fit_switzerland_111
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_111 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_111))
```

The residuals of the 1,0,0 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Switzerland", 1,1,1, 1951)
get_error_metrics("Switzerland", 1,1,1, 1951)
```
At every horizon the Auto specification outclasses the Manual one, and the gap widens as you look further ahead.

h1 (one-step). Auto posts lower errors across the board—RMSE 6.30 vs 7.22, MAE 5.25 vs 6.04, MAPE 37 % vs 45 %. Its mean error flips sign to a small positive (+0.39) while Manual shows a larger negative bias (–1.25), so Auto is both more accurate and less biased.

h3 (three-step). The advantage grows markedly. Auto trims RMSE by almost two points (7.20 vs 9.12) and cuts MAE from 8.15 to 5.91. Most striking is the percentage error: MAPE plunges from 62.6 % to 42.1 %. Bias virtually disappears in Auto (ME ≈ +0.07) but remains strongly negative in Manual (–4.58), confirming that the Manual model keeps under-predicting while Auto stays close to the mark.

h5 (five-step). Auto’s lead becomes decisive. RMSE falls to 5.02 (vs 6.99) and MAE to 3.64 (vs 6.00); MAPE is slashed to 18.4 %, less than half the Manual model’s 41.2 %. Manual still carries a large negative bias (–4.75), whereas Auto shows a moderate positive one (+2.20). Even allowing for that tilt, Auto’s absolute bias is smaller than Manual’s and its overall errors are dramatically lower.

Bottom line: The Manual model systematically under-predicts and accumulates large relative errors, especially beyond the first step, while the Auto ARIMA remains much closer to zero bias and delivers substantially tighter error metrics at all horizons—most dramatically at three and five steps. For both near-term and longer-range forecasting, Auto is the clearly preferable choice.
### Sweden

We study Sweden

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_sweden<- ts(log(country_splits[["Sweden"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Sweden"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Sweden"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ACF and PACF of the log-transformed series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(train_sweden)
pacf(train_sweden)
```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_sweden %>% diff())
```

The training series is not stationary. 

We need to difference the series.
```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_sweden %>% diff())
custom_pacf_plot(train_sweden %>% diff())

```

The series ACF plot a significant first lag, and the PACF plot shows significant spikes at lag 1 and 8.  We will study an ARIMA(1,1,1)

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto <- auto.arima(train_sweden )
summary(fit_sweden_auto)
```
The auto generated model is the ARIMA(0,1,1).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_auto))
```

The residuals for the autogenerate model satisfy the hypothesis.

```{r}
p <- c(0,1,8)
q <- c(0,1,8)
  
try_all_arima(p,1,q, train_sweden)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_sweden_810 <- Arima(train_sweden, order = c(8,1,0))
fit_sweden_810
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_810 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_810))
```

The residuals of the 1,0,0 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Sweden", 8,1,0, 1951)
get_error_metrics("Sweden", 8,1,0, 1951)
```
### Bulgaria

Now, we study Bulgaria data. As seen in the introduction, Bulgaria has a different trend for number_deaths series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_bulgaria <- ts(log(country_splits[["Bulgaria"]]$train$number_deaths), start = 1964, end = 2011,  frequency = 1)
test_bulgaria <- ts(log(country_splits[["Bulgaria"]][["test"]][["number_deaths"]]), start = 2012, frequency = 1)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Bulgaria"]]$full$number_deaths), start = 1964,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Bulgaria"]]$full$number_deaths, start = 1964, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

We first use the ADF test to assess whether the series is stationary or not.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria )
```
Without any difference, the series is not stationary. After two differences, we get stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria %>% diff(differences = 2))
```

Let's see which ARIMA order proposes the auto.arima() function.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto <- auto.arima(train_bulgaria, test = "adf")

summary(fit_bulgaria_auto)
```

The model proposed is an ARIMA(0,1,0) with drift, that has an AIC of $-78.32$. In order to determine an alternative model, we check the ACF and PACF plots of the time series.

First, we check the ACF and PACF of the first-order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_bulgaria %>% diff())
custom_pacf_plot(train_bulgaria %>% diff())
```
After one difference, the series does not present any structure left, justifying the selection criteria of the auto.arima function. Now, we check the two-order differences ACF and PACF:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_bulgaria %>% diff(differences = 2))
custom_pacf_plot(train_bulgaria %>% diff(differences = 2))
```
The ACF now shows a single first significant lag, whether the PACF shows an increasing pattern over the first few lags. Now, we apply the try_all_arima to find the best model:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1,2)
d <- c(1,2)
q <- c(0,1)

try_all_arima(p,d,q, train_bulgaria)
```
The model with the lowest AIC (of $-74.27$) is ARIMA($1,1,1$). Now, we check the residuals diagnostic of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_111 <- Arima(train_bulgaria, order = c(1,1,1))
summary(fit_bulgaria_111)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_111 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_111))
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_auto))
```

The residuals of both models satisfy the assumptions on residuals. We begin the forecast step by checking the accuracy metrics of both models.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arima_bulgaria <- run_country_forecast("Bulgaria", start_year = 1964, order_manual = c(1,1,1),
                          order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = FALSE)

results_arima_spain$metrics   

```




### Estonia

Now, we study Estonia data.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
country_splits[["Estonia"]]$train

train_estonia <- ts(log(country_splits[["Estonia"]]$train$number_deaths), start = 1981, end = 2011,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Estonia"]]$full$number_deaths), start = 1981,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Estonia"]]$full$number_deaths, start = 1981, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

In order to stabilize the variance of the series, we will work with the logarithmic data.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia)
```

The $p$-value of the ADF test is higher than $0,05$, so the series is non-stationary. We check both ACF and PACF plots.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(train_estonia)
pacf(train_estonia)

```

The ACF shows an exponential decay, while the PACF shows a single significant spike at lag 1. This suggest an AR($1$) process. However, the series is not stationary (as seen in the plot, and justified by the ADF test, with a $p$-value of $0.543$).

Let's see which ARIMA order proposes the auto.arima() function.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_auto <- auto.arima(train_estonia)

summary(fit_estonia_auto)
```

The model proposed is an ARIMA(1,0,0) with non-zero mean. We need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_estonia_auto))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_estonia,           
  test_estonia,            
  fit_auto,    
  max_steps= 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_estonia, pred_log, horizon = 1)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 3)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 5)



```


Let's check the error measures of the test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_estonia <- ts(log(country_splits[["Estonia"]][["test"]][["number_deaths"]]), start = 2012, frequency = 1)

preds_log <- rolling_predictions_single(train_estonia, test_estonia, fit_auto)

error_summary <- rolling_error_metrics_single(
  test_series = exp(test_estonia),
  predictions  = exp(preds_log)
)
error_summary
```
Let's propose a different model. Based on the ADF test, the log-transformed series is not stationary. We begin by checking the ACF and PACF plots of the differenced time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia %>% diff(differences = 2))

custom_acf_plot(train_estonia %>% diff())
custom_pacf_plot(train_estonia %>% diff())

custom_acf_plot(train_estonia %>% diff(differences = 2))
custom_pacf_plot(train_estonia %>% diff(differences = 2))

```

```{r}
ar_coef = c(1)
d = c(1,2)
ma_coef = c(0,1)

try_all_arima(ar_coef,d,ma_coef, train_estonia)
```

Once differenced, the time series does not present any temporal structure left. We study the ARIMA(1,1,0).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_110 <- Arima(train_estonia, order = c(1,1,0))

summary(fit_estonia_110)
```

Let's check the residuals of the model

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_110 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_estonia_110))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_estonia,           
  test_estonia,            
  fitting_function(1,1,0),    
  max_steps = 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_estonia, pred_log, horizon = 1)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 3)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 5)


```

```{r}
preds_log <- rolling_predictions_single(train_estonia, test_estonia, fitting_function(1,1,0))

error_summary <- rolling_error_metrics_single(
  test_series = exp(test_estonia),
  predictions  = exp(preds_log)
)

error_summary
```

Comparison:

```{r}
make_country_plots("Estonia", 1,1,0, 1981)
get_error_metrics("Estonia", 1,1,0, 1981)
```


## ARIMAX models

We have seen that ARIMA models are quite simple in order to do a well-suited forecast for our studied series. In this section we will study ARIMAX models; ARIMAX models are ARIMA models that include some exogenous variables in order to get better forecastings rather than basic ARIMA. In our study, we will consider two exogenous variables: Gross Domestic Product per capita and the country population.

First, we visualize these series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables <- full_dataset %>% 
  filter(country_name %in% c("Spain", "Switzerland", "Sweden", "Netherlands", "Estonia", "Bulgaria")) %>% 
  select(year, country_name, population,  gdp_capita) %>% 
  arrange(year)

```

We begin analysing the Population variable.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables %>%  
  ggplot(aes(x = year, y = population/1000000, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries population trends")+
  theme(legend.position = "right") +
  ylab("Population (in millions)")

```

In stark contrast with the other countries, Spain population has a strong increasing trend, climbing from around 28 million in 1950 to nearly 48 million by 2020. The Netherlands also grows steadily, from about 10 million to roughly 18 million. Sweden’s population increases more modestly, moving from approximately 7 million to just over 10 million, while Switzerland rises from about 5 million to nearly 9 million over the same period.

In contrast, Bulgaria peaks near 9 million in the 1980s before gradually declining to about 7 million by 2020, and Estonia remains the smallest, hovering around 1.7 million in 1980 but falling slightly to around 1.3 million by 2020. The plot clearly highlights Spain’s large and sustained growth, moderate increases for Northern and Western European countries, and population declines in Eastern Europe.

Now, let's visualize the GDP per capita tendencies:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
exogenous_variables %>%  
  ggplot(aes(x = year, y = gdp_capita, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries GDP per capita trends")+
  theme(legend.position = "right") +
  ylab("GDP per capita (in current U.S. dollars)")
```

Now, the outlook is quite different; Switzerland leads the list, climbing from around \$2,000 in 1960 to over \$90,000 by 2020, with sharp surges in the late 1990s and post-2005. Following Switzerland, the Netherlands and Sweden follow a similar upward trajectory. Spain increases more modestly, from under \$1,000 to a peak of around \$35,000 by 2008, then levels out in the \$25,000–\$30,000 range.Estonia lags until independence—remaining near zero through the Soviet era—then surges after 1992 from around \$2,000 to approximately \$25,000 by 2020. Bulgaria also starts below \$1,000, grows gradually through the 1980s, dips in the 1990s, and then climbs to roughly \$12,000 by 2020.

Overall, Switzerland, Sweden, and the Netherlands display long-term, high-income growth; Spain shows moderate growth with a plateau post-2008; and the Eastern European countries (Estonia and Bulgaria) demonstrate rapid catch-up following post-1990 transitions.

Before beginning the ARIMAX section, it is important to give special attention to the length of each of the variables, just to ensure that the studied variable (number_deaths) length coincides with the covariables length.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_all_lengths <- function(countries) {
  data.frame(
    Country = countries,
    number_deaths_length = sapply(countries, function(cn) get_length(cn, "full", "number_deaths")),
    population_length = sapply(countries, function(cn) get_length(cn, "full", "population")),
    gdp_capita_length = sapply(countries, function(cn) get_length(cn, "full", "gdp_capita")),
    row.names = NULL
  )
}

lengths_df <- get_all_lengths(chosen_countries)

lengths_df

```

It is necessary that all variable have the same length; we create a function in order to automate this step.

```{r}

slice_country_data <- function(country, start_year) {
  df_full <- country_splits[[country]][["full"]]
  df_filtered <- df_full %>%
    filter(year >= start_year) %>%
    arrange(year)  

  return(df_filtered)
}

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short <- hashmap()

countries_short[["Spain"]][["full"]] <- slice_country_data("Spain", 1960)
countries_short[["Netherlands"]][["full"]] <- slice_country_data("Netherlands", 1960)
countries_short[["Sweden"]][["full"]] <- slice_country_data("Sweden", 1960)
countries_short[["Switzerland"]][["full"]] <- slice_country_data("Switzerland", 1960)
countries_short[["Estonia"]][["full"]] <- slice_country_data("Estonia", 1993)
countries_short[["Bulgaria"]][["full"]] <- slice_country_data("Bulgaria", 1980)


```

Now, we need to divide these new series into a training and a testing set. We will do the split, ensuring that the 80% of the data is used for training.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
test_lengths_per_country_short = hashmap()

test_lengths_per_country_short[["Spain"]] = 12
test_lengths_per_country_short[["Switzerland"]] = 12
test_lengths_per_country_short[["Sweden"]] = 12
test_lengths_per_country_short[["Estonia"]] = 6
test_lengths_per_country_short[["Netherlands"]] = 12
test_lengths_per_country_short[["Bulgaria"]] = 8
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
for (country in chosen_countries) {
  country_dataset = countries_short[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country_short[[country]]
  countries_short[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  countries_short[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}


```

Now that we have prepared the dataset, we can begin the ARIMAX study.

### Spain

We begin studying Spain data. First, let's plot all three variables (number_deaths, population and gdp_capita) in the same plot.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_spain_arimax_plot <- data.frame(
  Year = countries_short[["Spain"]][["full"]]$year,
  number_deaths = countries_short[["Spain"]][["full"]]$number_deaths,
  population = countries_short[["Spain"]][["full"]]$population,
  gdp_capita = countries_short[["Spain"]][["full"]]$gdp_capita
)

train_spain_short <- ts(log(countries_short[["Spain"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

test_spain_short <- ts(log(countries_short[["Spain"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_spain_train <- data.frame(
  population = ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)

xreg_spain_test <- data.frame(
  population = ts(log(countries_short[["Spain"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

df <- df_spain_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df$log_deaths, df$log_gdp), na.rm = TRUE)

df <- df %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))   # población “dibujable”

ggplot(df, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2010, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```
We need to further analyze the main characteristics of the three series. We begin assessing the stationary condition using the ADF test:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population)
adf.test(xreg_spain_train$gdp_capita)

```

Neither the population nor the GDP per capita series are stationary. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population %>% diff())
adf.test(xreg_spain_train$gdp_capita %>% diff())

```

After a first order difference, series still not stationary. In fact, is not but after three differences that the series get stationary. However, and due to the consequences of high order differences explained in the memory, we are going to analyze both 1 or 2 differences only.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population %>% diff(differences = 3))
adf.test(xreg_spain_train$gdp_capita %>% diff())

```

We plot the ACF and PACF of both approaches, of each series.

1. Population series, first order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$population %>% diff())
custom_pacf_plot(xreg_spain_train$population %>% diff())

```

Results: The PACF reveals two significant lags at the beginning of the series, with additional spikes at lags 7 and 11. The ACF exhibits a slow decay, suggesting that the series may remain non-stationary after a single differencing.

2. Population series, two order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$population %>% diff(differences =2))
custom_pacf_plot(xreg_spain_train$population %>% diff(differences = 2))

```
Results: The ACF displays prominent spikes at lags 1, 6, and 7. The PACF similarly shows significant spikes at lags 1 and 6, while other lags fall within the confidence bounds. These patterns are more consistent with stationarity.

3. GDP per capita series, first order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_spain_train$gdp_capita %>% diff())

```
Results: The PACF exhibits significant spikes at lags 1 and 15. The ACF also shows notable autocorrelations at both the first and last lags, suggesting possible seasonality or long-range dependence.

4. GDP per capita series, two order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_spain_train$gdp_capita %>% diff(differences = 2))

```
Results: The PACF includes a significant negative spike at lag 3, while the rest remain within the confidence bounds. The ACF shows no significant autocorrelations, indicating that the second-order differencing may have adequately removed autocorrelated structure from the series.

We first study which model recomends the auto.arima function

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_auto_arimax_spain <- auto.arima(train_spain_short, xreg= as.matrix(xreg_spain_train ), test = "adf")

summary(fit_auto_arimax_spain)
```
The function suggested an ARIMAX(1,1,0), that presents an AIC of $-120$. Now, to choose the manual ARIMA, we could try the try_all_arima function and study which model presents better AIC value.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1)
d <- c(1,2)
q <- c(0,1)

try_all_arima(p,d,q, train_spain_short)
```
The model selected is an ARIMA($1,2,1$), with an AIC of $-117.66$. We check the residuals of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_manual_arimax_spain <- Arima(train_spain_short, order = c(1,2,1), xreg= as.matrix(xreg_spain_train ) )
summary(fit_manual_arimax_spain)
fit_auto_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_auto_arimax_spain))
```

The autogenerated model satisfies the assumption on the residuals. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_manual_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_manual_arimax_spain))
```
The manual model, too. Now, we check the accuracy measures:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax <- run_country_forecast("Spain", start_year = 1960, order_manual = c(1,2,1),
                            order_auto = c(1,1,0), horizons = c(1,3,5), use_xreg = TRUE)
results_arimax$metrics
```

The manually adjusted model consistently outperforms the automatic one across all error metrics and forecast horizons. In particular, the mean error of the automatic model is notably more negative across all horizons, reflecting a severe overestimation bias. For example, at horizon $h=5$, the automatic model overpredicts by more than 70 deaths on average, while the manual model maintains a considerably smaller bias of approximately $-7.66$.

Regarding scale-dependent metrics, such as RMSE and MAE, the manual model achieves significantly lower values—especially at $h=3$ and $h=5$—indicating more accurate point forecasts. Similarly, MAPE values show that the relative forecast error of the manual model remains below $11%$ at all horizons, compared to nearly $30%$ for the automatic model at $h=5$.

These results confirm the superiority of the manual ARIMA specification in both accuracy and stability, particularly in medium- and long-term forecasts. Moreover, the progressive deterioration of the automatic model’s accuracy with increasing horizon highlights its limited predictive capacity for multi-step forecasts.

The results can be visualized next:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

res$plots
```

```{r}
calc_exp_bounds(res, "auto", 1)
calc_exp_bounds(res, "manual", 1)

calc_exp_bounds(res, "auto", 2)
calc_exp_bounds(res, "manual",  2)

calc_exp_bounds(res, "auto",  3)
calc_exp_bounds(res, "manual",  3)
```




### The Netherlands

Let's continue with the Netherlands.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_netherlands_arimax_plot <- data.frame(
  Year = countries_short[["Netherlands"]][["full"]]$year,
  number_deaths = countries_short[["Netherlands"]][["full"]]$number_deaths,
  population = countries_short[["Netherlands"]][["full"]]$population,
  gdp_capita = countries_short[["Netherlands"]][["full"]]$gdp_capita
)

ggplot(df_netherlands_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#04225CFF") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "#862633FF", "gdp_capita" = "#088158FF")) +
  labs(title = "",
       x = "Year",
       y = "Log-scaled indicators",
       color = "Series") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_netherlands_short <- ts(log(countries_short[["Netherlands"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_netherlands_train <- as.matrix(data.frame(
  population = ts(log(countries_short[["Netherlands"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
))


fit_arimax_netherlands <- auto.arima(train_netherlands_short, xreg= as.matrix(xreg_netherlands_train ))

summary(fit_arimax_netherlands)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_netherlands %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_netherlands))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_netherlands_short <- ts(log(countries_short[["Netherlands"]][["test"]][["number_deaths"]]), start = 2011, frequency = 1)

xreg_netherlands_test <- as.matrix(data.frame(
  population = ts(log(countries_short[["Netherlands"]][["test"]][["population"]]), start = 2011, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["test"]][["gdp_capita"]]), start = 2011, frequency = 1)
))


pred_arimax <- rolling_arimax_predictions_single(train_netherlands_short, test_netherlands_short,
                                                 xreg_netherlands_train, xreg_netherlands_test,
                                                 fit_auto_arimax)


plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =5 )

```
We can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_netherlands_short), predictions = exp(pred_arimax))
error_summary

```
COMENTAR

Now, let's try to adjust another ARIMAX model, just to try to improve the error measures. The auto.arima() function does not apply any difference to the series; let's check the stationarity of the three series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_netherlands_short)

adf.test(train_netherlands_short %>% diff())
```

Yet the series is not stationary, when we apply a first order difference it passes the ADF test of stationarity. We an plot the ACf and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_netherlands_short %>% diff())
custom_pacf_plot(train_netherlands_short %>% diff())
```

Both the ACF and PACF show a significant spike at lag 2.

Now, we difference the other series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(ts(log(countries_short[["Netherlands"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Netherlands"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())

custom_acf_plot(ts(log(countries_short[["Netherlands"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Netherlands"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())

```

Fitted model: ARIMA(2,1,2)
```{r}
fit_arimax_netherlands_212 <- Arima(train_netherlands_short, order = c(2,1,2), xreg = xreg_netherlands_train)
summary(fit_arimax_netherlands_212)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_netherlands_212 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_netherlands_212))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
pred_arimax <- rolling_arimax_predictions_single(train_netherlands_short, test_netherlands_short,
                                                 xreg_netherlands_train, xreg_netherlands_test,
                                                 fitting_function_arimax(2,1,2))


plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_netherlands_short, pred_arimax, h =5 )
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_netherlands_short), predictions = exp(pred_arimax))
error_summary

```

**Final conclusions**

Let's do a summary of the Netherlands models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_error_metrics_arimax("Netherlands", 2,1,2, 1960, xreg_netherlands_train, xreg_netherlands_test)

```

Finally, we plot both approaches for the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
make_country_plots_arimax("Netherlands", 2,1 ,2, 1960)
```

### Bulgaria

Now, we study the Bulgarian time series. We begin, as in Spain, by studying the regressor variables.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_bulgaria_arimax_plot <- data.frame(
  Year = countries_short[["Bulgaria"]][["full"]]$year,
  number_deaths = countries_short[["Bulgaria"]][["full"]]$number_deaths,
  population = countries_short[["Bulgaria"]][["full"]]$population,
  gdp_capita = countries_short[["Bulgaria"]][["full"]]$gdp_capita
)

ggplot(df_bulgaria_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2014, linetype = "dashed", color = "#04225CFF") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "#862633FF", "gdp_capita" = "#088158FF")) +
  labs(title = "",
       x = "Year",
       y = "Log-scaled indicators",
       color = "Series") +
  theme_minimal()
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["train"]][["number_deaths"]]), start = 1980, frequency = 1)

xreg_bulgaria_train <- as.matrix(data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["train"]][["population"]]), start = 1980, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["train"]][["gdp_capita"]]), start = 1980, frequency = 1)
))


fit_arimax_bulgaria <- auto.arima(train_bulgaria_short, xreg= as.matrix(xreg_bulgaria_train ))

summary(fit_arimax_bulgaria)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Bulgaria"]][["test"]]
test_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["test"]][["number_deaths"]]), start = 2014, frequency = 1)

xreg_bulgaria_test <- as.matrix(data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["test"]][["population"]]), start = 2014, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["test"]][["gdp_capita"]]), start = 2014, frequency = 1)
))

pred_arimax <- rolling_arimax_predictions_single(train_bulgaria_short, test_bulgaria_short,
                                                 xreg_bulgaria_train, xreg_bulgaria_test,
                                                 fit_auto_arimax)


plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =5 )

```


Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_bulgaria_short), predictions = exp(pred_arimax))
error_summary

```

COMENTAR
As we see in the plot, the auto.arima function has not fully capture the structure of the series. Let's try to adjust manually another ARIMAX model. First, we need to check if the time series are stationary in the lof-transformed scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria_short)
```

The main series is not stationary. We difference this series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_bulgaria_short_diff <- train_bulgaria_short %>% diff()

custom_acf_plot(train_bulgaria_short_diff)
custom_pacf_plot(train_bulgaria_short_diff)
```

The ACF and PACF plots do not show any significant spikes after differencing once the series.

Next, we difference the log(population) time series over the same short training period:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
population_bulgaria_diff <- ts(log(countries_short[["Bulgaria"]][["train"]][["population"]]), start = 1980, frequency = 1) %>% diff()

custom_acf_plot(population_bulgaria_diff)
custom_pacf_plot(population_bulgaria_diff)
```

The ACF plot shows a slow exponential decay over the first few lags. In contrast, the PACF shows two large spikes at lags 1 and 2, and then subsequent lags are essentially within the confidence bounds. This pattern is characteristic of an AR($2$) process or a non-stationary time series.

Finally, we difference the log(gdp_capita) series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
gdp_capita_bulgaria_diff <- ts(log(countries_short[["Bulgaria"]][["train"]][["gdp_capita"]]), start = 1980, frequency = 1) %>% diff()

custom_acf_plot(gdp_capita_bulgaria_diff)
custom_pacf_plot(gdp_capita_bulgaria_diff)
```

It is noticeable that both ACF and PACF show a single spike at lag 4. This pattern may suggest a high MA component for this series.

Putting all together, we propose the ARIMA($1,1,1$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_bulgaria_111 <- Arima(train_bulgaria_short, order = c(1,1,1), xreg = as.matrix(xreg_bulgaria_train))
fit_arimax_bulgaria_111
```

The value of the AIC ($-50.02$) indicates a well-suited fit. Now, we need to check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria_111 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria_111))
```

The model's residuals pass both normality and Ljung-Box tests. Now, we do the forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
pred_arimax <- rolling_arimax_predictions_single(train_bulgaria_short, test_bulgaria_short,
                                                 xreg_bulgaria_train, xreg_bulgaria_test,
                                                 fitting_function_arimax(1,1,1))


plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_bulgaria_short, pred_arimax, h =5 )

```


Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_bulgaria_short), predictions = exp(pred_arimax))
error_summary

```

**Final conclusions**

Let's do a summary of the Bulgarian models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_error_metrics_arimax("Bulgaria", 1,1,1, 1980, xreg_bulgaria_train, xreg_bulgaria_test)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
make_country_plots_arimax("Bulgaria", 1,1,1, 1980)

```

### Estonia

Let's begin the study for Estonia data. Remember that Estonia is the country that has shorter time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_estonia_arimax_plot <- data.frame(
  Year = countries_short[["Estonia"]][["full"]]$year,
  number_deaths = countries_short[["Estonia"]][["full"]]$number_deaths,
  population = countries_short[["Estonia"]][["full"]]$population,
  gdp_capita = countries_short[["Estonia"]][["full"]]$gdp_capita
)

ggplot(df_estonia_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2017, linetype = "dashed", color = "#04225CFF") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "#862633FF", "gdp_capita" = "#088158FF")) +
  labs(title = "",
       x = "Year",
       y = "Log-scaled indicators",
       color = "Series") +
  theme_minimal()

```

In this case, as the gdp_capita time series increases over time, both number of deaths and population seem to decay, specially the TB deaths series.

Let's fit the auto.arima() first:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_estonia_short <- ts(log(countries_short[["Estonia"]][["train"]][["number_deaths"]]), start = 1993, frequency = 1)

xreg_estonia_train <- as.matrix(data.frame(
  population = ts(log(countries_short[["Estonia"]][["train"]][["population"]]), start = 1993, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["train"]][["gdp_capita"]]), start = 1993, frequency = 1)
))


fit_arimax_estonia <- auto.arima(train_estonia_short, xreg= as.matrix(xreg_estonia_train ))

summary(fit_arimax_estonia)
```

The auto.arima has selected the ARIMA(1,0,0) as the model with the AIC coefficient minimized. Let's check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_estonia %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_estonia))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_estonia_short <- ts(log(countries_short[["Estonia"]][["test"]][["number_deaths"]]), start = 2017, frequency = 1)

xreg_estonia_test <- as.matrix(data.frame(
  population = ts(log(countries_short[["Estonia"]][["test"]][["population"]]), start = 2017, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["test"]][["gdp_capita"]]), start = 2017, frequency = 1)
))

pred_arimax <- rolling_arimax_predictions_single(train_estonia_short, test_estonia_short,
                                                 xreg_estonia_train, xreg_estonia_test,
                                                 fit_auto_arimax)


plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =5 )

```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- rolling_error_metrics_single( test_series = exp(test_estonia_short), predictions = exp(pred_arimax))
error_summary
```
Now, we check the main characteristics of the covariates. We begin with the main series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(ts(log(countries_short[["Estonia"]][["train"]][["number_deaths"]]), start = 1993, frequency = 1))

train_estonia_diff <- ts(log(countries_short[["Estonia"]][["train"]][["number_deaths"]]), start = 1993, frequency = 1) %>% diff()


custom_acf_plot(train_estonia_diff)
custom_pacf_plot(train_estonia_diff)
```

The series do not present any significant structure left.
```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(ts(log(countries_short[["Estonia"]][["train"]][["population"]]), start = 1993, frequency = 1))

population_estonia_diff <- ts(log(countries_short[["Estonia"]][["train"]][["population"]]), start = 1993, frequency = 1) %>% diff()


custom_acf_plot(population_estonia_diff)
custom_pacf_plot(population_estonia_diff)
```

The differenced series ACF and PACF suggest an AR($1$) process.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(ts(log(countries_short[["Estonia"]][["train"]][["gdp_capita"]]), start = 1993, frequency = 1))

gdp_capita_estonia_diff <- ts(log(countries_short[["Estonia"]][["train"]][["gdp_capita"]]), start = 1993, frequency = 1) %>% diff()


custom_acf_plot(gdp_capita_estonia_diff)
custom_pacf_plot(gdp_capita_estonia_diff)
```
We will study an ARIMA(1,1,0).


```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_estonia_110 <- Arima(train_estonia_short, order = c(1,1,0),xreg= as.matrix(xreg_estonia_train ))

summary(fit_arimax_estonia_110)
```

Let's check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_estonia_110 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_estonia_110))
```
The residuals are well-behaved. We begin the forecast step.


```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_arimax <- rolling_arimax_predictions_single(train_estonia_short, test_estonia_short,
                                                 xreg_estonia_train, xreg_estonia_test,
                                                 fitting_function_arimax(1,1,0))


plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_estonia_short, pred_arimax, h =5 )

```
We check the error measures.


```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_estonia_short), predictions = exp(pred_arimax))
error_summary
```
**Final conclusions**

```{r, warning=FALSE, message=FALSE, echo = FALSE}
get_error_metrics_arimax("Estonia", 1,1,0, 1993, xreg_estonia_train, xreg_estonia_test)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
make_country_plots_arimax("Estonia", 1,1,0, 1993)
```


### Sweden

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_sweden_arimax_plot <- data.frame(
  Year = countries_short[["Sweden"]][["full"]]$year,
  number_deaths = countries_short[["Sweden"]][["full"]]$number_deaths,
  population = countries_short[["Sweden"]][["full"]]$population,
  gdp_capita = countries_short[["Sweden"]][["full"]]$gdp_capita
)


ggplot(df_sweden_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#04225CFF") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "#862633FF", "gdp_capita" = "#088158FF")) +
  labs(title = "",
       x = "Year",
       y = "Log-scaled indicators",
       color = "Series") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_sweden_short <- ts(log(countries_short[["Sweden"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_sweden_train <- as.matrix(data.frame(
  population = ts(log(countries_short[["Sweden"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Sweden"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
))


fit_arimax_sweden <- auto.arima(train_sweden_short, xreg= as.matrix(xreg_sweden_train ))

summary(fit_arimax_sweden)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_sweden))
```

The residuals of the ARIMAX model do not satisfy the normality hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_sweden_short <- ts(log(countries_short[["Sweden"]][["test"]][["number_deaths"]]), start = 2011, frequency = 1)

xreg_sweden_test <- as.matrix(data.frame(
  population = ts(log(countries_short[["Sweden"]][["test"]][["population"]]), start = 2011, frequency = 1),
  gdp_capita = ts(log(countries_short[["Sweden"]][["test"]][["gdp_capita"]]), start = 2011, frequency = 1)
))


pred_arimax <- rolling_arimax_predictions_single(train_sweden_short, test_sweden_short,
                                                 xreg_sweden_train, xreg_sweden_test,
                                                 fit_auto_arimax)


plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =5 )

```
We can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_sweden_short), predictions = exp(pred_arimax))
error_summary

```
COMENTAR

Now, let's try to adjust another ARIMAX model, just to try to improve the error measures. The auto.arima() function does not apply any difference to the series; let's check the stationarity of the three series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_sweden_short)

adf.test(train_sweden_short %>% diff())
```

Yet the series is not stationary, when we apply a first order difference it passes the ADF test of stationarity. We an plot the ACf and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_sweden_short %>% diff())
custom_pacf_plot(train_sweden_short %>% diff())
```

Neither the ACF nor the PACF show any structure left.

Now, we difference the other series. The ADF test for the population series shows that it is stationary without any differences.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(ts(log(countries_short[["Sweden"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Sweden"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())

custom_acf_plot(ts(log(countries_short[["Sweden"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Sweden"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())

```

Fitted model: ARIMA(1,1,0)
```{r}
fit_arimax_sweden_110 <- Arima(train_sweden_short, order = c(1,1,0), xreg = xreg_sweden_train)
summary(fit_arimax_sweden_110)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden_110 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_sweden_110))
```
The residuals of the ARIMAX model do not satisfy the normality hypothesis. Now, we begin the forecast:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
pred_arimax <- rolling_arimax_predictions_single(train_sweden_short, test_sweden_short,
                                                 xreg_sweden_train, xreg_sweden_test,
                                                 fitting_function_arimax(1,1,0))


plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_sweden_short, pred_arimax, h =5 )
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_sweden_short), predictions = exp(pred_arimax))
error_summary

```
**Final conclusions**

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_error_metrics_arimax("Sweden", 1,1,0, 1960, xreg_sweden_train, xreg_sweden_test)

```
```{r, warning=FALSE, message=FALSE, echo = FALSE}

make_country_plots_arimax("Sweden", 1,1,0, 1960)

```

### Switzerland

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_switzerland_arimax_plot <- data.frame(
  Year = countries_short[["Switzerland"]][["full"]]$year,
  number_deaths = countries_short[["Switzerland"]][["full"]]$number_deaths,
  population = countries_short[["Switzerland"]][["full"]]$population,
  gdp_capita = countries_short[["Switzerland"]][["full"]]$gdp_capita
)

ggplot(df_switzerland_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2010, linetype = "dashed", color = "#04225CFF") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "#862633FF", "gdp_capita" = "#088158FF")) +
  labs(title = "",
       x = "Year",
       y = "Log-scaled indicators",
       color = "Series") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_switzerland_short <- ts(log(countries_short[["Switzerland"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_switzerland_train <- as.matrix(data.frame(
  population = ts(log(countries_short[["Switzerland"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Switzerland"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
))


fit_arimax_switzerland<- auto.arima(train_switzerland_short, xreg= as.matrix(xreg_switzerland_train ))

summary(fit_arimax_switzerland)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_switzerland %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_switzerland))
```

The residuals of the ARIMAX model do not satisfy the normality hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_switzerland_short <- ts(log(countries_short[["Switzerland"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

xreg_switzerland_test <- as.matrix(data.frame(
  population = ts(log(countries_short[["Switzerland"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Switzerland"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
))


pred_arimax <- rolling_arimax_predictions_single(train_switzerland_short, test_switzerland_short,
                                                 xreg_switzerland_train, xreg_switzerland_test,
                                                 fit_auto_arimax)


plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =5 )

```
We can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_switzerland_short), predictions = exp(pred_arimax))
error_summary

```
COMENTAR

Now, let's try to adjust another ARIMAX model, just to try to improve the error measures. The auto.arima() function does not apply any difference to the series; let's check the stationarity of the three series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_switzerland_short)
kpss.test(train_switzerland_short)
```

The series is not stationary. We can plot the ACf and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_switzerland_short %>% diff())
custom_pacf_plot(train_switzerland_short %>% diff())
```

Neither the ACF nor the PACF show any structure left.

Now, we difference the other series. The ADF test for the population series shows that it is stationary without any differences.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(ts(log(countries_short[["Switzerland"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Switzerland"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff())

custom_acf_plot(ts(log(countries_short[["Switzerland"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())
custom_pacf_plot(ts(log(countries_short[["Switzerland"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff())

```

Fitted model: ARIMA(2,1,1)
```{r}
fit_arimax_switzerland_211 <- Arima(train_switzerland_short, order = c(2,1,1), xreg = xreg_switzerland_train)
summary(fit_arimax_switzerland_211)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_switzerland_211 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_switzerland_211))
```
The residuals of the ARIMAX model do not satisfy the normality hypothesis. Now, we begin the forecast:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
pred_arimax <- rolling_arimax_predictions_single(train_switzerland_short, test_switzerland_short,
                                                 xreg_switzerland_train, xreg_switzerland_test,
                                                 fitting_function_arimax(2,1,1))


plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =1 )
plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =3 )
plot_rolling_forecast_single(test_switzerland_short, pred_arimax, h =5 )
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- rolling_error_metrics_single( test_series = exp(test_switzerland_short), predictions = exp(pred_arimax))
error_summary

```
**Final conclusions**

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_error_metrics_arimax("Switzerland", 2,1,1, 1960, xreg_switzerland_train, xreg_switzerland_test)

```
```{r, warning=FALSE, message=FALSE, echo = FALSE}

make_country_plots_arimax("Switzerland", 2,1,1, 1960)

```




