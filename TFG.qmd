---
title: "TFG"
author: "Margalida Verd Julià"
format: html
editor: visual
---

## Installing data and packages

First, we will install and load the necessary packages for this study. Additionally, we will load the required datasets. The analysis is based on three datasets:

-   **Mortality**: Downloaded from the World Health Organization, this is the primary dataset for the analysis. It contains the number of tuberculosis-related deaths in all countries. However, our study will focus solely on European countries.

-   **Population**: From this dataset, we will extract only the population variable. The source of this data is *Our World in Data*.

-   **GDP per capita**: Similar to the population dataset, we will extract only the *gdp_per_capita* variable. The source of this data is *Data Bank*.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# packages loading

library(tidyverse)
library(readr)
library(dplyr)
library(zoo)
library(feasts)
library(eurostat)
library(leaflet)
library(sf)
library(scales)
library(cowplot)
library(ggthemes)
library(giscoR)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(dplyr)
library(gridExtra)
library(grid)
library(tsibble)
library(tseries)
library(FinTS)
library(fable)
library(vctsfr)
library(fpp2)
library(r2r)
library(Metrics)

```

Let's examine the structure of the datasets:

1.  Mortality:

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# data loading

mortality_dataset <- read.csv("mortality.csv", header = TRUE, colClasses = c("character","character","character","character","double","character","character","character","double","double","double","double"), row.names = NULL) 

colnames(mortality_dataset) <- colnames(mortality_dataset)[2:ncol(mortality_dataset)]
mortality_dataset <- mortality_dataset[1:(ncol(mortality_dataset)-1)]

mortality_dataset %>% 
  glimpse()

unique(mortality_dataset$Age.group)
```

2.  Population

```{r, warning=FALSE, message=FALSE, echo= FALSE}
population_dataset <- read.csv("population.csv", header = TRUE)

population_dataset %>% 
  glimpse()
```

3.  gdp_per_capita

```{r, warning=FALSE, message=FALSE, echo= FALSE}
gdp_per_capita_dataset <- read.csv("gdp_per_capita.csv", header = TRUE)

gdp_per_capita_dataset %>% 
  glimpse()
```

## Cleaning data

As seen, we need to standardize the variables names to merge the tables.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# renaming variables

print("Mortality")

mortality_dataset <- mortality_dataset %>%  
  rename(number_deaths = Number, 
         year = Year, percent_cause_specific_death_rate = Percentage.of.cause.specific.deaths.out.of.total.deaths, age_death_rate = Age.standardized.death.rate.per.100.000.standard.population, death_rate = Death.rate.per.100.000.population, country_name = Country.Name, country_code = Country.Code, region_code = Region.Code, region_name = Region.Name) %>% 
  glimpse() 

print("Population")
population_dataset <- population_dataset %>% 
  rename(population = Population...Sex..all...Age..all...Variant..estimates, country_name = Entity, year = Year) %>% 
  glimpse() 

print("gdp_per_capita")
gdp_per_capita_dataset <- gdp_per_capita_dataset %>% 
  select(3,4,5,7) %>% 
  rename(country_name = Country.Name, country_code = Country.Code, year = Time, gdp_capita = Value) %>% 
  glimpse()

```

The next step is to select the study variables from the mortality dataset. We will exclude `Sex`, `Age.group.code` and `Age.group`.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# Select rows of interest in the mortality dataset

mortality_dataset <- mortality_dataset %>% 
  dplyr::filter(Sex == "All") 

# Delete age variables

mortality_dataset <- mortality_dataset %>% 
  select(1:5,9:12) %>% 
  glimpse()
```

Now, we can merge the remaining two datasets.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# joins

full_dataset <- mortality_dataset %>% 
  left_join(population_dataset, by=c("country_name", "year")) %>% 
  left_join(gdp_per_capita_dataset, by = c("country_code", "year")) %>% 
  dplyr::filter(region_code=="EU") %>% 
  select(1:10,12) %>% 
  rename(country_name = country_name.x) 

full_dataset %>% 
  glimpse()

```

## Chosen countries

First, we will define the criteria for dividing European countries into six distinct regions: North, South, West, East, Central, and the Balkans. The Balkans have been designated as a separate region due to their significant cultural differences from neighboring countries. We will add a new variable to the dataset that specifies the subregion to which each country belongs.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset <- full_dataset %>%
  mutate(subregion = case_when(
    country_name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    country_name %in% c("Spain", "Portugal", "Italy", "Malta", "Greece") ~ "S",
    country_name %in% c("Albania", "Bulgaria", "Romania", "Bosnia and Herzegovina", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    country_name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    country_name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~"E",
    country_name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C" ,TRUE ~ NA_character_), .after = region_name)

```

The map below shows the division that would be used from this point forward.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# Load world map with country boundaries
world <- ne_countries(scale = "medium", returnclass = "sf")

# Filter only European countries
europe <- world %>% 
  filter(continent == "Europe")


# Define the classification
europe <- europe %>%
  mutate(Subregion = case_when(
    name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    name %in% c("Spain", "Portugal", "Italy", "Malta", 
                 "Greece") ~ "S",
    name %in% c("Albania", "Bulgaria", "Romania", "Kosovo", "Bosnia and Herz.", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~ "E",
    name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C",
  ))


ggplot(data = europe) +
  geom_sf(aes(fill = Subregion), color = "black") +
  scale_fill_manual(values = c(
    "N" = "#F5BA6A",    
    "S" = "#4044A8",    
    "W" = "#CC4853",    
    "E" = "#5ED171",   
    "C" = "#F5E973",    
    "B" = "#66B0FA"    
  )) + scale_x_continuous(limits = c(-20, 35)) +
  scale_y_continuous(limits = c(35, 70)) +
  theme_minimal() +
  labs(
       fill = "Subregion") +
  theme(legend.position = "right")
```

We are considering Greece as part of the Southern region due to the cultural differences with the Balkan countries. Now, we would choose a country to represent each European subregion. We will select five European countries to analyze their trends in the number of tuberculosis-related deaths. The selection criteria will ensure that the chosen countries represent different regions of Europe (e.g., North, South, etc.) while also having a sufficient number of time observations to construct a reliable time series. Additionally, we aim to include countries that exhibit distinct trends in tuberculosis mortality, making the study more insightful by allowing for a comparative analysis and accurate forecasting of different patterns.

As a first step, we will address any missing values (NA) in the dataset for the variable Number_Deaths in each selected country. We are going to choose countries that at least have 40 years with data.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  dplyr::select(country_name, number_deaths) %>% 
  na.exclude() %>%  
  group_by(country_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  data.frame() %>% 
  filter(n >= 40)

```

```{r}

full_dataset %>%
  filter(subregion == "C") %>% 
  group_by(country_name) %>%
  summarise(
    number_deaths = sum(!is.na(number_deaths)),
    population  = sum(!is.na(population)),
    gdp_capita  = sum(!is.na(gdp_capita))
  ) %>%
  arrange(desc(number_deaths)) %>%
  data.frame() 

```


Lets study each subregion:

-   **Southern Europe**. Due to the geographical origin of the authors, we will choose Spain as the representative country of this region.

-   **Northern Europe**. We observe that Iceland has 72 out of 74 years with recorded values for the selected variable, making it a suitable choice to represent the North region of Europe.

-   **Western Europe**. As Netherlands is the country with a greatest number of values, it would be our choice for this specific region.

-   **Eastern Europe**. It is noticeable that eastern countries are the ones with a less number of recorded values (most of them have only 40 or less); then, it would be a special region to analyse. Lithuania will represent the Northeast region, with 40 recorded values. Even though there are nearby countries with longer recorded periods, the tendency of Lithuania stands out among the rest, which will make for an interesting analysis.

-   **Central Europe**. Switzerland will be the representative country of the central region. It has 71 recorded values, that will fit perfectly when modeling the time series.

-   **Balkans region**. For the Balkans region, we have selected Romania, which has 60 recorded values. It will be an interesting case of analysis due to its tendency, that is a bit different as the other countries.

The selection criteria prioritize minimizing the number of missing values (NA) while ensuring a diverse representation of different regions in Europe. As we have discussed trends, let's display the trend in tuberculosis-related deaths for the selected countries.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  filter(country_name %in% c( "Spain", "Sweden", "Netherlands", "Switzerland", "Estonia", "Bulgaria")) %>%  
  ggplot(aes(x = year, y = number_deaths, color = country_name)) +  
  geom_line() +
  coord_cartesian(ylim = c(0,2700)) +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries trends")+
  theme(legend.position = "right") +
  ylab("Number of deaths")


```

## Data partitioning utilities

To standardize the modeling process across multiple countries, we define helper structures that facilitate consistent data handling. Specifically, we construct a country_splits hashmap to store the full, training, and testing datasets for each selected country.

The first step is to initialize this structure with the full dataset filtered by country and ordered by year:

```{r, warning=FALSE, message=FALSE}
country_splits <- hashmap()
chosen_countries = c("Spain", "Netherlands", "Sweden", "Switzerland", "Bulgaria", "Estonia")

for (name in chosen_countries) {
  country_splits[[name]][["full"]] <- full_dataset %>% filter(country_name == name) %>%  arrange(year)
}


```

Next, we define the specific number of years to allocate to the testing set for each country. These values were chosen based on the total number of available observations, ensuring approximately 15–20% of the series is reserved for out-of-sample evaluation.

```{r, warning=FALSE, message=FALSE}
test_lengths_per_country = hashmap()

test_lengths_per_country[["Spain"]] = 11
test_lengths_per_country[["Switzerland"]] = 11
test_lengths_per_country[["Sweden"]] = 11
test_lengths_per_country[["Estonia"]] = 11
test_lengths_per_country[["Netherlands"]] = 12
test_lengths_per_country[["Bulgaria"]] = 10
```

Finally, we split the dataset for each country into a training and a testing subset based on the predefined test lengths. This setup is essential for subsequent model fitting and forecast evaluation.

```{r, warning=FALSE, message=FALSE}
for (country in chosen_countries) {
  country_dataset = country_splits[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country[[country]]
  country_splits[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  country_splits[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}

```

We now define two utility functions. The first is designed to automate the selection of ARIMA models by systematically evaluating various parameter combinations and reporting their corresponding Akaike Information Criterion (AIC) values. This approach allows for an informed and reproducible model selection process, particularly useful when the number of possible $(p,d,q)$ combinations is large and exhaustive testing is impractical.


```{r, warning=FALSE, message=FALSE}

try_all_arima <- function(ar_coef, d_coef, ma_coef, time_series) {
  for (p in ar_coef) {
    for(d in d_coef) {
      for (q in ma_coef) {
      arima_fit <- Arima(time_series, order = c(p, d, q))
      cat("ARIMA(", p, ",", d,"," ,q, ")\n", sep = "")
      print(arima_fit$coef)
      cat("AIC:", AIC(arima_fit), "\n\n")
  }
    }
}
}
```

This function iterates over all specified combinations of autoregressive (AR), differencing (I), and moving average (MA) orders. For each configuration, it fits an ARIMA model and outputs the estimated parameters along with the AIC value, which serves as the model selection criterion.

The second function is responsible for fitting an ARIMA model to the training series of a given country. It takes as input the ARIMA parameters $(p,d,q)$ and a country name, and includes an optional boolean argument, `log_transform`. This parameter allows the user to specify whether the time series should be log-transformed prior to model fitting. This functionality ensures flexibility in handling different types of data distributions, particularly those exhibiting heteroscedasticity or exponential decay patterns. It uses the `Arima()` function of the `forecast` package.

```{r, warning=FALSE, message=FALSE}
fit_arima <- function(p, d, q, country, log_transform = TRUE) {
  series <- country_splits[[country]]$train$number_deaths
  if (log_transform) {
    series <- log(series)
  }
  train_ts <- ts(series)
  arima_fit <- Arima(train_ts, order = c(p, d, q))
  return(arima_fit)
}
```

Finally, we define the get_length function to facilitate quick retrieval of the number of non-missing observations in a specified dataset. Accessing time series lengths manually for each country and subset (full, train, or test) can be cumbersome and error-prone. This utility function simplifies the process by requiring only the country name, the desired subset, and the target variable. It returns the number of valid (non-NA) entries.

```{r}
get_length <- function(country, set, variable) {
  return(length(na.omit(country_splits[[country]][[set]][[variable]])))
}

```

## ARIMA models

In this section, we analyze the temporal dynamics of tuberculosis-related mortality across the selected European countries using ARIMA models. Each country will be studied individually, beginning with an exploratory analysis of the log-transformed mortality data. Model parameters (p,d,q) will be selected based on empirical diagnostics such as the ACF/PACF plots and the AIC. The adequacy of each model will be verified through residual analysis.

### Spain

We begin our analysis with the Spanish dataset, which spans from 1951 to 2021 and comprises 71 annual observations. Given the long time span and the observed declining trend in raw counts, a logarithmic transformation is applied to stabilize variance and linearize the trend. The figure below shows the log-transformed training time series for tuberculosis mortality in Spain.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain <- ts(log(country_splits[["Spain"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(train_spain) +
  theme_minimal() +
  labs(
    title = "Log-transformed time series",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Spain"]]$train$number_deaths, start = 1951, frequency = 1)) +
  theme_minimal() +
  labs(
    title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

grid.arrange(p1,p2)

```
Next, we check the ACF and PACF plots:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(train_spain)
pacf(train_spain)
```
The ACF shows very high autocorrelation at the initial lags, which gradually decays in an exponential trend. In contrast, the PACF displays a single significant spike at lag 1, with all subsequent lags falling within the confidence bounds. This pattern is consistent with an AR($1$) process applied to a non-stationary series.

In order to formally assess whether the series is stationary, we apply the Augmented Dickey-Fuller (ADF) test:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain)
```

As expected, the high $p$-value indicates that we fail to reject the null hypothesis, which suggests that the series is non-stationary. In this case, applying a first-order difference is recommended.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain_diff <- train_spain %>% diff()


plot_ts(train_spain) +
  theme_minimal() +
  labs(
    title = "Differenced log-transformed time series",
    x = "Year",
    y = "Δ log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )
```
We can apply the ADF test to the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain_diff)
```

The test $p$-value ensures the stationarity of the time series. Now, we check the ACF and PACF of the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(train_spain_diff)
pacf(train_spain_diff)
```
The ACF of the differenced log-transformed series shows a strong spike at lag 0, which is expected since any time series is perfectly correlated with itself at lag 0. Beyond that, no significant spikes appear—autocorrelations at higher lags lie well within the confidence bounds. This suggests there is no strong moving average (MA) structure in the differenced series.

Similarly, the PACF displays only minor fluctuations, with all values remaining inside the confidence intervals. This indicates no clear autoregressive (AR) component is present either.

Now, we need to choose the order for the ARIMA models; in general, the selection is based on the ACF and PACF. However, since the ACF and PACF show no other AR or MA components, we will use the function `auto.arima()` from the `forecast`package in order to determine the best model, based on the AIC criterion. Also, we will fit the ARIMA($0,1,0$), that is the result of differencing the series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain <- ts(log(country_splits[["Spain"]]$test$number_deaths), start = 2011,  frequency = 1)

fit_spain_auto <- auto.arima(train_spain)
fit_spain_010 <- Arima(train_spain, order = c(0,1,0)) 

summary(fit_spain_auto)
summary(fit_spain_010)

```

The ARIMA autogenerated is an ARIMA(0,2,1), meaning that it has differenced the series twice and has an MA component left. The AIC is quite low ($-100,25$), indicating that it can be a good model. Looking at the error measures of the training set, the model shows good performance, with an RMSE of $0.096$ and a MAPE below $1$% on the log-transformed training set. The low MAE and near-zero ACF1 ($-0.03$) indicate well-behaved residuals and a solid overall fit. 

The ARIMA($0,1,0$) has also a small AIC ($-80,98$); the model yields moderate in-sample accuracy, with an RMSE of $0.119$ and a MAPE of $1.13$% on the log-transformed training set. Although the error metrics are acceptable, the higher MAE and MASE values suggest less precise fitting. The residual autocorrelation (ACF1 = $-0.086$) is low, indicating that no substantial temporal structure remains unmodeled.

Before the forecast, we need to check on the residuals of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_auto %>% forecast::checkresiduals()

shapiro.test(residuals(fit_spain_auto))
```

The ARIMA($0,2,1$) passes both the Ljung-Box test and the Shapiro-Wilk normality test, indicating that the residuals do not present any temporal structure left. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_010 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_spain_010))
```
In contrast, the ARIMA($0,1,0$) does not pass the normality test for residuals. To mitigate the potencial impact of non-normal residuals on forecast, we apply a bootstrap approach during forecasting.

In the `forecast()` function, setting `bootstrap = TRUE` generates forecast intervals by resampling the residuals rather than assuming they follow a normal distribution. This produces more robust and data-driven prediction intervals when the normality assumption is violated.

We now proceed with the forecasting stage. The forecast horizon is set to match the length of the test set, ensuring a direct comparison between predicted and actual values. A confidence level of $95$% is used, meaning that each forecasted point is accompanied by an interval within which the true value is expected to lie with $95$% probability.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

forecast_spain_auto <- forecast(fit_spain_auto, level = c(95), h = get_length("Spain", "test", "number_deaths"))

forecast_spain_auto
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecast_spain_auto) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(0,2,1)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecast_spain_auto) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(0,2,1)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, max(time(forecast_spain_auto$mean)))) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```
Now, although the model has captured the downward trend of the time series, it has predicted a quasi-linear trend. Now, we can plot the real values versus the predicted ones, on the logarithmic scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

plot_spain_log_021 <- data.frame(
  Year = seq_along(test_spain),
  Actual = test_spain,
  Predicted_021 = forecast_spain_auto$mean
)


ggplot(plot_spain_log_021, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_021, color = "Predicted_021"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_021" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```
To finally determine that the model does not predict correctly the test values, we check the error measures:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- data.frame(
  Model = "ARIMA(0,2,1)",
  ME = mean(test_spain - forecast_spain_auto$mean),
  RMSE = rmse(test_spain, forecast_spain_auto$mean),
  MPE = mean((test_spain - forecast_spain_auto$mean) / test_spain) * 100,
  MAE = mae(test_spain, forecast_spain_auto$mean),
  MAPE = mape(test_spain, forecast_spain_auto$mean) * 100
)

error_summary
```

The ARIMA($0,2,1$) model produced a Mean Error of $–0.25$ and a RMSE of $0.26$ on the log-transformed test set, indicating a mild tendency to overestimate. The MPE and MAPE were $–4.58$% and $4.58$%, respectively. These values suggest that, on average, the model overpredicts tuberculosis deaths by approximately $4.6$%.

Now, we do the same analysis for the ARIMA($0,1,0$).


```{r, warning=FALSE, message=FALSE, echo = FALSE}
forecast_spain_010 <- forecast(fit_spain_010, level = c(95), h = get_length("Spain", "test", "number_deaths"), bootstrap = TRUE)

forecast_spain_010
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

autoplot(forecast_spain_010) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(0,1,0)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecast_spain_010) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(0,1,0)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, max(time(forecast_spain_auto$mean)))) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```
The model has predicted a constant line, indicating that it is not a good model for the data. To assess formally this fact, we study the error measures on the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary <- data.frame(
  Model = "ARIMA(0,1,0)",
  ME = mean(test_spain - forecast_spain_010$mean),
  RMSE = rmse(test_spain, forecast_spain_010$mean),
  MPE = mean((test_spain - forecast_spain_010$mean) / test_spain) * 100,
  MAE = mae(test_spain, forecast_spain_010$mean),
  MAPE = mape(test_spain, forecast_spain_010$mean) * 100
)

error_summary
```
The ARIMA($0,1,0$) model yields relatively poor forecast performance, with a high RMSE of $0.49$ and a MAPE of $8.52$% on the log-transformed test set. The negative ME and MPE values indicate a consistent overestimation of tuberculosis deaths, suggesting that the model fails to adequately capture the underlying downward trend.

The final conclusion is that the current models are too simple to forecast this series. We will now manually select another model and examine whether a more complex model can predict the series more accurately.

We will use the `try_all_arima` function. We choose a 1 order difference, as the series showed stationarity after the differencing. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ma_coef = c(2,3)
ar_coef = c(2,3)

try_all_arima(ar_coef, 1, ma_coef, train_spain)
```

The function shows that the two models with the smallest AIC is the ARIMA($2,1,2$).

We check the residuals of the models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_212 <- Arima(train_spain, order = c(2,1,2))

fit_spain_212 %>% 
  forecast::checkresiduals()

shapiro.test(residuals(fit_spain_212))
```
The residuals of the ARIMA($2,1,2$) satisfy both hypothesis of normality and no autocorrelation left.

Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
forecast_spain_212 <- forecast(fit_spain_212, level = c(95), h = get_length("Spain", "test", "number_deaths"))

forecast_spain_212
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecast_spain_212) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(2,1,2)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecast_spain_212) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(2,1,2)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, max(time(forecast_spain_auto$mean)))) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

The plot shows how a higher order of the parameters, starts to capture the oscillating behavior of the series. Let's check the error measures of the test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMA(2,1,2)",
  ME = mean(test_spain - forecast_spain_212$mean),
  RMSE = rmse(test_spain, forecast_spain_212$mean),
  MPE = mean((test_spain - forecast_spain_212$mean) / test_spain) * 100,
  MAE = mae(test_spain, forecast_spain_212$mean),
  MAPE = mape(test_spain, forecast_spain_212$mean) * 100
)

error_summary
```

The ARIMA($2,1,2$) model exhibits a slight overestimation bias but maintains moderate error magnitude (RMSE = $0.296$, MAE = $0.282$) on the log scale. Its MPE of $–5.17$% and MAPE of $5.17$% indicate forecasts deviate by just over $5$% from actual values, reflecting a reasonable balance between accuracy and complexity.

Finally, we can plot the predicted values versus the real values, on the logarithmic scale.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_spain_log_212 <- data.frame(
  Year = seq_along(test_spain),
  Actual = test_spain,
  Predicted_212 = forecast_spain_212$mean
)


ggplot(plot_spain_log_212, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_212, color = "Predicted_212"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_212" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

**Final conclusions**

Let's do a summary of the Spain models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain_real <- exp(test_spain)
pred_spain_auto <- exp(forecast_spain_auto$mean)
pred_spain_010 <- exp(forecast_spain_010$mean)
pred_spain_212 <- exp(forecast_spain_212$mean)

plot_spain <- data.frame(
  Year = seq_along(test_spain_real),
  Actual = test_spain_real,
  Predicted_auto = pred_spain_auto,
  Predicted_010 = pred_spain_010,
  Predicted_212 = pred_spain_212
)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary_spain <- data.frame(
  Model = c("ARIMA(0,2,1)", "ARIMA(0,1,0)", "ARIMA(2,1,2)"),
  ME = c(mean(test_spain_real - pred_spain_auto),
         mean(test_spain_real - pred_spain_010),
         mean(test_spain_real - pred_spain_212)),
  
  RMSE = c(rmse(test_spain_real, pred_spain_auto),
           rmse(test_spain_real, pred_spain_010),
           rmse(test_spain_real, pred_spain_212)),
  
  MPE = c(mean((test_spain_real - pred_spain_auto) / test_spain_real) * 100,
          mean((test_spain_real - pred_spain_010) / test_spain_real) * 100,
          mean((test_spain_real - pred_spain_212) / test_spain_real) * 100),
  
  MAE = c(mae(test_spain_real, pred_spain_auto),
          mae(test_spain_real, pred_spain_010),
          mae(test_spain_real, pred_spain_212)),
  
  MAPE = c(mape(test_spain_real, pred_spain_auto) * 100,
           mape(test_spain_real, pred_spain_010) * 100,
           mape(test_spain_real, pred_spain_212) * 100)
)

error_summary_spain

```

The out‐of‐sample comparison on the original (untransformed) scale shows that ARIMA($0,2,1$) achieves the lowest overall error among the three candidates. Specifically, its RMSE of $70.10$ and MAE of $68.47$ indicate smaller average forecast deviations compared to ARIMA(0,1,0) (RMSE = $147.64$, MAE = $141.82$) and ARIMA(2,1,2) (RMSE = $80.62$, MAE = $78.51$). In percentage terms, ARIMA($0,2,1$) yields a MAPE of $28.76$%, which is nearly half of ARIMA($0,1,0$)’s $61.33$% and substantially better than ARIMA($2,1,2$)’s $33.11$%. Although all three models exhibit a modest overestimation bias (negative ME and MPE), ARIMA($0,2,1$) overpredicts by an average of only $68$ deaths ($–28.76$% relative bias), whereas ARIMA($0,1,0$) and ARIMA($2,1,2$) overestimate by $142$ ($–61.33$%) and $79$ ($–33.11$%) deaths, respectively.

Taken together, these results demonstrate that ARIMA($0,2,1$) best balances predictive accuracy for tuberculosis mortality in Spain.. Consequently, ARIMA($0,2,1$) is the preferred model for forecasting this series.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
ggplot(plot_spain, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_auto, color = "Predicted_auto"), linetype = "dashed") +
  geom_line(aes(y = Predicted_010, color = "Predicted_010"), linetype = "dashed") +
  geom_line(aes(y = Predicted_212, color = "Predicted_212"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_auto" = "purple", "Predicted_010" = "red", "Predicted_212" = "green")) +
  labs(title = "Actual vs Predicted TB Deaths",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```



Although ARIMA($0,2,1$) achieved the lowest numerical errors, its fitted trajectory clearly overestimates the true decline in TB deaths (see the plot). However, because the forecast curve from ARIMA($0,2,1$) decays too gradually and remains well above the actual values after 2015, it fails to capture the accelerated drop in mortality.

In light of this discrepancy between numerical error metrics and visual fit, ARIMA($0,2,1$) does not adequately reproduce the sharp downturn observed in the test period. Therefore, despite its lower AIC and error measures, ARIMA($0,2,1$) is not optimal.


## ARIMAX models

We have seen that ARIMA models are quite simple in order to do a well-suited forecast for our studied series. In this section we will study ARIMAX models; ARIMAX models are ARIMA models that include some exogenous variables in order to get better forecastings rather than basic ARIMA. In our study, we will consider two exogenous variables: Gross Domestic Product per capita and the country population. 

First, we visualize these series. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables <- full_dataset %>% 
  filter(country_name %in% c("Spain", "Switzerland", "Sweden", "Netherlands", "Estonia", "Bulgaria")) %>% 
  select(year, country_name, population,  gdp_capita) %>% 
  arrange(year)

```

We begin analysing the Population variable. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables %>%  
  ggplot(aes(x = year, y = population/1000000, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries population trends")+
  theme(legend.position = "right") +
  ylab("Population (in millions)")

```
In stark contrast with the other countries, Spain population has a strong increasing trend, climbing from around 28 million in 1950 to nearly 48 million by 2020. The Netherlands also grows steadily, from about 10 million to roughly 18 million. Sweden’s population increases more modestly, moving from approximately 7 million to just over 10 million, while Switzerland rises from about 5 million to nearly 9 million over the same period. 

In contrast, Bulgaria peaks near 9 million in the 1980s before gradually declining to about 7 million by 2020, and Estonia remains the smallest, hovering around 1.7 million in 1980 but falling slightly to around 1.3 million by 2020. The plot clearly highlights Spain’s large and sustained growth, moderate increases for Northern and Western European countries, and population declines in Eastern Europe.

Now, let's visualize the GDP per capita tendencies:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
exogenous_variables %>%  
  ggplot(aes(x = year, y = gdp_capita, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries GDP per capita trends")+
  theme(legend.position = "right") +
  ylab("GDP per capita (in current U.S. dollars)")
```
Now, the outlook is quite different; Switzerland leads the list, climbing from around \$2,000 in 1960 to over \$90,000 by 2020, with sharp surges in the late 1990s and post-2005. Following Switzerland, the Netherlands and Sweden follow a similar upward trajectory. Spain increases more modestly, from under \$1,000 to a peak of around \$35,000 by 2008, then levels out in the \$25,000–\$30,000 range.Estonia lags until independence—remaining near zero through the Soviet era—then surges after 1992 from around \$2,000 to approximately \$25,000 by 2020. Bulgaria also starts below \$1,000, grows gradually through the 1980s, dips in the 1990s, and then climbs to roughly \$12,000 by 2020. 

Overall, Switzerland, Sweden, and the Netherlands display long-term, high-income growth; Spain shows moderate growth with a plateau post-2008; and the Eastern European countries (Estonia and Bulgaria) demonstrate rapid catch-up following post-1990 transitions.

Before beginning the ARIMAX section, it is important to give special attention to the length of each of the variables, just to ensure that the studied variable (number_deaths) length coincides with the covariables length.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_all_lengths <- function(countries) {
  data.frame(
    Country = countries,
    number_deaths_length = sapply(countries, function(cn) get_length(cn, "full", "number_deaths")),
    population_length = sapply(countries, function(cn) get_length(cn, "full", "population")),
    gdp_capita_length = sapply(countries, function(cn) get_length(cn, "full", "gdp_capita")),
    row.names = NULL
  )
}

lengths_df <- get_all_lengths(chosen_countries)

lengths_df

```

It is necessary that all variable have the same length; we create a function in order to automate this step.

```{r}

slice_country_data <- function(country, start_year) {
  df_full <- country_splits[[country]][["full"]]
  df_filtered <- df_full %>%
    filter(year >= start_year) %>%
    arrange(year)  

  return(df_filtered)
}

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short <- hashmap()

countries_short[["Spain"]][["full"]] <- slice_country_data("Spain", 1960)
countries_short[["Netherlands"]][["full"]] <- slice_country_data("Netherlands", 1960)
countries_short[["Sweden"]][["full"]] <- slice_country_data("Sweden", 1960)
countries_short[["Switzerland"]][["full"]] <- slice_country_data("Switzerland", 1960)
countries_short[["Estonia"]][["full"]] <- slice_country_data("Estonia", 1993)
countries_short[["Bulgaria"]][["full"]] <- slice_country_data("Bulgaria", 1980)


```

Now, we need to divide these new series into a training and a testing set. We will do the split, ensuring that the 80% of the data is used for training.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
test_lengths_per_country_short = hashmap()

test_lengths_per_country_short[["Spain"]] = 12
test_lengths_per_country_short[["Switzerland"]] = 12
test_lengths_per_country_short[["Sweden"]] = 12
test_lengths_per_country_short[["Estonia"]] = 6
test_lengths_per_country_short[["Netherlands"]] = 12
test_lengths_per_country_short[["Bulgaria"]] = 8
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
for (country in chosen_countries) {
  country_dataset = countries_short[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country_short[[country]]
  countries_short[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  countries_short[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}


```

Now that we have prepared the dataset, we can begin the ARIMAX study.

### Spain

We begin studying Spain data. First, let's plot all three variables (number_deaths, population and gdp_capita) in the same plot.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_spain_arimax_plot <- data.frame(
  Year = countries_short[["Spain"]][["full"]]$year,
  number_deaths = countries_short[["Spain"]][["full"]]$number_deaths,
  population = countries_short[["Spain"]][["full"]]$population,
  gdp_capita = countries_short[["Spain"]][["full"]]$gdp_capita
)


ggplot(df_spain_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = number_deaths, color = "number_deaths")) +
  geom_line(aes(y = population/10000, color = "population")) +
  geom_line(aes(y = gdp_capita, color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Spain",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()


ggplot(df_spain_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Spain",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain_short <- ts(log(countries_short[["Spain"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_spain_train <- data.frame(
  population = ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)


fit_arimax_spain <- auto.arima(train_spain_short, xreg= as.matrix(xreg_spain_train ))

summary(fit_arimax_spain)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_spain))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain_short <- ts(log(countries_short[["Spain"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

xreg_spain_test <- data.frame(
  population = ts(log(countries_short[["Spain"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
)

forecastx_spain_200 <- forecast(fit_arimax_spain, level = c(95), h = length(test_lengths_per_country_short[["Spain"]]), xreg = as.matrix(xreg_spain_test))

forecastx_spain_200
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_spain_200) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMAX(2,0,0)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_spain_200) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(2,0,0)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_spain_log_200 <- data.frame(
  Year = seq_along(test_spain_short),
  Actual = test_spain_short,
  Predicted_arimax = forecastx_spain_200$mean
)


ggplot(plot_spain_log_200, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```
Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(2,0,0)",
  ME = mean(test_spain_short - forecastx_spain_200$mean),
  RMSE = rmse(test_spain_short ,forecastx_spain_200$mean),
  MPE = mean((test_spain_short - forecastx_spain_200$mean) / test_spain_short) * 100,
  MAE = mae(test_spain_short, forecastx_spain_200$mean),
  MAPE = mape(test_spain_short ,forecastx_spain_200$mean) * 100
)


error_summary
```

The ARIMAX(2,0,0) model exhibits a slight overestimation bias (ME = $–0.36$) and moderate overall error (RMSE = $0.40$, MAE = $0.37$) on the log‐transformed series. Its MPE of $–6.57$% and MAPE of $6.76$% indicate that, on average, forecasts overshoot actual logarithmic values by around $6.8$%, suggesting that while the exogenous variables help, there remains room for improvement in capturing the downward trajectory of TB deaths.

In order to improve our ARIMAX model beyond what `auto.arima()` suggested, we will now inspect each differenced series manually (the response and both regressors) and choose orders $p$ and $q$ based on the ACF/PACF patterns, rather than relying on automatic selection. Recall that all three series (log(number_deaths), log(population) and log(gdp_capita)) are non‐stationary, so we first take first differences.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain_short_diff <- train_spain_short %>% diff()

acf(train_spain_short_diff)
pacf(train_spain_short_diff)
```
The ACF plot shows a large, significant spike at lag 1, and then quickly dies off. In the same way, the PACF plot shows a significant spike at lag 1, with all higher partial autocorrelations inside the confidence bounds. These patterns suggest an ARIMA($p,1,q$) where one of $p$ or $q$ should be 1.

Next, we difference the log⁡(population) series over the same short training period:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
population_spain_diff <- ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff()

acf(population_spain_diff)
pacf(population_spain_diff)
```
TH ACF plot shows a slow exponential decay over the first few lags. In contrast, the PACF shows a single large spike at lag 1, and then subsequent lags are essentially within the confidence bounds. This pattern is characteristic of an AR($1$) process. 

Finally, we difference the log(gdp_capita) series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
gdp_capita_spain_diff <- ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff()

acf(gdp_capita_spain_diff)
pacf(gdp_capita_spain_diff)
```
The ACF plot shows a large spike at lag 1 and smaller but non-negligible negative values at lags 3-7 and 9-11. On the other hand, the PACF also shows a strong negative spike at lag 5, and samller spikes between lags 6 and 15, but the dominant feature is the large positive spike at lag 1.

This may suggest that the series may require both an AR($1$) and possibly an MA component to capture the very strong lag-1 autocorrelation. 

Putting all together, we propose the ARIMA($1,1,1$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_spain_111 <- Arima(train_spain_short, order = c(1,1,1), xreg = as.matrix(xreg_spain_train))
fit_arimax_spain_111
```
The value of the AIC ($-107.89$) indicates a well-suited fit. Now, we need to check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_spain_111 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_spain_111))
```

The model's residuals pass both normality and Ljung-Box tests. Now, we do the forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
forecastx_spain_111 <- forecast(fit_arimax_spain_111, level = c(95), h = length(test_lengths_per_country_short[["Spain"]]), xreg = as.matrix(xreg_spain_test))

forecastx_spain_111

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_spain_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMAX(1,1,1)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_spain_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(1,1,1)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```
Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_spain_log_111 <- data.frame(
  Year = seq_along(test_spain_short),
  Actual = test_spain_short,
  Predicted_arimax = forecastx_spain_111$mean
)


ggplot(plot_spain_log_111, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```
Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,1,1)",
  ME = mean(test_spain_short - forecastx_spain_111$mean),
  RMSE = rmse(test_spain_short ,forecastx_spain_111$mean),
  MPE = mean((test_spain_short - forecastx_spain_111$mean) / test_spain_short) * 100,
  MAE = mae(test_spain_short, forecastx_spain_111$mean),
  MAPE = mape(test_spain_short ,forecastx_spain_111$mean) * 100
)


error_summary
```

The ARIMAX($1,1,1$) model yields a small overestimation bias (ME = $–0.35$) and moderate error magnitude (RMSE = $0.396$, MAE = $0.362$) on the log‐transformed series. Its MPE of $–6.42$% and MAPE of $6.64$% indicate that forecasts tend to overshoot actual values by roughly $6.6$%, reflecting improved but still imperfect tracking of the downward TB‐death trend.

**Final conclusions**

Let's do a summary of the Spain models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain_real_short <- exp(test_spain_short)
predx_spain_auto <- exp(forecastx_spain_200$mean)
predx_spain_111 <- exp(forecastx_spain_111$mean)


plot_spain_arimax <- data.frame(
  Year = seq_along(test_spain_real_short),
  Actual = test_spain_real_short,
  Predicted_auto= predx_spain_auto,
  Predicted_111 = predx_spain_111
)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
arimax_error_summary_spain <- data.frame(
  Model = c("ARIMA(2,0,0)", "ARIMA(1,1,1)"),
  ME = c(mean(test_spain_real_short - predx_spain_auto),
         mean(test_spain_real_short - predx_spain_111)),
  
  RMSE = c(rmse(test_spain_real_short, predx_spain_auto),
           rmse(test_spain_real_short, predx_spain_111)),
  
  MPE = c(mean((test_spain_real_short - predx_spain_auto) / test_spain_real_short) * 100,
          mean((test_spain_real_short - predx_spain_111) / test_spain_real_short) * 100),
  
  MAE = c(mae(test_spain_real_short, predx_spain_auto),
          mae(test_spain_real_short, predx_spain_111)),
  
  MAPE = c(mape(test_spain_real_short, predx_spain_auto) * 100,
           mape(test_spain_real_short, predx_spain_111) * 100)
)

arimax_error_summary_spain

```

The out‐of‐sample comparison on the original scale shows that ARIMA($1,1,1$) slightly outperforms ARIMA($2,0,0$). Although both models exhibit a modest overestimation bias (ME ≈ $–105$ for (2,0,0) versus $–102$ for (1,1,1)), ARIMA($1,1,1$) achieves a lower RMSE ($113.57$ vs. $116.45$), a lower MAE ($106.59$ vs. $108.95$), and a lower MAPE ($45.44$% vs. $46.50$%). In percentage terms, ARIMA($1,1,1$) also has a smaller average bias ($–44.15$% vs. $–45.41$%). Taken together, these results indicate that ARIMA($1,1,1$) provides a marginally better fit to the actual TB‐death trajectory than ARIMA($2,0,0$), making it the preferred model for forecasting.

Finally, we plot both approaches for the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

ggplot(plot_spain_arimax, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_auto, color = "Predicted_auto"), linetype = "dashed") +
  geom_line(aes(y = Predicted_111, color = "Predicted_111"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_auto" = "purple", "Predicted_111" = "red")) +
  labs(title = "Actual vs Predicted TB Deaths",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```


## Logarithmic regression

We have proved that ARIMA and ARIMAX models do not fit well the time series. The final option, is to apply a logarithmic regression. We will apply two different regressions: the simple regression log(number_deaths) ~ year, and a more complex one, log(number_deaths) ~ year + log(population) + log(gdp_capita).

### Spain

#### Simple regression

In this first regression, we will use the complete data, not the shorter ones. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_spain_df <- country_splits[["Spain"]][["train"]] 

lm_trend_simple_spain <- lm(train_spain ~ year, data = train_spain_df)
summary(lm_trend_simple_spain)

```

The linear regression of log(number_deaths) on year yields an intercept of 137.93 and a slope of –0.0658 (both highly significant, $p<2\mathrm{e}{-16}$), indicating a strong, steady annual decline in log‐deaths. The model explains 98.07% of the variance ($R^2=0.9807$), with residuals showing a low standard error (0.1626), confirming an excellent fit during 1960–2000.

Now, we need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

lm_trend_simple_spain %>% forecast::checkresiduals()

simple_spain_residuals <- ts(residuals(lm_trend_simple_spain), start = 1951, frequency = 1)

```

As we see in the plot, the model has not fully capture the structure of the series, meaning we will need to determine an ARIMA structure for the residuals. We begin by plotting the ACF and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(simple_spain_residuals)
pacf(simple_spain_residuals)

```
The ACF plot shows an exponential decaying trend, whereas the PACF shows a significant spike at lag 1. This pattern may suggest an AR($1$) component for the residuals.

Let's fit an ARMA($1,0$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arima_simple_spain_residuals <- Arima(simple_spain_residuals, order = c(1, 0, 0))
summary(fit_arima_simple_spain_residuals)
```

It seems a well-fitted model (AIC value of $-103.8$). Now, we check the residuals of the model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_simple_spain_residuals %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arima_simple_spain_residuals))
```

The residuals have checked the Ljung-Box text; however, they do not pass the normality test.

We begin the forecast phase. The forecast is divided into two steps:
1. The trend pronostic
2. The residuals pronostic

The final pronostic is given by the sum of the above ones.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_simple_spain_trend <- predict(
  lm_trend_simple_spain,
  newdata = data.frame(year = country_splits[["Spain"]][["test"]]$year)
)

predicted_simple_spain_residuals <- forecast(fit_arima_simple_spain_residuals, h = get_length("Spain", "test", "number_deaths"))

forecast_simple_spain_log <- predicted_simple_spain_trend + predicted_simple_spain_residuals$mean


forecast_simple_spain <- exp(forecast_simple_spain_log)
forecast_simple_spain
```

Finally, we plot the forecasted time series versus the real values, on the original scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

plot_simple_spain <- data.frame(
  Year     = country_splits[["Spain"]][["test"]]$year,
  Actual   = country_splits[["Spain"]][["test"]]$number_deaths,
  Forecast = forecast_simple_spain
)

ggplot(plot_simple_spain, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#ff7f0e")
  ) +
  labs(
    title    = "Actual vs. Predicted TB deaths",
    subtitle = "Model: log(number_deaths) ~ year + ARMA(1,0) in residuals",
    x        = "Year (Test Set: 2001–2010)",
    y        = "Number of Deaths",
    color    = "Serie"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```
It is clear that the model have given a more adjusted prediction that all the models tried before. Finally, we need to analyze the error measures.



```{r, warning=FALSE, message=FALSE, echo = FALSE}
actual_spain <- country_splits[["Spain"]][["test"]]$number_deaths


error_summary_simple_spain <- data.frame(
  Model = "log(number_deaths) ~ year",
  ME = mean(actual_spain - forecast_simple_spain),
  RMSE = rmse(actual_spain, forecast_simple_spain),
  MPE = mean((actual_spain - forecast_simple_spain) / actual_spain) * 100,
  MAE = mae(actual_spain, forecast_simple_spain),
  MAPE = mape(actual_spain, forecast_simple_spain) * 100
)


error_summary_simple_spain
```
The trend‐plus‐AR(1) model on $\log(\text{number_deaths}) \sim \text{year}$ delivers a modest bias (ME = $–4.82$ deaths) and a low RMSE of $28.11$, corresponding to an average absolute error of $20.55$ deaths. Its MAPE of $7.93$% indicates that forecasts typically deviate by less than $8$%, a substantial improvement over earlier ARIMA‐only approaches. Overall, this specification captures the downward TB mortality trend very effectively.

#### Complete regression

Now, as we have the population and gdp per capita regressors, we will define a regression model with those variables. Note that in this approach, the shorter dataset will be used, in order to asses the discrepancies on variables' lengths.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
spain_short_train_df <- countries_short[["Spain"]][["train"]]
log_population_spain <- log(spain_short_train_df$population)
log_gdp_capita_spain <- log(spain_short_train_df$gdp_capita)

lm_trend_complete_spain <- lm(train_spain_short ~ year + log_population_spain + log_gdp_capita_spain, data = spain_short_train_df)

summary(lm_trend_complete_spain)
```
The multiple regression of $\log(\text{deaths})$ on year, $\log(\text{population})$, and $\log(\text{GDP per capita})$ explains 98.9% of the variance ($R^2 = 0.9889$) with a very small residual error (0.102). Holding population and GDP constant, the coefficient for year is $-0.0328$ ($p < 10^{-6}$), indicating a significant annual decline in log‐deaths. While $\log(\text{GDP per capita})$ also has a significant negative effect ($\beta = -0.2249,\;p = 0.0005$), $\log(\text{population})$ shows a marginally non‐significant negative association ($\beta = -1.5083,\;p = 0.0707$).

Now, we need to check the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
lm_trend_complete_spain %>% forecast::checkresiduals()

complete_spain_residuals <- residuals(lm_trend_complete_spain)

```
As the simple regression, the residuals for this more complex model do not satisfy any of the conditions, meaning that the regression still not capture all the interal structure. 

We need to further study the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(complete_spain_residuals)
pacf(complete_spain_residuals)

```
The ACF plot shows a very large spike at lag 1 followed by a gradual decay over lags 2-7, where it begins to increase again. The PACF plot exhibits a single dominant spike at lag 1 with all higher-lag partial autocorrelations inside the confidence boundaries. This pattern may suggest, as the simple regression model, an AR($1$) process.

We fit this model on the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_spain_residuals <- Arima(complete_spain_residuals, order = c(1, 0, 0))
summary(fit_arima_complete_spain_residuals)

```
The low AIC value indicates a good fit. We check now the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_spain_residuals %>% forecast::checkresiduals()
shapiro.test(residuals(fit_arima_complete_spain_residuals))
```
Now the residuals satisfy the necessary hypothesis. We begin the pronostics.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_complete_spain_trend <- predict(
  lm_trend_complete_spain,
  newdata = data.frame(
    year = countries_short[["Spain"]][["test"]][["year"]],
    log_population_spain = log(countries_short[["Spain"]][["test"]][["population"]]),
    log_gdp_capita_spain = log(countries_short[["Spain"]][["test"]][["gdp_capita"]])
  )
)

predicted_complete_spain_log_residuals <- forecast(fit_arima_complete_spain_residuals, h = length(countries_short[["Spain"]][["test"]][["year"]]))

forecast_complete_spain_log <- predicted_complete_spain_trend + predicted_complete_spain_log_residuals$mean


forecast_complete_spain <- exp(forecast_complete_spain_log)
forecast_complete_spain
```

Finally, let's plot the new regression:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_complete_spain <- data.frame(
  Year     = countries_short[["Spain"]][["test"]][["year"]],
  Actual   = countries_short[["Spain"]][["test"]][["number_deaths"]],
  Forecast = forecast_complete_spain
)

plot_complete_spain

ggplot(plot_complete_spain, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#2ca02c")
  ) +
  labs(
    title    = "Actual vs. Forecast TB Deaths (Trend + Pop + GDP)",
    subtitle = "Modelo completo: log_deaths ~ year + log_population + log_gdp + ARMA(1,0)",
    x        = "Year (Test Set: 2001–2010)",
    y        = "Number of Deaths",
    color    = "Series"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

actual_deaths <- df_test$number_deaths

# 7.2. Calcular métricas para el modelo “FULL”
ME_full   <- mean(actual_deaths - deaths_forecast_full)
RMSE_full <- rmse(actual_deaths, deaths_forecast_full)
MAE_full  <- mae(actual_deaths, deaths_forecast_full)
MPE_full  <- mean((actual_deaths - deaths_forecast_full) / actual_deaths) * 100
MAPE_full <- mean(abs((actual_deaths - deaths_forecast_full) / actual_deaths)) * 100

results_full <- data.frame(
  Model = "Trend + ARMA (Full)",
  ME    = ME_full,
  RMSE  = RMSE_full,
  MAE   = MAE_full,
  MPE   = MPE_full,
  MAPE  = MAPE_full
)

print(results_full)

# ------------------------------------------------
# 8. GRAFICAR “ACTUAL vs. PRONÓSTICO (FULL)”
# ------------------------------------------------



```



