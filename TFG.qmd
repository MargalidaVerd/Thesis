---
title: "TFG"
author: "Margalida Verd Julià"
toc: true
format: html
editor: visual
---

## Installing data and packages

First, we will install and load the necessary packages for this study. Additionally, we will load the required datasets. The analysis is based on three datasets:

-   **Mortality**: Downloaded from the World Health Organization, this is the primary dataset for the analysis. It contains the number of tuberculosis-related deaths in all countries. However, our study will focus solely on European countries.

-   **Population**: From this dataset, we will extract only the population variable. The source of this data is *Our World in Data*.

-   **GDP per capita**: Similar to the population dataset, we will extract only the *gdp_per_capita* variable. The source of this data is *Data Bank*.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# packages loading

library(tidyverse)
library(readr)
library(dplyr)
library(zoo)
library(feasts)
library(eurostat)
library(leaflet)
library(sf)
library(scales)
library(cowplot)
library(ggthemes)
library(giscoR)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(dplyr)
library(gridExtra)
library(grid)
library(tsibble)
library(tseries)
library(FinTS)
library(fable)
library(vctsfr)
library(fpp2)
library(r2r)
library(Metrics)

```

Let's examine the structure of the datasets:

1.  Mortality:

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# data loading

mortality_dataset <- read.csv("mortality.csv", header = TRUE, colClasses = c("character","character","character","character","double","character","character","character","double","double","double","double"), row.names = NULL) 

colnames(mortality_dataset) <- colnames(mortality_dataset)[2:ncol(mortality_dataset)]
mortality_dataset <- mortality_dataset[1:(ncol(mortality_dataset)-1)]

mortality_dataset %>% 
  glimpse()

unique(mortality_dataset$Age.group)
```

2.  Population

```{r, warning=FALSE, message=FALSE, echo= FALSE}
population_dataset <- read.csv("population.csv", header = TRUE)

population_dataset %>% 
  glimpse()
```

3.  gdp_per_capita

```{r, warning=FALSE, message=FALSE, echo= FALSE}
gdp_per_capita_dataset <- read.csv("gdp_per_capita.csv", header = TRUE)

gdp_per_capita_dataset %>% 
  glimpse()
```

## Cleaning data

As seen, we need to standardize the variables names to merge the tables.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# renaming variables

print("Mortality")

mortality_dataset <- mortality_dataset %>%  
  rename(number_deaths = Number, 
         year = Year, percent_cause_specific_death_rate = Percentage.of.cause.specific.deaths.out.of.total.deaths, age_death_rate = Age.standardized.death.rate.per.100.000.standard.population, death_rate = Death.rate.per.100.000.population, country_name = Country.Name, country_code = Country.Code, region_code = Region.Code, region_name = Region.Name) %>% 
  glimpse() 

print("Population")
population_dataset <- population_dataset %>% 
  rename(population = Population...Sex..all...Age..all...Variant..estimates, country_name = Entity, year = Year) %>% 
  glimpse() 

print("gdp_per_capita")
gdp_per_capita_dataset <- gdp_per_capita_dataset %>% 
  select(3,4,5,7) %>% 
  rename(country_name = Country.Name, country_code = Country.Code, year = Time, gdp_capita = Value) %>% 
  glimpse()

```

The next step is to select the study variables from the mortality dataset. We will exclude `Sex`, `Age.group.code` and `Age.group`.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# Select rows of interest in the mortality dataset

mortality_dataset <- mortality_dataset %>% 
  dplyr::filter(Sex == "All") 

# Delete age variables

mortality_dataset <- mortality_dataset %>% 
  select(1:5,9:12) %>% 
  glimpse()
```

Now, we can merge the remaining two datasets.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# joins

full_dataset <- mortality_dataset %>% 
  left_join(population_dataset, by=c("country_name", "year")) %>% 
  left_join(gdp_per_capita_dataset, by = c("country_code", "year")) %>% 
  dplyr::filter(region_code=="EU") %>% 
  select(1:10,12) %>% 
  rename(country_name = country_name.x) 

full_dataset <- full_dataset %>% 
  filter(!(country_name == "Estonia" & year %in% c(1981, 1982)))

full_dataset %>% 
  glimpse()
```

## Chosen countries

First, we will define the criteria for dividing European countries into six distinct regions: North, South, West, East, Central, and the Balkans. The Balkans have been designated as a separate region due to their significant cultural differences from neighboring countries. We will add a new variable to the dataset that specifies the subregion to which each country belongs.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
view(full_dataset)

full_dataset <- full_dataset %>%
  mutate(subregion = case_when(
    country_name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    country_name %in% c("Spain", "Portugal", "Italy", "Malta", "Greece") ~ "S",
    country_name %in% c("Albania", "Bulgaria", "Romania", "Bosnia and Herzegovina", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    country_name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    country_name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~"E",
    country_name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C" ,TRUE ~ NA_character_), .after = region_name)

```

The map below shows the division that would be used from this point forward.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# Load world map with country boundaries
world <- ne_countries(scale = "medium", returnclass = "sf")

# Filter only European countries
europe <- world %>% 
  filter(continent == "Europe")


# Define the classification
europe <- europe %>%
  mutate(Subregion = case_when(
    name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    name %in% c("Spain", "Portugal", "Italy", "Malta", 
                 "Greece") ~ "S",
    name %in% c("Albania", "Bulgaria", "Romania", "Kosovo", "Bosnia and Herz.", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~ "E",
    name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C",
  ))


ggplot(data = europe) +
  geom_sf(aes(fill = Subregion), color = "black") +
  scale_fill_manual(values = c(
    "N" = "#F5BA6A",    
    "S" = "#4044A8",    
    "W" = "#CC4853",    
    "E" = "#5ED171",   
    "C" = "#F5E973",    
    "B" = "#66B0FA"    
  )) + scale_x_continuous(limits = c(-20, 35)) +
  scale_y_continuous(limits = c(35, 70)) +
  theme_minimal() +
  labs(
       fill = "Subregion") +
  theme(legend.position = "right")
```

We are considering Greece as part of the Southern region due to the cultural differences with the Balkan countries. Now, we would choose a country to represent each European subregion. We will select five European countries to analyze their trends in the number of tuberculosis-related deaths. The selection criteria will ensure that the chosen countries represent different regions of Europe (e.g., North, South, etc.) while also having a sufficient number of time observations to construct a reliable time series. Additionally, we aim to include countries that exhibit distinct trends in tuberculosis mortality, making the study more insightful by allowing for a comparative analysis and accurate forecasting of different patterns.

As a first step, we will address any missing values (NA) in the dataset for the variable Number_Deaths in each selected country. We are going to choose countries that at least have 40 years with data.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  dplyr::select(country_name, number_deaths) %>% 
  na.exclude() %>%  
  group_by(country_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  data.frame() %>% 
  filter(n >= 40)

```

```{r}

full_dataset %>%
  filter(subregion == "C") %>% 
  group_by(country_name) %>%
  summarise(
    number_deaths = sum(!is.na(number_deaths)),
    population  = sum(!is.na(population)),
    gdp_capita  = sum(!is.na(gdp_capita))
  ) %>%
  arrange(desc(number_deaths)) %>%
  data.frame() 

```

Lets study each subregion:

-   **Southern Europe**. Due to the geographical origin of the authors, we will choose Spain as the representative country of this region.

-   **Northern Europe**. We observe that Iceland has 72 out of 74 years with recorded values for the selected variable, making it a suitable choice to represent the North region of Europe.

-   **Western Europe**. As Netherlands is the country with a greatest number of values, it would be our choice for this specific region.

-   **Eastern Europe**. It is noticeable that eastern countries are the ones with a less number of recorded values (most of them have only 40 or less); then, it would be a special region to analyse. Lithuania will represent the Northeast region, with 40 recorded values. Even though there are nearby countries with longer recorded periods, the tendency of Lithuania stands out among the rest, which will make for an interesting analysis.

-   **Central Europe**. Switzerland will be the representative country of the central region. It has 71 recorded values, that will fit perfectly when modeling the time series.

-   **Balkans region**. For the Balkans region, we have selected Romania, which has 60 recorded values. It will be an interesting case of analysis due to its tendency, that is a bit different as the other countries.

The selection criteria prioritize minimizing the number of missing values (NA) while ensuring a diverse representation of different regions in Europe. As we have discussed trends, let's display the trend in tuberculosis-related deaths for the selected countries.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  filter(country_name %in% c( "Spain", "Sweden", "Netherlands", "Switzerland", "Estonia", "Bulgaria")) %>%  
  ggplot(aes(x = year, y = number_deaths, color = country_name)) +  
  geom_line() +
  coord_cartesian(ylim = c(0,2700)) +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries trends")+
  theme(legend.position = "right") +
  ylab("Number of deaths")


full_dataset %>% 
  filter(country_name %in% c( "Spain", "Sweden", "Netherlands", "Switzerland", "Estonia", "Bulgaria")) %>%  
  ggplot(aes(x = year, y = log(number_deaths), color = country_name)) +  
  geom_line() +
  #coord_cartesian(ylim = c(0,2700)) +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries trends")+
  theme(legend.position = "right") +
  ylab("Number of deaths")


```
```{r}
countries <- c("Spain","Sweden","Netherlands",
               "Switzerland","Estonia","Bulgaria")

colors <- c(
  "Bulgaria"    = "#04A3BDFF",
  "Switzerland" = "#F0BE3DFF",
  "Estonia"     = "#931E18FF",
  "Sweden"      = "#DA7901FF",
  "Spain"       = "#247D3FFF",
  "Netherlands" = "#20235BFF"
)

base <- full_dataset %>%
  filter(country_name %in% countries, number_deaths > 0)

p_lin <- ggplot(base, aes(year, number_deaths, colour = country_name)) +
  geom_line() +
  coord_cartesian(ylim = c(0, 3000)) +
  scale_colour_manual(values = colors) +
  labs(x = "Year", y = "Number of deaths", colour = "Country") +
  guides(colour = guide_legend(nrow = 2, byrow = FALSE)) + 
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    axis.text  = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.text  = element_text(size = 12),
    legend.title = element_text(size = 12)
  )

p_log <- ggplot(base, aes(year, log(number_deaths), colour = country_name)) +
  geom_line() +
  scale_colour_manual(values = colors) +
  labs(x = "Year", y = "Logarithm of the number of deaths", colour = "Country") +
  guides(colour = guide_legend(nrow = 2, byrow = FALSE)) +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    axis.text  = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.text  = element_text(size = 12),
    legend.title = element_text(size = 12)
  )

g_legend <- function(a.gplot) {
  g <- ggplotGrob(a.gplot)
  gtable::gtable_filter(g, "guide-box")
}

legend_shared <- g_legend(p_lin)

p_lin_nolegend <- p_lin + theme(legend.position = "none")
p_log_nolegend <- p_log + theme(legend.position = "none")

grid.arrange(
  gridExtra::arrangeGrob(p_lin_nolegend, p_log_nolegend, ncol = 2),
  legend_shared,
  heights = c(9, 2)
)
```

## Data partitioning utilities

To standardize the modeling process across multiple countries, we define helper structures that facilitate consistent data handling. Specifically, we construct a country_splits hashmap to store the full, training, and testing datasets for each selected country.

The first step is to initialize this structure with the full dataset filtered by country and ordered by year:

```{r, warning=FALSE, message=FALSE}
country_splits <- hashmap()
chosen_countries = c("Spain", "Netherlands", "Sweden", "Switzerland", "Bulgaria", "Estonia")

for (name in chosen_countries) {
  country_splits[[name]][["full"]] <- full_dataset %>% filter(country_name == name) %>%  arrange(year)
}


```

Next, we define the specific number of years to allocate to the testing set for each country. These values were chosen based on the total number of available observations, ensuring approximately 15–20% of the series is reserved for out-of-sample evaluation.

```{r, warning=FALSE, message=FALSE}
test_lengths_per_country = hashmap()

test_lengths_per_country[["Spain"]] = 11
test_lengths_per_country[["Switzerland"]] = 11
test_lengths_per_country[["Sweden"]] = 11
test_lengths_per_country[["Estonia"]] = 11
test_lengths_per_country[["Netherlands"]] = 12
test_lengths_per_country[["Bulgaria"]] = 10
```

Finally, we split the dataset for each country into a training and a testing subset based on the predefined test lengths. This setup is essential for subsequent model fitting and forecast evaluation.

```{r, warning=FALSE, message=FALSE}
for (country in chosen_countries) {
  country_dataset = country_splits[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country[[country]]
  country_splits[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  country_splits[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}

```



## ARIMA model utilities

In this section are presented the different methods for the ARIMA forecast. First of all, new functions to plot the ACF and PACF of the time series are defined, in order to get more visible plots (following the schema of python's library matplt.lib). 

```{r, warning=FALSE, message=FALSE}
custom_acf_plot <- function(ts_data, max_lag = 25) {
  acf_vals <- acf(ts_data, plot = FALSE)
  acf_df <- with(acf_vals, data.frame(
    Lag = lag,
    ACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  acf_df$UCL <- conf
  acf_df$LCL <- -conf
  
  ggplot(acf_df, aes(x = Lag, y = ACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(
    panel.grid   = element_blank(),
    axis.title   = element_text(size = 12), 
    axis.text    = element_text(size = 12)
  ) +
  labs(title = "", x = "Lag", y = "Value")
}

```

```{r, warning=FALSE, message=FALSE}
custom_pacf_plot <- function(ts_data, max_lag = 25) {
  pacf_vals <- pacf(ts_data, plot = FALSE)
  pacf_df <- with(pacf_vals, data.frame(
    Lag = lag,
    PACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  pacf_df$UCL <- conf
  pacf_df$LCL <- -conf
  
  ggplot(pacf_df, aes(x = Lag, y = PACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(
    panel.grid   = element_blank(),
    axis.title   = element_text(size = 12), 
    axis.text    = element_text(size = 12)
  ) +
  labs(title = "", x = "Lag", y = "Value")
}

```

Then, a function to automate the selection of ARIMA models is created. This function systematically evaluates various parameter combinations and reports their corresponding Akaike Information Criterion (AIC) values. This approach allows for an informed and reproducible model selection process, particularly useful when the number of possible $(p,d,q)$ combinations is large and exhaustive testing is impractical.

```{r, warning=FALSE, message=FALSE}

try_all_arima <- function(ar_coef, d_coef, ma_coef, time_series) {
  for (p in ar_coef) {
    for(d in d_coef) {
      for (q in ma_coef) {
        arima_fit <- Arima(time_series, order = c(p, d, q))
        cat("ARIMA(", p, ",", d,"," ,q, ")\n", sep = "")
        print(arima_fit$coef)
        cat("AIC:", AIC(arima_fit), "\n\n")
      }
    }
  }
}
```

This function iterates over all specified combinations of autoregressive, differencing, and moving average orders. For each configuration, it fits an ARIMA model and outputs the estimated parameters along with the AIC value, which serves as the model selection criterion.

Next, we define the get_length function to facilitate quick retrieval of the number of non-missing observations in a specified dataset. Accessing time series lengths manually for each country and subset (full, train, or test) can be cumbersome and error-prone. This utility function simplifies the process by requiring only the country name, the desired subset, and the target variable. It returns the number of valid (non-NA) entries.

```{r, warning=FALSE, message=FALSE}
get_length <- function(country, set, variable) {
  return(length(na.omit(country_splits[[country]][[set]][[variable]])))
}

```

Now, we begin with the core functions defined for the rolling forecast methodology. We begin by defining a model constructor called `fitting_function()`; it takes ARIMA orders $(p,d,q)$ as input and returns a function that fits a model with those parameters to any given time series. 

```{r, warning=FALSE, message=FALSE}
fitting_function <- function(order, use_xreg = FALSE) {
  stopifnot(is.numeric(order) && length(order) == 3)
  if (use_xreg) {
    function(y, xreg) {
      Arima(y, order = order, xreg = as.matrix(xreg))
    }
  } else {
    function(y) Arima(y, order = order)
  }
}
```

The core of the forecasting mechanism is implemented in the function `rolling_forecast()`.

```{r, warning=FALSE, message=FALSE, echo=FALSE}

rolling_forecast_generic <- function(train_series, test_series, order_manual, order_auto, use_xreg = FALSE, xreg_train =
                                       NULL, xreg_test = NULL, horizons = c(1, 3, 5), conf_level = 95) {
  max_steps    <- max(horizons)
  horizons_labels <- paste0("h", horizons)
  test_len     <- length(test_series)

  predictions_matrix <- function() {
    matrix(NA_real_, nrow = test_len, ncol = length(horizons), dimnames = list(NULL, horizons_labels))
    }

  outputs_manual <- list(mean = predictions_matrix(), lower = predictions_matrix(), upper = predictions_matrix())
  outputs_auto   <- list(mean = predictions_matrix(), lower = predictions_matrix(), upper = predictions_matrix())

  fit_manual <- fitting_function(order_manual, use_xreg)
  fit_auto   <- fitting_function(order_auto,   use_xreg)

  rolling_series <- train_series
  if (use_xreg) rolling_xreg <- xreg_train

  for (i in seq_len(test_len)) {
    if (use_xreg) {
      fitted_manual_arima <- fit_manual(rolling_series, rolling_xreg)
      fitted_auto_arima <- fit_auto  (rolling_series, rolling_xreg)

      xreg_forecasting_window <- xreg_test[i:min(i + max_steps - 1, nrow(xreg_test)), , drop = FALSE]

      forecasted_manual <- forecast(fitted_manual_arima, h = nrow(xreg_forecasting_window), xreg = xreg_forecasting_window, level = conf_level)
      forecasted_auto <- forecast(fitted_auto_arima, h = nrow(xreg_forecasting_window), xreg = xreg_forecasting_window, level = conf_level)
    } else {
      fitted_manual_arima <- fit_manual(rolling_series)
      fitted_auto_arima <- fit_auto(rolling_series)

      forecasted_manual <- forecast(fitted_manual_arima, h = max_steps, level = conf_level)
      forecasted_auto <- forecast(fitted_auto_arima, h = max_steps, level = conf_level)
    }
    
    get_level_column <- function(fc_component) {
      if (is.null(dim(fc_component))) return(rep(NA_real_, max_steps))
      level_names <- colnames(fc_component)
      
      lvl_idx <- which(level_names == as.character(conf_level))
      if (length(lvl_idx) == 0) lvl_idx <- 1
      fc_component[, lvl_idx]
    }

    mean_manual  <- forecasted_manual$mean
    lower_manual <- get_level_column(forecasted_manual$lower)
    upper_manual <- get_level_column(forecasted_manual$upper)

    mean_auto  <- forecasted_auto$mean
    lower_auto <- get_level_column(forecasted_auto$lower)
    upper_auto <- get_level_column(forecasted_auto$upper)

    for (h in horizons) {
      idx <- i + h - 1
      if (idx <= test_len) {
        col <- paste0("h", h)
        outputs_manual$mean [idx, col] <- mean_manual[h]
        outputs_manual$lower[idx, col] <- lower_manual[h]
        outputs_manual$upper[idx, col] <- upper_manual[h]

        outputs_auto$mean [idx, col] <- mean_auto[h]
        outputs_auto$lower[idx, col] <- lower_auto[h]
        outputs_auto$upper[idx, col] <- upper_auto[h]
      }
    }

    rolling_series <- c(rolling_series, test_series[i])
    if (use_xreg) rolling_xreg <- rbind(rolling_xreg, xreg_test[i, , drop = FALSE])
  }

  list(manual = outputs_manual, auto = outputs_auto)
}
```

This function simulates a real-time prediction scenario by iteratively refitting the model to an expanding training set. At each iteration, it fits the model to the currently available data and generates forecasts up to a specified horizon (e.g., 1, 3, and 5 years ahead). These predictions are stored in a matrix with dimensions corresponding to the length of the test set and the number of horizons. Importantly, the function only retains the forecasted values that correspond to actual future observations in the test set, ensuring a fair comparison. The following table shows the main idea of the function:
  
```{r, warning=FALSE, message=FALSE, echo=FALSE}
example_tbl <- data.frame(
  Iteration = 1:3,
  Data_used_to_fit = c("1951–2010",
                       "1951–2011",
                       "1951–2012"),
  Forecast_block = c("2011–2015",
                     "2012–2016",
                     "2013–2017"),
  Data_stored = c("h1 → 2011, h3 → 2013, h5 → 2015",
                  "h1 → 2012, h3 → 2014, h5 → 2016",
                  "h1 → 2013, h3 → 2015, h5 → 2017"),
  stringsAsFactors = FALSE
)

print(example_tbl, row.names = FALSE)
```


To visualize the model behavior at different forecast horizons, the function `make_horizon_plots()` creates a series of time series plots. It takes as input the training and testing series, along with two fitting functions (one for the manually specified model and another using `auto.arima()`), and returns separate plots for each forecast horizon (1, 3, and 5 years). In each plot, the actual data are shown in the original scale, alongside the predictions from both models.

```{r, warning=FALSE, message=FALSE}
plot_horizons <- function(test_log_series, forecast_list, horizons = c(1, 3, 5)) {
  
  horizons_labels <- paste0("h", horizons)
  year_vector <- time(test_log_series)
  test_raw <- exp(as.numeric(test_log_series))

  build_long_df <- function(forecasting_matrix, model_label) {
    as.data.frame(forecasting_matrix) %>%
      mutate(year = year_vector) %>%
      pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
      mutate(Value = exp(as.numeric(Value)), Model = model_label)
  }

  df_manual <- build_long_df(forecast_list$manual$mean, "manualARIMA")
  df_auto   <- build_long_df(forecast_list$auto$mean,   "autoARIMA")
  df_obs    <- data.frame(year = year_vector, Horizon = "Observed", Model = "Observed", Value = test_raw)

  plot_df <- bind_rows(df_obs, df_manual, df_auto) %>%
    mutate(Horizon = factor(Horizon, levels = c(horizons_labels, "Observed")))

  col_map <- c(Observed = "#1f77b4", autoARIMA = "#6ba292", manualARIMA = "#ff7f0e")
  lty_map <- c(Observed = "solid",   autoARIMA = "dashed", manualARIMA = "dashed")

  make_single_plot <- function(h_label) {
    ggplot(filter(plot_df, Horizon == h_label | Model == "Observed"),
           aes(x = year, y = Value, colour = Model, linetype = Model)) +
      geom_line(na.rm = TRUE) +
      scale_colour_manual(values = c(Observed = "#1f77b4", autoARIMA = "#6ba292", manualARIMA = "#ff7f0e")) +
      scale_linetype_manual(values = c(Observed = "solid",   autoARIMA = "dashed", manualARIMA = "dashed")) +
      labs(title = "",
           x = "Year", y = "Number of deaths",
           colour = "Series", linetype = "Series") +
      theme_minimal(base_size = 13)
  }

  plots <- lapply(horizons_labels, make_single_plot)
  names(plots) <- horizons_labels
  #plots
  return(list("plots"=plots, "df"=plot_df))
}
#paste("Forecast horizon:", h_label)

```

In addition to visual inspection, we provide quantitative tools to assess forecast accuracy. The function `compute_accuracy_table()` computes key performance metrics such as Mean Error (ME), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Percentage Error (MPE) and Mean Absolute Percentage Error (MAPE).

```{r, warning=FALSE, message=FALSE}
compute_accuracy_table <- function(test_log, forecast_list, horizons = c(1, 3, 5)) {
  
  horizons_labels <- paste0("h", horizons)
  rows <- list()
  
  test_orig <- exp(test_log)
  
  for (model_name in names(forecast_list)) {
    predicted_log <- forecast_list[[model_name]]$mean
    predicted_orig <- exp(predicted_log)  
    
    for (h_lab in horizons_labels) {
      keep <- !is.na(predicted_orig[, h_lab])
      rows[[paste(model_name, h_lab, sep = "_")]] <- data.frame(
        Model = paste0(ifelse(model_name == "auto", "autoARIMA", "manualARIMA"), "-", h_lab),
        ME    = mean(test_orig[keep] - predicted_orig[keep, h_lab]),
        RMSE  = rmse(test_orig[keep], predicted_orig[keep, h_lab]),
        MAE   = mae (test_orig[keep], predicted_orig[keep, h_lab]),
        MAPE  = mape(test_orig[keep], predicted_orig[keep, h_lab]) * 100,
        row.names = NULL
      )
    }
  }
  
  dplyr::bind_rows(rows)
}
```

Finally, function `run_country_forecast()` helps getting the computed information of a specific country. 

```{r, warning=FALSE, message=FALSE}
run_country_forecast <- function(country, start_year, order_manual,
                                 order_auto, horizons = c(1, 3, 5), use_xreg = FALSE) {
  
  if (use_xreg) {
    
    train_raw <- countries_short[[country]]$train$number_deaths
    test_raw  <- countries_short[[country]]$test$number_deaths

    train_ts <- ts(log(train_raw), start = start_year, frequency = 1)
    test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)

    xreg_train <- as.matrix(data.frame(
      population = ts(log(countries_short[[country]]$train$population), start = start_year, frequency = 1),
      gdp_capita = ts(log(countries_short[[country]]$train$gdp_capita), start = start_year, frequency = 1)
    ))

    xreg_test <- as.matrix(data.frame(
      population = ts(log(countries_short[[country]]$test$population), start = end(train_ts)[1] + 1, frequency = 1),
      gdp_capita = ts(log(countries_short[[country]]$test$gdp_capita), start = end(train_ts)[1] + 1, frequency = 1)
    ))

    fc_list <- rolling_forecast_generic(train_ts, test_ts, order_manual, order_auto,
                                        use_xreg = TRUE, xreg_train = xreg_train, xreg_test = xreg_test,
                                        horizons = horizons)
  } else {
    
    train_raw <- country_splits[[country]]$train$number_deaths
    test_raw  <- country_splits[[country]]$test$number_deaths

    train_ts <- ts(log(train_raw), start = start_year, frequency = 1)
    test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)

    fc_list <- rolling_forecast_generic(train_ts, test_ts, order_manual, order_auto,
                                        use_xreg = FALSE, horizons = horizons)
  }

  accuracy_tbl <- compute_accuracy_table(test_ts, fc_list, horizons = horizons)

  plots <- plot_horizons(test_ts, fc_list, horizons = horizons)

  list(metrics = accuracy_tbl, plots = plots, forecasts = fc_list)
}

```

This function is required in order to get the boundaries of the confidence intervals:

```{r}
calc_exp_bounds <- function(res, model, horizon) {
  model   <- as.character(model)
  horizon <- as.integer(horizon)

  lower_vals <- res$forecasts[[model]][["lower"]][ , horizon]
  lower_vals <- exp(lower_vals[!is.na(lower_vals)])

  upper_vals <- res$forecasts[[model]][["upper"]][ , horizon]
  upper_vals <- exp(upper_vals[!is.na(upper_vals)])

  c(min = min(lower_vals), max = max(upper_vals))
}
```


## ARIMA models

In this section, we analyze the temporal dynamics of tuberculosis-related mortality across the selected European countries using ARIMA models. Each country will be studied individually, beginning with an exploratory analysis of the log-transformed mortality data. Model parameters (p,d,q) will be selected based on empirical diagnostics such as the ACF/PACF plots and the AIC. The adequacy of each model will be verified through residual analysis.

### Spain

We begin our analysis with the Spanish dataset, which spans from 1951 to 2021 and comprises 71 annual observations. Given the long time span and the observed declining trend in raw counts, a logarithmic transformation is applied to stabilize variance and linearize the trend. The figure below shows the log-transformed training time series for tuberculosis mortality in Spain.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain <- ts(log(country_splits[["Spain"]]$train$number_deaths), start = 1951,  frequency = 1)
test_spain <- ts(log(country_splits[["Spain"]]$test$number_deaths), start = 2011,  frequency = 1)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Spain"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Spain"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

In order to formally assess whether the series is stationary, we apply the Augmented Dickey-Fuller (ADF) test:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain)
```

As expected, the high $p$-value indicates that we fail to reject the null hypothesis, which suggests that the series is non-stationary. In this case, applying a first-order difference is recommended.

We can apply the ADF test to the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain %>% diff())
```

The test $p$-value ensures the stationarity of the time series. Now, we check the ACF and PACF of the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_spain %>% diff())
custom_pacf_plot(train_spain %>% diff())

```

Neither the ACF nor the PACF show any ignificant spikes—autocorrelations at higher lags lie well within the confidence bounds. This suggest that the series present no AR or MA structure left after the differences. We first fit the auto.arima model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_spain_auto <- auto.arima(train_spain, test = "adf")

summary(fit_spain_auto)

```
The auto.arima() procedure suggests an ARIMA(0,1,0) specification, indicating that the series follows a random walk without drift. The corresponding AIC is relatively low ($-104.73$), supporting the adequacy of this simple model. Moreover, the in-sample performance is satisfactory, with a root mean squared error (RMSE) of $0.096$ and a mean absolute percentage error (MAPE) below 1% on the log-transformed training set.

Nonetheless, in pursuit of a potentially more flexible and interpretable model, we consider a broader set of ARIMA specifications that include either an AR(1) or MA(1) component. This aims to assess whether a slightly more complex model can better capture the underlying dynamics, or whether the series can indeed be sufficiently described as a random walk process. 

We apply the try_all_arima using $p,q \in \{0,1\}$:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ma_coef = c(0,1)
ar_coef = c(0,1)

try_all_arima(ar_coef, 1, ma_coef, train_spain)
```
The model with the lowest AIC (specifically, with a value of $-100.25$) is the ARIMA($1,1,1$). We proceed with the residuals diagnostics of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_111 <- Arima(train_spain, order = c(1,1,1))
summary(fit_spain_111)
```

First, the auto.arima: 
```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_spain_auto))
```
Just by checking the residuals distribution function on the `checkresiduals` plot, it is clear that the residuals of the autogenerated model do not pass the Shapiro-Wilk normality test. 

Then, the residuals of the manual model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_111 %>% 
  forecast::checkresiduals()

shapiro.test(residuals(fit_spain_111))
```

The residuals of the manual model do not pass neither the normality assumption. However, we proceed with the forecasting step.

First, we validate the accuracy of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arima_spain <- run_country_forecast("Spain", start_year = 1951, order_manual = c(1,1,1),
                          order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = FALSE)

results_arima_spain$metrics   

```

The manual ARIMA model consistently outperforms the automatic specification across all horizons. In particular, it achieves substantially lower RMSE and MAE values, especially for medium- and long-term forecasts. For example, at horizon $h=5$, the manual model yields an RMSE of 36.88 and a MAPE of 11.65%, whereas the automatic model reaches 78.31 and 31.49%, respectively. Moreover, the manual model maintains smaller forecast biases (ME) across horizons, suggesting a more balanced and accurate predictive behavior.

Now, we can plot the forecasting results:
```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arima_spain$plots
```

Notably, both models tend to slightly overestimate the first forecasted value. Across all three horizons, the manual ARIMA provides more accurate approximations than the automatically selected model. This is particularly evident in the five-step-ahead forecasts, where the autoARIMA overpredicts by up to 50 tuberculosis-related deaths.

```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}

calc_exp_bounds(results_arima_spain, "auto", 1)
calc_exp_bounds(results_arima_spain, "manual", 1)

calc_exp_bounds(results_arima_spain, "auto", 2)
calc_exp_bounds(results_arima_spain, "manual",  2)

calc_exp_bounds(results_arima_spain, "auto",  3)
calc_exp_bounds(results_arima_spain, "manual",  3)
```




### The Netherlands

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_netherlands <- ts(log(country_splits[["Netherlands"]]$train$number_deaths), start = 1950,  frequency = 1)
test_netherlands <- ts(log(country_splits[["Netherlands"]]$test$number_deaths), start = 2011, frequency = 1)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Netherlands"]]$full$number_deaths), start = 1950,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Netherlands"]]$full$number_deaths, start = 1950, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```
In order to select the model, first, we study the order of differences needed to ensure stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_netherlands %>% diff())
```

The series need a first order difference to get stationary. We check the ACF and PACF plots:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_netherlands %>% diff())
custom_pacf_plot(train_netherlands %>% diff())
```
After apply a first order difference, the series ACF plot (first) shows a significant spike at lag 3, and the PACF plot shows significant spikes at lags 3 and 7. 

Let's see which model suggests the auto.arima function:
```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto <- auto.arima(train_netherlands, test = "adf" )
summary(fit_netherlands_auto)
```
The auto generated model is the ARIMA(0,0,5), meaning no differences are required. For the manual model, we apply the try_all_arima function

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1,3)
q <- c(0,1,3)

try_all_arima(p,1,q, train_netherlands)

```
The best model, which minimizes the AIC ($-54.25$) is the ARIMA(1,1,3). We now check the assumptions on the residuals of the both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_auto))
```

The residuals for the autogenerate model do not satisfy the hypothesis. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_113 <- Arima(train_netherlands, order = c(1,1,3))
summary(fit_netherlands_113)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_113 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_113))
```

On the contrary, the residuals of the manual model satisfy the no autocorrelation assumption, however, the normality is not ensured ($p$-value of $0.04$). We begin the forecast step:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_netherlands_arima <- run_country_forecast("Netherlands", start_year = 1950, order_manual = c(1,1,3),
                          order_auto = c(0,0,5), horizons = c(1,3,5), use_xreg = FALSE)

results_netherlands_arima$metrics   

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_netherlands_arima$plots   

```
The auto.arima model is clearly inadequate for this series: the large ME values reveal a systematic tendency to over-forecast, and the three- and five-step MAPE values exceed 200 %, signalling a very poor fit. By contrast, the manually specified model yields much smaller error metrics and appears to capture the underlying trend of the series.

### Switzerland

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_switzerland <- ts(log(country_splits[["Switzerland"]]$train$number_deaths), start = 1951,  frequency = 1)
test_switzerland <- ts(log(country_splits[["Switzerland"]]$test$number_deaths), start = 2011, frequency = 1)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Switzerland"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Switzerland"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```
We check the stationary of the series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_switzerland)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
kpss.test(train_switzerland)
```
Notably, the series passes the ADF test without differencing, suggesting stationarity. However, the visual inspection reveals a clear downward trend, which contradicts this result and raises concerns about potential non-stationarity. To clarify this discrepancy, we applied the KPSS test, which assumes stationarity as the null hypothesis. The KPSS result ($p$-value of $0.01$) leads us to reject stationarity, thereby supporting the use of first-order differencing before model fitting. 

Next, we check the ACF and PACF of the first order differenced time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_switzerland %>% diff())
custom_pacf_plot(train_switzerland %>% diff())
```
The series, after a first difference, does not present any temporal structure left. We check the auto.arima function:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto <- auto.arima(train_switzerland , test = "adf")
summary(fit_switzerland_auto)
```
The selected model of the auto.arima function is ARIMA(0,1,1). Then, for the manual model, as the series seems to behave as a $0,1,0$ (random walk), we apply the try_all_arima in order to study if another model should present better performance.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1)
d <- c(0,1)
q <- c(0,1)

try_all_arima(p,d,q, train_switzerland)
```
We will study the ARIMA($1,1,1$). 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_switzerland_111 <- Arima(train_switzerland, order = c(1,1,1))
summary(fit_switzerland_111)
```
Now it is time to check the residuals diagnostics of both models, beginning with the automatic one:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_auto))
```
The residuals for the autogenerate model do not satisfy the normality hypothesis.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_111 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_111))
```
Neither the residuals of the manually selected model seem to distribute normally. We begin the forecast step

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_switzerland_arima <- run_country_forecast("Switzerland", start_year = 1951, order_manual = c(1,1,1),
                          order_auto = c(0,1,1), horizons = c(1,3,5), use_xreg = FALSE)

results_switzerland_arima$metrics   

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_switzerland_arima$plots   

```
Although any of both models ensures the normality of residuals, both models present quite well-fitted model features; however, the manual model seems to outperform in all three forecast horizons.

### Sweden

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_sweden<- ts(log(country_splits[["Sweden"]]$train$number_deaths), start = 1951,  frequency = 1)
test_sweden <- ts(log(country_splits[["Sweden"]]$test$number_deaths), start = 2012, frequency = 1)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Sweden"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Sweden"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```
We check first the order of differences required to ensure stationarity:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_sweden %>% diff())
```
We need to difference the series once to ensure stationarity. Now, we check the ACF and PACF of the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_sweden %>% diff())
custom_pacf_plot(train_sweden %>% diff())

```
The ACF and PACF show significant spikes at lag 8, both. However, a simpler model should also be studied. First, let's check which is the auto.arima model selected:


```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto <- auto.arima(train_sweden, test = "adf" )
summary(fit_sweden_auto)
```
The auto generated model is the ARIMA(0,1,1), with an AIC of $-44.08$. Now, we study the manual model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1)
q <- c(0,1)

try_all_arima(p,1,q, train_sweden)
```
The model that minimizes the AIC is ARIMA(1,1,1), meaning the series depends on eight past values and adds a moving average component.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_111 <- Arima(train_sweden, order = c(1,1,1))
summary(fit_sweden_111)
```

We need to further check the residuals of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_auto))
```
The residuals for the autogenerate model satisfy both assumptions. Now, we check the manual model:


```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_111 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_111))
```
As the residuals do not ensure the no autocorrelation assumption, a new model should be applied. We study a higher order parameters:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1,8)
q <- c(0,1,8)

try_all_arima(p,1,q, train_sweden)
```

It seems that an ARIMA($8,1,0$) could fit well. We check the residuals diagnostics:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_sweden_810 <- Arima(train_sweden, order = c(8,1,0))
fit_sweden_810 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_810))
```

Residuals now present no autocorrelation left; however, they do not distribute normally. We begin the forecast step.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_sweden_arima <- run_country_forecast("Sweden", start_year = 1951, order_manual = c(8,1,0),
                          order_auto = c(0,1,1), horizons = c(1,3,5), use_xreg = FALSE)

results_sweden_arima$metrics   

```
```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_sweden_arima$plots   

```
The auto.arima model seems to outperform the manual one in the one-step-ahead forecasts, in both accuracy metrics and visual forecasts. However, as the horizon increases, the manual one seems to outperform the auto.arima selected model.

### Bulgaria

Now, we study Bulgaria data. As seen in the introduction, Bulgaria has a different trend for number_deaths series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_bulgaria <- ts(log(country_splits[["Bulgaria"]]$train$number_deaths), start = 1964, end = 2011,  frequency = 1)
test_bulgaria <- ts(log(country_splits[["Bulgaria"]][["test"]][["number_deaths"]]), start = 2012, frequency = 1)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}


p1 <- plot_ts(ts(log(country_splits[["Bulgaria"]]$full$number_deaths), start = 1964,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Bulgaria"]]$full$number_deaths, start = 1964, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

We first use the ADF test to assess whether the series is stationary or not.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria )
```
Without any difference, the series is not stationary. After two differences, we get stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria %>% diff(differences = 2))
```

Let's see which ARIMA order proposes the auto.arima() function.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto <- auto.arima(train_bulgaria, test = "adf")

summary(fit_bulgaria_auto)
```

The model proposed is an ARIMA(0,1,0) with drift, that has an AIC of $-78.32$. In order to determine an alternative model, we check the ACF and PACF plots of the time series.

First, we check the ACF and PACF of the first-order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_bulgaria %>% diff())
custom_pacf_plot(train_bulgaria %>% diff())
```
After one difference, the series does not present any structure left, justifying the selection criteria of the auto.arima function. Now, we check the two-order differences ACF and PACF:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_bulgaria %>% diff(differences = 2))
custom_pacf_plot(train_bulgaria %>% diff(differences = 2))
```
The ACF now shows a single first significant lag, whether the PACF shows an increasing pattern over the first few lags. Now, we apply the try_all_arima to find the best model:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1,2)
d <- c(2)
q <- c(0,1)

try_all_arima(p,d,q, train_bulgaria)
```
The model with the lowest AIC (of $-72.35$) is ARIMA($0,2,1$). Now, we check the residuals diagnostic of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_021 <- Arima(train_bulgaria, order = c(0,2,1))
summary(fit_bulgaria_021)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_021 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_021))
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_auto))
```

The residuals of both models satisfy the assumptions on residuals. We begin the forecast step by checking the accuracy metrics of both models. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arima_bulgaria <- run_country_forecast("Bulgaria", start_year = 1964, order_manual = c(0,2,1),
                          order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = FALSE)

results_arima_bulgaria$metrics   

```
In all forecast horizons considered, the manually specified ARIMA models outperformed their automated counterparts, showing lower overall errors and less systematic over-forecasting. The negative mean error values across models indicate a consistent tendency to overestimate tuberculosis deaths, but this bias was less pronounced in the manual models (e.g., –9.2 vs –11.5 at h = 1; –48.4 vs –51.8 at h = 5). RMSE and MAE were also smaller for manual models at every horizon (e.g., RMSE 15.0 → 51.4 vs 16.0 → 54.1; MAE 12.5 → 48.4 vs 12.7 → 51.8). Likewise, MAPE increased with forecast horizon but remained consistently lower for the manual model, staying below 35% through h = 3 and rising more gradually by h = 5 (59.2% vs 62.8%). 
```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arima_bulgaria$plots

```
```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}
calc_exp_bounds(results_arima_bulgaria, "auto", 1)
calc_exp_bounds(results_arima_bulgaria, "manual", 1)

calc_exp_bounds(results_arima_bulgaria, "auto", 2)
calc_exp_bounds(results_arima_bulgaria, "manual",  2)

calc_exp_bounds(results_arima_bulgaria, "auto",  3)
calc_exp_bounds(results_arima_bulgaria, "manual",  3)

```



### Estonia

Finally, Estonia is studied. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adjusted_estonia_data <- country_splits[["Estonia"]]

train_estonia <- ts(log(country_splits[["Estonia"]]$train$number_deaths), start = 1985, end = 2011,  frequency = 1)
test_estonia <- ts(log(country_splits[["Estonia"]]$test$number_deaths), start = 2012, frequency = 1)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

p1 <- plot_ts(ts(log(country_splits[["Estonia"]]$full$number_deaths), start = 1985,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Estonia"]]$full$number_deaths, start = 1985, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

Let's see which model is suggested by the auto.arima function:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_autoarima_estonia <- auto.arima(train_estonia, test = "adf")

summary(fit_autoarima_estonia)
```

The model proposed is ARIMA(0,1,0), with an AIC of 5.52, meaning the series behaves as a white noise without drift. To further improve this model, to make a more flexible and interpretable model, we check the main characteristics of the series.


```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia)

```

The series is not stationary as observed in the initial plot and proved by the ADF test. Now, we check if after a differenced applied, we get stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia %>% diff())

```
The first order difference is not sufficient to get the series stationary; in fact, second order differences is still not sufficient. We will not study the third-order differenced.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia %>% diff(differences = 3))

```

We can check the ACF and PACF plots of both approaches:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_estonia %>%  diff())
custom_pacf_plot(train_estonia %>%  diff())
```
After a difference, neither the ACF (left) nor the PACF (right) show any significant lags (this is the justification of the autogenerated selected model).

Now, we check the ACF and PACF of the second order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_estonia %>%  diff(differences = 2))
custom_pacf_plot(train_estonia %>%  diff(differences = 2))
```
The ACF shows a spike at lag 1 that lies outside the confidence boundaries. This behavior is presented too in the PACF plot, but with a negative spike.

We study the best model following the results obtained:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1)
d <- c(1,2)
q <- c(0,1)

try_all_arima(p,d,q,train_estonia)
```
The model with the lowest AIC is an ARIMA(1,1,0), meaning that after a first order difference, the series still depends on the past value.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_estonia_110 <- Arima(train_estonia, order = c(1,1,0))

summary(fit_arima_estonia_110)
```

Now, we need to check the residuals assumptions on both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_estonia_110  %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arima_estonia_110))
```

The normality assumption is not guaranteed in the manual fitted model. Neither in the autogenerated one, as seen next:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_autoarima_estonia  %>% forecast::checkresiduals()

shapiro.test(residuals(fit_autoarima_estonia))
```
We can check the accuracy metric on test data of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arima_estonia<- run_country_forecast("Estonia", start_year = 1985, order_manual = c(1,1,0),
                          order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = FALSE)




results_arima_estonia$metrics   

results_arima_estonia$plots$df


```
At all forecast horizons, both the manual and automated ARIMA models showed a systematic tendency to over-forecast tuberculosis deaths, as indicated by negative mean errors. However, the extent of over-forecasting was slightly greater for the manual model at each step (e.g., ME –3.3 vs –3.1 at h = 1; –13.4 vs –13.1 at h = 5). Despite this, overall forecast accuracy was generally comparable between the two approaches. The manual ARIMA exhibited marginally lower root mean square errors (RMSE) at h = 3 and h = 5 (10.2 vs 10.1; 13.5 vs 13.3, respectively), while absolute errors (MAE) were nearly identical. Percentage errors (MAPE), however, revealed a clear difference: the manual model yielded consistently lower MAPE at each horizon (e.g., 30.6% vs 34.1% at h = 1), suggesting better relative accuracy in proportion to the observed values. Nevertheless, MAPE values above 50% from h = 3 onward highlight the inherent challenge of longer-term TB mortality forecasting, regardless of model selection strategy.

The plots of the results are provided next:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arima_estonia$plots 

```

```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}

calc_exp_bounds(results_arima_estonia, "auto", 1)
calc_exp_bounds(results_arima_estonia, "manual", 1)

calc_exp_bounds(results_arima_estonia, "auto", 2)
calc_exp_bounds(results_arima_estonia, "manual",  2)

calc_exp_bounds(results_arima_estonia, "auto",  3)
calc_exp_bounds(results_arima_estonia, "manual",  3)
```

## ARIMAX models

We have seen that ARIMA models are quite simple in order to do a well-suited forecast for our studied series. In this section we will study ARIMAX models; ARIMAX models are ARIMA models that include some exogenous variables in order to get better forecastings rather than basic ARIMA. In our study, we will consider two exogenous variables: Gross Domestic Product per capita and the country population.

First, we visualize these series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables <- full_dataset %>% 
  filter(country_name %in% c("Spain", "Switzerland", "Sweden", "Netherlands", "Estonia", "Bulgaria")) %>% 
  select(year, country_name, population,  gdp_capita) %>% 
  arrange(year)

```

We begin analysing the Population variable.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables %>%  
  ggplot(aes(x = year, y = population/1000000, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries population trends")+
  theme(legend.position = "right") +
  ylab("Population (in millions)")

```

In stark contrast with the other countries, Spain population has a strong increasing trend, climbing from around 28 million in 1950 to nearly 48 million by 2020. The Netherlands also grows steadily, from about 10 million to roughly 18 million. Sweden’s population increases more modestly, moving from approximately 7 million to just over 10 million, while Switzerland rises from about 5 million to nearly 9 million over the same period.

In contrast, Bulgaria peaks near 9 million in the 1980s before gradually declining to about 7 million by 2020, and Estonia remains the smallest, hovering around 1.7 million in 1980 but falling slightly to around 1.3 million by 2020. The plot clearly highlights Spain’s large and sustained growth, moderate increases for Northern and Western European countries, and population declines in Eastern Europe.

Now, let's visualize the GDP per capita tendencies:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
exogenous_variables %>%  
  ggplot(aes(x = year, y = gdp_capita, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries GDP per capita trends")+
  theme(legend.position = "right") +
  ylab("GDP per capita (in current U.S. dollars)")
```

Now, the outlook is quite different; Switzerland leads the list, climbing from around \$2,000 in 1960 to over \$90,000 by 2020, with sharp surges in the late 1990s and post-2005. Following Switzerland, the Netherlands and Sweden follow a similar upward trajectory. Spain increases more modestly, from under \$1,000 to a peak of around \$35,000 by 2008, then levels out in the \$25,000–\$30,000 range.Estonia lags until independence—remaining near zero through the Soviet era—then surges after 1992 from around \$2,000 to approximately \$25,000 by 2020. Bulgaria also starts below \$1,000, grows gradually through the 1980s, dips in the 1990s, and then climbs to roughly \$12,000 by 2020.

Overall, Switzerland, Sweden, and the Netherlands display long-term, high-income growth; Spain shows moderate growth with a plateau post-2008; and the Eastern European countries (Estonia and Bulgaria) demonstrate rapid catch-up following post-1990 transitions.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries <- c("Spain","Sweden","Netherlands",
               "Switzerland","Estonia","Bulgaria")

colors <- c(
  "Bulgaria"    = "#04A3BDFF",
  "Switzerland" = "#F0BE3DFF",
  "Estonia"     = "#931E18FF",
  "Sweden"      = "#DA7901FF",
  "Spain"       = "#247D3FFF",
  "Netherlands" = "#20235BFF"
)

base2 <- exogenous_variables %>%
  filter(country_name %in% countries)

p_pop <- ggplot(base2,
                aes(year, population/1e6, colour = country_name)) +
  geom_line() +
  scale_colour_manual(values = colors) +
  labs(x = "Year", y = "Population (millions)", colour = "Country") +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    axis.text  = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.text  = element_text(size = 12),
    legend.title = element_text(size = 12)
  )

p_gdp <- ggplot(base2,
                aes(year, gdp_capita, colour = country_name)) +
  geom_line() +
  scale_colour_manual(values = colors) +
  labs(x = "Year", y = "GDP per capita (USD)", colour = "Country") +
  theme_minimal(base_size = 13) +
  theme(
    legend.position = "bottom",
    axis.text  = element_text(size = 12),
    axis.title = element_text(size = 12),
    legend.text  = element_text(size = 12),
    legend.title = element_text(size = 12)
  )

g_legend <- function(a.gplot) {
  g <- ggplotGrob(a.gplot)
  gtable::gtable_filter(g, "guide-box")
}

legend_shared <- g_legend(p_pop)

p_pop_nolegend <- p_pop + theme(legend.position = "none")
p_gdp_nolegend <- p_gdp + theme(legend.position = "none")

grid.arrange(
  gridExtra::arrangeGrob(p_pop_nolegend, p_gdp_nolegend, ncol = 2),
  legend_shared,
  nrow = 2,
  heights = c(8, 3)
)
```


Before beginning the ARIMAX section, it is important to give special attention to the length of each of the variables, just to ensure that the studied variable (number_deaths) length coincides with the covariables length.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_all_lengths <- function(countries) {
  data.frame(
    Country = countries,
    number_deaths_length = sapply(countries, function(cn) get_length(cn, "full", "number_deaths")),
    population_length = sapply(countries, function(cn) get_length(cn, "full", "population")),
    gdp_capita_length = sapply(countries, function(cn) get_length(cn, "full", "gdp_capita")),
    row.names = NULL
  )
}

lengths_df <- get_all_lengths(chosen_countries)

lengths_df

```

It is necessary that all variable have the same length; we create a function in order to automate this step.

```{r}

slice_country_data <- function(country, start_year) {
  df_full <- country_splits[[country]][["full"]]
  df_filtered <- df_full %>%
    filter(year >= start_year) %>%
    arrange(year)  

  return(df_filtered)
}

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short <- hashmap()

countries_short[["Spain"]][["full"]] <- slice_country_data("Spain", 1960)
countries_short[["Netherlands"]][["full"]] <- slice_country_data("Netherlands", 1960)
countries_short[["Sweden"]][["full"]] <- slice_country_data("Sweden", 1960)
countries_short[["Switzerland"]][["full"]] <- slice_country_data("Switzerland", 1960)
countries_short[["Estonia"]][["full"]] <- slice_country_data("Estonia", 1993)
countries_short[["Bulgaria"]][["full"]] <- slice_country_data("Bulgaria", 1980)


```

Now, we need to divide these new series into a training and a testing set. We will do the split, ensuring that the 80% of the data is used for training.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
test_lengths_per_country_short = hashmap()

test_lengths_per_country_short[["Spain"]] = 12
test_lengths_per_country_short[["Switzerland"]] = 12
test_lengths_per_country_short[["Sweden"]] = 12
test_lengths_per_country_short[["Estonia"]] = 6
test_lengths_per_country_short[["Netherlands"]] = 12
test_lengths_per_country_short[["Bulgaria"]] = 8
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
for (country in chosen_countries) {
  country_dataset = countries_short[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country_short[[country]]
  countries_short[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  countries_short[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}


```

Now that we have prepared the dataset, we can begin the ARIMAX study.

### Spain

We begin studying Spain data. First, let's plot all three variables (number_deaths, population and gdp_capita) in the same plot.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_spain_arimax_plot <- data.frame(
  Year = countries_short[["Spain"]][["full"]]$year,
  number_deaths = countries_short[["Spain"]][["full"]]$number_deaths,
  population = countries_short[["Spain"]][["full"]]$population,
  gdp_capita = countries_short[["Spain"]][["full"]]$gdp_capita
)

df_spain_arimax_plot

train_spain_short <- ts(log(countries_short[["Spain"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

test_spain_short <- ts(log(countries_short[["Spain"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_spain_train <- data.frame(
  population = ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)

xreg_spain_test <- data.frame(
  population = ts(log(countries_short[["Spain"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_spain <- df_spain_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_spain$log_deaths, df_spain$log_gdp), na.rm = TRUE)

df_spain <- df_spain %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))   # población “dibujable”

ggplot(df_spain, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2010, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_spain$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```
We need to further analyze the main characteristics of the three series. We begin assessing the stationary condition using the ADF test:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population)
adf.test(xreg_spain_train$gdp_capita)

```

Neither the population nor the GDP per capita series are stationary. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population %>% diff())
adf.test(xreg_spain_train$gdp_capita %>% diff())

```

After a first order difference, series still not stationary. In fact, is not but after three differences that the series get stationary. However, and due to the consequences of high order differences explained in the memory, we are going to analyze both 1 or 2 differences only.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_spain_train$population %>% diff(differences = 3))
adf.test(xreg_spain_train$gdp_capita %>% diff())

```

We plot the ACF and PACF of both approaches, of each series.

1. Population series, first order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$population %>% diff())
custom_pacf_plot(xreg_spain_train$population %>% diff())

```

Results: The PACF reveals two significant lags at the beginning of the series, with additional spikes at lags 7 and 11. The ACF exhibits a slow decay, suggesting that the series may remain non-stationary after a single differencing.

2. Population series, two order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$population %>% diff(differences =2))
custom_pacf_plot(xreg_spain_train$population %>% diff(differences = 2))

```
Results: The ACF displays prominent spikes at lags 1, 6, and 7. The PACF similarly shows significant spikes at lags 1 and 6, while other lags fall within the confidence bounds. These patterns are more consistent with stationarity.

3. GDP per capita series, first order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_spain_train$gdp_capita %>% diff())

```
Results: The PACF exhibits significant spikes at lags 1 and 15. The ACF also shows notable autocorrelations at both the first and last lags, suggesting possible seasonality or long-range dependence.

4. GDP per capita series, two order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_spain_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_spain_train$gdp_capita %>% diff(differences = 2))

```
Results: The PACF includes a significant negative spike at lag 3, while the rest remain within the confidence bounds. The ACF shows no significant autocorrelations, indicating that the second-order differencing may have adequately removed autocorrelated structure from the series.

We first study which model recomends the auto.arima function

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_auto_arimax_spain <- auto.arima(train_spain_short, xreg= as.matrix(xreg_spain_train ), test = "adf")

summary(fit_auto_arimax_spain)
```
The function suggested an ARIMAX(1,1,0), that presents an AIC of $-120$. Now, to choose the manual ARIMA, we could try the try_all_arima function and study which model presents better AIC value.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
p <- c(0,1)
d <- c(1,2)
q <- c(0,1)

try_all_arima(p,d,q, train_spain_short)
```
The model selected is an ARIMA($1,2,1$), with an AIC of $-117.66$. We check the residuals of both models.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_manual_arimax_spain <- Arima(train_spain_short, order = c(1,2,1), xreg= as.matrix(xreg_spain_train ) )
summary(fit_manual_arimax_spain)
fit_auto_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_auto_arimax_spain))
```

The autogenerated model satisfies the assumption on the residuals. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_manual_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_manual_arimax_spain))
```
The manual model, too. Now, we check the accuracy measures:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_spain <- run_country_forecast("Spain", start_year = 1960, order_manual = c(1,2,1),
                            order_auto = c(1,1,0), horizons = c(1,3,5), use_xreg = TRUE)
results_arimax_spain$metrics
```

The manually adjusted model consistently outperforms the automatic one across all error metrics and forecast horizons. In particular, the mean error of the automatic model is notably more negative across all horizons, reflecting a severe overestimation bias. For example, at horizon $h=5$, the automatic model overpredicts by more than 70 deaths on average, while the manual model maintains a considerably smaller bias of approximately $-7.66$.

Regarding scale-dependent metrics, such as RMSE and MAE, the manual model achieves significantly lower values—especially at $h=3$ and $h=5$—indicating more accurate point forecasts. Similarly, MAPE values show that the relative forecast error of the manual model remains below $11%$ at all horizons, compared to nearly $30%$ for the automatic model at $h=5$.

These results confirm the superiority of the manual ARIMA specification in both accuracy and stability, particularly in medium- and long-term forecasts. Moreover, the progressive deterioration of the automatic model’s accuracy with increasing horizon highlights its limited predictive capacity for multi-step forecasts.

The results can be visualized next:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arimax_spain$plots
```

```{r message=FALSE, warning=FALSE, results='hide'}
calc_exp_bounds(results_arimax_spain, "auto", 1)
calc_exp_bounds(results_arimax_spain, "manual", 1)

calc_exp_bounds(results_arimax_spain, "auto", 2)
calc_exp_bounds(results_arimax_spain, "manual",  2)

calc_exp_bounds(results_arimax_spain, "auto",  3)
calc_exp_bounds(results_arimax_spain, "manual",  3)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df1 <- results_arima_spain$plots$df  

df2 <- results_arimax_spain$plots$df
df1$Type ="ARIMA"
df2$Type = "ARIMAX"

dfT <- rbind(df1, df2)

observed_data <- dfT %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT$Horizon),
  Type = unique(dfT$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2 <- dfT %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2 <- dfT2 %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2$Model <- factor(dfT2$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )
```


### The Netherlands

Let's continue with the Netherlands.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_netherlands_arimax_plot <- data.frame(
  Year = countries_short[["Netherlands"]][["full"]]$year,
  number_deaths = countries_short[["Netherlands"]][["full"]]$number_deaths,
  population = countries_short[["Netherlands"]][["full"]]$population,
  gdp_capita = countries_short[["Netherlands"]][["full"]]$gdp_capita
)

train_netherlands_short <- ts(log(countries_short[["Netherlands"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)
test_netherlands_short <- ts(log(countries_short[["Netherlands"]][["test"]][["number_deaths"]]), start = 2011, frequency = 1)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_netherlands_train <- data.frame(
  population = ts(log(countries_short[["Netherlands"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)

xreg_netherlands_test <- data.frame(
  population = ts(log(countries_short[["Netherlands"]][["test"]][["population"]]), start = 2011, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["test"]][["gdp_capita"]]), start = 2011, frequency = 1)
)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_netherlands <- df_netherlands_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_netherlands$log_deaths, df_netherlands$log_gdp), na.rm = TRUE)

df_netherlands <- df_netherlands %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))   # población “dibujable”

ggplot(df_netherlands, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2011, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_netherlands$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```
We check the stationarity of the three series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_netherlands_train$population)
adf.test(xreg_netherlands_train$gdp_capita)

```
We apply a first order differences in both series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_netherlands_train$population %>% diff())
adf.test(xreg_netherlands_train$gdp_capita %>% diff())

```

We still not get stationarity. We apply again a difference:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_netherlands_train$population %>% diff(differences = 2))
adf.test(xreg_netherlands_train$gdp_capita %>% diff(differences = 2))

```

We need two differences to get the series stationary. Let's check now which model selects the auto.arima function

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_auto_arimax_netherlands <- auto.arima(train_netherlands_short, xreg= as.matrix(xreg_netherlands_train ), test = "adf")

summary(fit_auto_arimax_netherlands)
```
The selected model is ARIMA($1,1,2$), meaning that after a first order difference, the series still has an autorregressive and moving average components. Now, for the manual model, we should check the ACF and PACF plots. We will study the twice-differenced series.

We begin with the population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_netherlands_train$population %>% diff(differences = 2))
custom_pacf_plot(xreg_netherlands_train$population %>% diff(differences = 2))

```
The ACF (first) shows significant spikes at lags one and three, whereas the PACF (second) displays two significant first lags. We continue woth the GDP per capita series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_netherlands_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_netherlands_train$gdp_capita %>% diff(differences = 2))

```

GDP per capita series show a different pattern; the PACF (bottom) displays two significant spikes at lags 2 and 3, whereas the ACF (top) presents an only spike at lag 4.

Overall, an ARIMA($2,2,1$) is selected.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_netherlands_221 <- Arima(train_netherlands_short, xreg= as.matrix(xreg_netherlands_train ), order = c(2,2,1))

summary(fit_arimax_netherlands_221)
```

It gives an AIC of $-33.89$. Now, we check the residuals of both models. We begin with the auto.arima model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_auto_arimax_netherlands %>% forecast::checkresiduals()
shapiro.test(residuals(fit_auto_arimax_netherlands))
```

The automated model satisfy both assumptions on residuals. We now check the manual model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_netherlands_221 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_arimax_netherlands_221))
```
Residual diagnostic of the manual model determines a well-fitted model, too. We begin the forecast step:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_netherlands <- run_country_forecast("Netherlands", start_year = 1960, order_manual = c(2,2,1),
                            order_auto = c(1,1,2), horizons = c(1,3,5), use_xreg = TRUE)
results_arimax_netherlands$metrics
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_netherlands$plots
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df1 <- results_netherlands_arima$plots$df  

df2 <- results_arimax_netherlands$plots$df
df1$Type ="ARIMA"
df2$Type = "ARIMAX"

dfT <- rbind(df1, df2)

observed_data <- dfT %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT$Horizon),
  Type = unique(dfT$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2 <- dfT %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2 <- dfT2 %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2$Model <- factor(dfT2$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  scale_x_continuous(breaks = seq(min(dfT2$year), max(dfT2$year), by = 3)) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )
```


### Bulgaria

Now, we study the Bulgarian time series. We begin, as in Spain, by studying the regressor variables.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_bulgaria_arimax_plot <- data.frame(
  Year = countries_short[["Bulgaria"]][["full"]]$year,
  number_deaths = countries_short[["Bulgaria"]][["full"]]$number_deaths,
  population = countries_short[["Bulgaria"]][["full"]]$population,
  gdp_capita = countries_short[["Bulgaria"]][["full"]]$gdp_capita
)
train_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["train"]][["number_deaths"]]), start = 1980, frequency = 1)
test_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["test"]][["number_deaths"]]), start = 2014, frequency = 1)


```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_bulgaria_train <- data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["train"]][["population"]]), start = 1980, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["train"]][["gdp_capita"]]), start = 1980, frequency = 1)
)

xreg_bulgaria_test <- data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["test"]][["population"]]), start = 2014, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["test"]][["gdp_capita"]]), start = 2014, frequency = 1)
)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_bulg <- df_bulgaria_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_bulg$log_deaths, df_bulg$log_gdp), na.rm = TRUE)

df_bulg <- df_bulg %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))

ggplot(df_bulg, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2014, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_bulg$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```

The autogenerated model is:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_bulgaria <- auto.arima(train_bulgaria_short, xreg= as.matrix(xreg_bulgaria_train ), test = "adf")

summary(fit_arimax_bulgaria)
```

ARIMA(0,1,0) with an AIC of $-53.06$. We check the characteristics of the series in order to determine the alternative model. We begin assessing the stationary condition using the ADF test:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_bulgaria_train$population)
adf.test(xreg_bulgaria_train$gdp_capita)

```

Neither the population nor the GDP per capita series are stationary. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_bulgaria_train$population %>% diff())
adf.test(xreg_bulgaria_train$gdp_capita %>% diff())

```

After a first order difference, series still not stationary. In fact, is not but after two differences that the series get stationary. We study both analysis to choose whether adding an order of differences ensures a better perfomance of the model rather than only one difference.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_bulgaria_train$population %>% diff(differences = 2))
adf.test(xreg_bulgaria_train$gdp_capita %>% diff(differences = 2))

```

1. Population series, first order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_bulgaria_train$population %>% diff())
custom_pacf_plot(xreg_bulgaria_train$population %>% diff())

```

Results: The PACF reveals two significant lags at the beginning of the series. The ACF exhibits a slow decay, suggesting that the series may remain non-stationary after a single differencing, as we proved by the ADF test.

2. Population series, two order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_bulgaria_train$population %>% diff(differences =2))
custom_pacf_plot(xreg_bulgaria_train$population %>% diff(differences = 2))

```
Results: The ACF displays prominent spikes at lags 1, and 4. The PACF similarly shows significant spikes at the first two lags, while other lags fall within the confidence bounds. These patterns are more consistent with stationarity.

3. GDP per capita series, first order differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_bulgaria_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_bulgaria_train$gdp_capita %>% diff())

```
Results: The PACF does not show any significant lags rather than at 4th lag. The ACF also shows notable autocorrelations in the first lag.

4. GDP per capita series, two order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_bulgaria_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_bulgaria_train$gdp_capita %>% diff(differences = 2))

```
Results: The ACF (left) shows oscillating lags, with many significant spikes at lags 1,3,4,7. The PACF includes significant negative spikes at lags 1 and 2, while the rest remain within the confidence bounds.  

Overall, the model proposed is an ARIMA(2,1,2).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria_212 <- Arima(train_bulgaria_short, xreg = as.matrix(xreg_bulgaria_train), order = c(2,1,2))
summary(fit_arimax_bulgaria_212)
```
The model's AIC is nearly $-49.8$, a bit bigger than the autogenerated one, but with no big differences. Noe its time of residuals diagnostic.

We first check the automated one:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. We check the manual model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria_212 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria_212))
```

Residuals satisfy the assumptions. We then compare the accuracy metrics on both models:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_bulgaria <- run_country_forecast("Bulgaria", start_year = 1980, order_manual = c(2,1,2),
                            order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = TRUE)

results_arimax_bulgaria$metrics

```
Across all forecast horizons, the manually specified ARIMA model showed smaller errors and less systematic bias than the models selected automatically by the auto.arima() procedure. Negative mean error values in every model indicate a tendency to under-forecast tuberculosis deaths, but the magnitude of this bias was consistently lower for the manual models. Forecast dispersion increased with horizon, as expected, yet the manual ARIMA retained lower RMSE and MAE at each step. Critically, percentage-scaled accuracy (MAPE) remained < 20 % for the manual model up to three steps ahead (15.3 % → 19.1 %), whereas the automated model crossed widely used acceptability thresholds (15.4 % → 27.2 % → 49.4 %). 

We finally check the plots of the results:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_bulgaria <- run_country_forecast("Bulgaria", start_year = 1980, order_manual = c(2,1,2),
                            order_auto = c(0,1,0), horizons = c(1,3,5), use_xreg = TRUE)

results_arimax_bulgaria$plots

```
Notably, as the horizon increases, the predictions do not fit well with the observed values; however, and markedly enough, at three-step-ahead forecast, the manual model has capture the spike in 2019 quite good, even better than the one-step-ahead forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}
calc_exp_bounds(results_arimax_bulgaria, "auto", 1)
calc_exp_bounds(results_arimax_bulgaria, "manual", 1)

calc_exp_bounds(results_arimax_bulgaria, "auto", 2)
calc_exp_bounds(results_arimax_bulgaria, "manual",  2)

calc_exp_bounds(results_arimax_bulgaria, "auto",  3)
calc_exp_bounds(results_arimax_bulgaria, "manual",  3)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df1 <- results_arima_bulgaria$plots$df  

df2 <- results_arimax_bulgaria$plots$df
df1$Type ="ARIMA"
df2$Type = "ARIMAX"

dfT <- rbind(df1, df2)

observed_data <- dfT %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT$Horizon),
  Type = unique(dfT$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2 <- dfT %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2 <- dfT2 %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2$Model <- factor(dfT2$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  scale_x_continuous(breaks = seq(min(dfT2$year), max(dfT2$year), by = 3)) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )
```

### Estonia

Let's begin the study for Estonia data. Remember that Estonia is the country that has shorter time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_estonia_arimax_plot <- data.frame(
  Year = countries_short[["Estonia"]][["full"]]$year,
  number_deaths = countries_short[["Estonia"]][["full"]]$number_deaths,
  population = countries_short[["Estonia"]][["full"]]$population,
  gdp_capita = countries_short[["Estonia"]][["full"]]$gdp_capita
)

train_estonia_short <- ts(log(countries_short[["Estonia"]][["train"]][["number_deaths"]]), start = 1993, frequency = 1)
test_estonia_short <- ts(log(countries_short[["Estonia"]][["test"]][["number_deaths"]]), start = 2017, frequency = 1)

length(train_estonia_short)
length(test_estonia_short)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

xreg_estonia_train <- data.frame(
  population = ts(log(countries_short[["Estonia"]][["train"]][["population"]]), start = 1993, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["train"]][["gdp_capita"]]), start = 1993, frequency = 1)
)

xreg_estonia_test <- data.frame(
  population = ts(log(countries_short[["Estonia"]][["test"]][["population"]]), start = 2017, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["test"]][["gdp_capita"]]), start = 2017, frequency = 1)
)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_est <- df_estonia_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_est$log_deaths, df_est$log_gdp), na.rm = TRUE)

df_est <- df_est %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))

ggplot(df_est, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2017, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_est$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```

It is clear that the series are not stationary. To further asses this, we use the ADF test:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_estonia_train$population)
adf.test(xreg_estonia_train$gdp_capita)

```

We try the first differences:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_estonia_train$population %>% diff())
adf.test(xreg_estonia_train$gdp_capita %>% diff())

```

The population time series passes the stationarity test after a first difference being applied. In contrast, the GDP per capita time series need more than two differences to get stationary.

We check the first-order difference ACF and PACF plots:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(xreg_estonia_train$population %>% diff())
custom_pacf_plot(xreg_estonia_train$population %>% diff())

```
The results of the population's ACF and PACF plots suggest an AR(1) behaviour. We now check the GDP per capita time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(xreg_estonia_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_estonia_train$gdp_capita %>% diff())

```
No signficant spikes are shown in the ACF and PACF plots. Let's investigate which is the selected ARIMA model of the auto.arima function:


```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_autoarimax_estonia <- auto.arima(train_estonia_short, xreg= as.matrix(xreg_estonia_train ), test = "adf")

summary(fit_autoarimax_estonia)
```

The auto.arima has selected the ARIMA(1,1,0) as the model with the AIC coefficient minimized ($-2.81$). This selection fully coincides with the results of the ACF and PACF, so we need to investigate a bit more to choose an alternative model.

Recall that Estonia's TB-deaths series was not stationary after two differences being applied. We can study the ACF and PACF of the covariates after two differences.

First, the populations series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(xreg_estonia_train$population %>% diff(differences = 2))
custom_pacf_plot(xreg_estonia_train$population %>% diff(differences = 2))

```
Then, the GDP per capita time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(xreg_estonia_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_estonia_train$gdp_capita %>% diff(differences = 2))

```

We propose an ARIMA(1,2,2) and check the results. First, the AIC returned is:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_estonia_122 <- Arima(train_estonia_short, xreg = as.matrix(xreg_estonia_train), order = c(1,2,2))

summary(fit_arimax_estonia_122)
```

We check the residuals of both models. 


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_autoarimax_estonia  %>% forecast::checkresiduals()

shapiro.test(residuals(fit_autoarimax_estonia))
```

The residuals of the automated model do not satisfy the normality assumption. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_estonia_122%>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_estonia_122))
```

In contrast, the manually selected model satisfy both hypothesis. We can check the accuracy metrics of both models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_estonia <- run_country_forecast("Estonia", start_year = 1993, order_manual = c(1,2,2),
                            order_auto = c(1,1,0), horizons = c(1,3,5), use_xreg = TRUE)

results_arimax_estonia$metrics

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arimax_estonia$plots$plots$h1
results_arimax_estonia$plots$plots$h1
results_arimax_estonia$plots$plots$h1

```

```{r, warning=FALSE, message=FALSE, echo = FALSE, results='hide'}

calc_exp_bounds(results_arimax_estonia, "auto", 1)
calc_exp_bounds(results_arimax_estonia, "manual", 1)

calc_exp_bounds(results_arimax_estonia, "auto", 2)
calc_exp_bounds(results_arimax_estonia, "manual",  2)

calc_exp_bounds(results_arimax_estonia, "auto",  3)
calc_exp_bounds(results_arimax_estonia, "manual",  3)
```

```{r}
df1_estonia <- results_arima_estonia$plots$df  

df2_estonia <- results_arimax_estonia$plots$df

df1_estonia$Type ="ARIMA"
df2_estonia$Type = "ARIMAX"

dfT_estonia <- rbind(df1_estonia, df2_estonia)



observed_data <- dfT_estonia %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT_estonia$Horizon),
  Type = unique(dfT_estonia$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2_estonia <- dfT_estonia %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2_estonia <- dfT2_estonia %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2_estonia$Model <- factor(dfT2_estonia$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2_estonia, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )
```


### Sweden

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_sweden_arimax_plot <- data.frame(
  Year = countries_short[["Sweden"]][["full"]]$year,
  number_deaths = countries_short[["Sweden"]][["full"]]$number_deaths,
  population = countries_short[["Sweden"]][["full"]]$population,
  gdp_capita = countries_short[["Sweden"]][["full"]]$gdp_capita
)

train_sweden_short <- ts(log(countries_short[["Sweden"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)
test_sweden_short <- ts(log(countries_short[["Sweden"]][["test"]][["number_deaths"]]), start = 2011, frequency = 1)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_sweden_train <- data.frame(
  population = ts(log(countries_short[["Sweden"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Sweden"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)

xreg_sweden_test <- data.frame(
  population = ts(log(countries_short[["Sweden"]][["test"]][["population"]]), start = 2011, frequency = 1),
  gdp_capita = ts(log(countries_short[["Sweden"]][["test"]][["gdp_capita"]]), start = 2011, frequency = 1)
)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_sweden <- df_sweden_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_sweden$log_deaths, df_sweden$log_gdp), na.rm = TRUE)

df_sweden <- df_sweden %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))   # población “dibujable”

ggplot(df_sweden, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2011, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_sweden$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```

We check the stationarity of the covariates.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_sweden_train$population)
adf.test(xreg_sweden_train$gdp_capita %>% diff(differences = 2))
```

The GDP per capita series need to order differences to get stationary; on the contrary, the population series seems to be stationary without any difference. The KPPS test reveals that it is not stationary:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
kpss.test(xreg_sweden_train$population )
```

Now, we check the ACF and PACF of both first and two differences:

1. First difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_sweden_train$population %>% diff())
custom_pacf_plot(xreg_sweden_train$population %>% diff())
```
It is clear that the series is not stationary, and the slow decay of the ACF confirms the hypothesis.

2. Second difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_sweden_train$population %>% diff(differences = 2))
custom_pacf_plot(xreg_sweden_train$population %>% diff(differences = 2))
```
After two differences, the ACF (top) shows a significant spike at the first lag, whereas the PACF (bottom) displays three signficant spikes at the first three lags.

3. First difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_sweden_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_sweden_train$gdp_capita %>% diff())
```
No autocorrelation is shown in the ACF (top) and in the PACF (bottom) only at lag 5.

4. Second difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_sweden_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_sweden_train$gdp_capita %>% diff(differences = 2))
```

The ACF (top) displays significant spikes at lags 4, 8 and 16, whereas the PACF (bottom) displays an only significant spike at lag 3. 

Overall, the manual selected model is ARIMA($2,1,2$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden_212 <- Arima(train_sweden_short, order = c(2,1,2), xreg = as.matrix(xreg_sweden_train))
summary(fit_arimax_sweden_212)
```

Now, we check the auto.arima function selected model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden_auto <- auto.arima(train_sweden_short, test = "adf", xreg = as.matrix(xreg_sweden_train))
summary(fit_arimax_sweden_auto)
```

The model selected is ARIMA($2,1,0$). Now we check the residuals of both models. We begin with the automatic model:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden_auto %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_sweden_auto))
```

The residuals of the auto.arima model satisfy both assumptions. Now, we check the residuals of the ARIMA($1,2,2$):


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_sweden_212 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_sweden_212))
```

The residuals of the ARIMAX model satisfy the assumptions. Now, we begin the forecast:
```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_sweden <- run_country_forecast("Sweden", start_year = 1960, order_manual = c(2,1,2),
                            order_auto = c(2,1,0), horizons = c(1,3,5), use_xreg = TRUE)

results_arimax_sweden$metrics

```
```{r, warning=FALSE, message=FALSE, echo = FALSE}

results_arimax_sweden$plots

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df1 <- results_sweden_arima$plots$df  

df2 <- results_arimax_sweden$plots$df
df1$Type ="ARIMA"
df2$Type = "ARIMAX"

dfT <- rbind(df1, df2)

observed_data <- dfT %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT$Horizon),
  Type = unique(dfT$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2 <- dfT %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2 <- dfT2 %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2$Model <- factor(dfT2$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  scale_x_continuous(breaks = seq(min(dfT2$year), max(dfT2$year), by = 3)) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )

```

### Switzerland

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_switzerland_arimax_plot <- data.frame(
  Year = countries_short[["Switzerland"]][["full"]]$year,
  number_deaths = countries_short[["Switzerland"]][["full"]]$number_deaths,
  population = countries_short[["Switzerland"]][["full"]]$population,
  gdp_capita = countries_short[["Switzerland"]][["full"]]$gdp_capita
)


train_switzerland_short <- ts(log(countries_short[["Switzerland"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)
test_switzerland_short <- ts(log(countries_short[["Switzerland"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
xreg_switzerland_train <- data.frame(
  population = ts(log(countries_short[["Switzerland"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Switzerland"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)

xreg_switzerland_test <- data.frame(
  population = ts(log(countries_short[["Switzerland"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Switzerland"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

df_switzerland <- df_switzerland_arimax_plot %>% 
  mutate(
    log_deaths = log(number_deaths),
    log_gdp    = log(gdp_capita),
    log_pop    = log(population)
  )

range_primary <- range(c(df_switzerland$log_deaths, df_switzerland$log_gdp), na.rm = TRUE)

df_switzerland <- df_switzerland %>% 
  mutate(pop_scaled = rescale(log_pop, to = range_primary))   # población “dibujable”

ggplot(df_switzerland, aes(x = Year)) +
  geom_line(aes(y = log_deaths, colour = "Number of deaths")) +
  geom_line(aes(y = log_gdp,    colour = "GDP per capita")) +
  geom_line(aes(y = pop_scaled, colour = "Population")) +
  geom_vline(xintercept = 2010, linetype = "dashed", colour = "#04225CFF") +
  scale_color_manual(
    name   = "Series",
    values = c("Number of deaths" = "#1f77b4",
               "GDP per capita" = "#088158FF",
               "Population" = "#862633FF")
  ) +
  scale_y_continuous(
    name = "Logarithm of number of deaths & GDP per capita",
    sec.axis = sec_axis(
      ~ rescale(., from = range_primary, to = range(df_switzerland$log_pop, na.rm = TRUE)),
      name = "Logarithm of population"
    )
  ) +
  labs(x = "Year", y = NULL, title = "") +
  theme_minimal()
```

We check the stationarity of the covariates:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_switzerland_train$population)
adf.test(xreg_switzerland_train$gdp_capita)
```

The series are clearly non-stationary. We apply a first order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_switzerland_train$population %>% diff())
adf.test(xreg_switzerland_train$gdp_capita %>% diff())
```

We apply a second order differences:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_switzerland_train$population %>% diff(differences = 2))
adf.test(xreg_switzerland_train$gdp_capita %>% diff(differences = 2))
```

The series get stationary after two differences. We check the auto.arima suggested model:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_autoarimax_switzerland<- auto.arima(train_switzerland_short, xreg= as.matrix(xreg_switzerland_train ), test= "adf")

summary(fit_autoarimax_switzerland)
```
The procedure suggested an ARIMA($1,0,0$), meaning no differences are applied (recall that the ADF test of the main series show that the series is stationary without any differences).

Now, let's check the ACF and PACF plots of the covariates after one and two differences:

1. First difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_switzerland_train$population %>% diff())
custom_pacf_plot(xreg_switzerland_train$population %>% diff())
```
It is clear that the series is not stationary, and the slow decay of the ACF confirms the hypothesis.

2. Second difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_switzerland_train$population %>% diff(differences = 2))
custom_pacf_plot(xreg_switzerland_train$population %>% diff(differences = 2))
```
After two differences, the ACF (top) shows a significant spike at the first lag, whereas the PACF (bottom) displays two signficant spikes at the first two lags.

3. First difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_switzerland_train$gdp_capita %>% diff())
custom_pacf_plot(xreg_switzerland_train$gdp_capita %>% diff())
```
No autocorrelation is shown in the PACF (bottom) and in the ACF (top) only at lag 1.

4. Second difference of population series

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(xreg_switzerland_train$gdp_capita %>% diff(differences = 2))
custom_pacf_plot(xreg_switzerland_train$gdp_capita %>% diff(differences = 2))
```
The ACF (top) shows significant spikes at lags 4 and 8, whereas the PACF shows negative spikes at lags 2 and 7. Overall, the fitted model is ARIMA($2,2,1$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_switzerland_221 <- Arima(train_switzerland_short, xreg = as.matrix(xreg_switzerland_train), order = c(2,2,1))
summary(fit_arimax_switzerland_221)
```

Now, we check the residuals of both models:


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_autoarimax_switzerland %>% forecast::checkresiduals()

shapiro.test(residuals(fit_autoarimax_switzerland))
```

The residuals of the auto.arima ARIMAX model do not satisfy the normality hypothesis. Now we check the ARIMA(2,2,1):

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_switzerland_221 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_switzerland_221))
```

The residuals of the manual model do not distribute normally neither. Now we begin the forecast step:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_switzerland <- run_country_forecast("Switzerland", start_year = 1960, order_manual = c(2,2,1),
                            order_auto = c(1,0,0), horizons = c(1,3,5), use_xreg = TRUE)

results_arimax_switzerland$metrics
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
results_arimax_switzerland$plots
```
```{r, warning=FALSE, message=FALSE, echo = FALSE}
df1 <- results_switzerland_arima$plots$df  

df2 <- results_arimax_switzerland$plots$df
df1$Type ="ARIMA"
df2$Type = "ARIMAX"

dfT <- rbind(df1, df2)

observed_data <- dfT %>%
  filter(Model == "Observed") %>%
  distinct(year, Value)

hor_types <- expand.grid(
  Horizon = unique(dfT$Horizon),
  Type = unique(dfT$Type)
)

observed_complete <- merge(observed_data, hor_types) %>%
  mutate(Model = "Observed")

dfT2 <- dfT %>%
  filter(Model != "Observed") %>%
  bind_rows(observed_complete)

dfT2 <- dfT2 %>%
  group_by(Horizon, Type) %>%
  mutate(models_in_group = n_distinct(Model)) %>%
  filter(models_in_group > 1) %>%
  select(-models_in_group) %>%
  ungroup()

dfT2$Model <- factor(dfT2$Model, levels = c("Observed", "autoARIMA", "manualARIMA"))

colors <- c("Observed" = "#1f77b4", "autoARIMA" = "#6ba292", "manualARIMA" = "#ff7f0e")
linetypes <- c("Observed" = "solid", "autoARIMA" = "dashed", "manualARIMA" = "dashed")

ggplot(dfT2, aes(x = year, y = Value, color = Model, linetype = Model)) +
  geom_line() +
  facet_grid(Horizon ~ Type) +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  scale_x_continuous(breaks = seq(min(dfT2$year), max(dfT2$year), by = 3)) +
  labs( x = "Year", y = "Number of deaths",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    panel.grid.major = element_line(color = "grey95", linewidth = 0.5),  
    panel.grid.minor = element_line(color = "grey95", linewidth = 0.2),  
    strip.text = element_text(),
    legend.position = "bottom",
    panel.border = element_rect(color = "grey60", fill = NA, linewidth = 0.3),
    panel.spacing = unit(0.5, "lines")
  )

```


## Video



```{r}
df1 <- results_arima_spain$plots$df
df2 <- results_arimax_spain$plots$df

df1$Type <- "ARIMA"
df2$Type <- "ARIMAX"

dfT <- rbind(df1, df2)

df_models <- dfT %>%
  filter(Horizon == "h1",
         Model == "manualARIMA",
         year >= 2015, year <= 2021)

df_observed <- dfT %>%
  filter(Horizon == "Observed",
         Model == "Observed",
         year >= 2015, year <= 2021) %>%
  select(year, Value) %>%
  distinct() %>%
  mutate(Model = "Observed") %>%
  tidyr::crossing(Type = c("ARIMA", "ARIMAX"),
                  Horizon = "h1")  

df_plot <- bind_rows(df_models, df_observed)

df_plot <- df_plot %>%
  mutate(ModelLabel = case_when(
    Model == "Observed" ~ "Valor Real",
    Model == "manualARIMA" & Type == "ARIMA" ~ "ARIMA",
    Model == "manualARIMA" & Type == "ARIMAX" ~ "ARIMAX"
  ))


df_plot$ModelLabel <- factor(df_plot$ModelLabel, levels = c("Valor Real", "ARIMA", "ARIMAX"))

colors <- c("Valor Real" = "#1f77b4", "ARIMA" = "#088158FF", "ARIMAX" = "#862633FF")
linetypes <- c("Valor Real" = "solid", "ARIMA" = "dashed", "ARIMAX" = "dashed")


p_1 <- ggplot(df_plot, aes(x = year, y = Value, color = ModelLabel, linetype = ModelLabel)) +
  geom_line() +
  scale_color_manual(values = colors) +
  scale_linetype_manual(values = linetypes) +
  labs(x = "Any", y = "Nombre de defuncions de TB",
       color = "Model", linetype = "Model") +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = "#f3f3f3", color = NA),
    panel.background = element_rect(fill = "#f3f3f3", color = NA),
    strip.background = element_rect(fill = "#f3f3f3", color = NA),
    legend.background = element_rect(fill = "#f3f3f3", color = NA),
    panel.grid.minor = element_blank(),
    strip.text = element_text(face = "bold", size = 12),
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

```








