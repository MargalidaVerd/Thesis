---
title: "TFG"
author: "Margalida Verd Julià"
format: html
editor: visual
---

## Installing data and packages

First, we will install and load the necessary packages for this study. Additionally, we will load the required datasets. The analysis is based on three datasets:

-   **Mortality**: Downloaded from the World Health Organization, this is the primary dataset for the analysis. It contains the number of tuberculosis-related deaths in all countries. However, our study will focus solely on European countries.

-   **Population**: From this dataset, we will extract only the population variable. The source of this data is *Our World in Data*.

-   **GDP per capita**: Similar to the population dataset, we will extract only the *gdp_per_capita* variable. The source of this data is *Data Bank*.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# packages loading

library(tidyverse)
library(readr)
library(dplyr)
library(zoo)
library(feasts)
library(eurostat)
library(leaflet)
library(sf)
library(scales)
library(cowplot)
library(ggthemes)
library(giscoR)
library(rnaturalearth)
library(ggplot2)
library(sf)
library(dplyr)
library(gridExtra)
library(grid)
library(tsibble)
library(tseries)
library(FinTS)
library(fable)
library(vctsfr)
library(fpp2)
library(r2r)
library(Metrics)

```

Let's examine the structure of the datasets:

1.  Mortality:

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# data loading

mortality_dataset <- read.csv("mortality.csv", header = TRUE, colClasses = c("character","character","character","character","double","character","character","character","double","double","double","double"), row.names = NULL) 

colnames(mortality_dataset) <- colnames(mortality_dataset)[2:ncol(mortality_dataset)]
mortality_dataset <- mortality_dataset[1:(ncol(mortality_dataset)-1)]

mortality_dataset %>% 
  glimpse()

unique(mortality_dataset$Age.group)
```

2.  Population

```{r, warning=FALSE, message=FALSE, echo= FALSE}
population_dataset <- read.csv("population.csv", header = TRUE)

population_dataset %>% 
  glimpse()
```

3.  gdp_per_capita

```{r, warning=FALSE, message=FALSE, echo= FALSE}
gdp_per_capita_dataset <- read.csv("gdp_per_capita.csv", header = TRUE)

gdp_per_capita_dataset %>% 
  glimpse()
```

## Cleaning data

As seen, we need to standardize the variables names to merge the tables.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# renaming variables

print("Mortality")

mortality_dataset <- mortality_dataset %>%  
  rename(number_deaths = Number, 
         year = Year, percent_cause_specific_death_rate = Percentage.of.cause.specific.deaths.out.of.total.deaths, age_death_rate = Age.standardized.death.rate.per.100.000.standard.population, death_rate = Death.rate.per.100.000.population, country_name = Country.Name, country_code = Country.Code, region_code = Region.Code, region_name = Region.Name) %>% 
  glimpse() 

print("Population")
population_dataset <- population_dataset %>% 
  rename(population = Population...Sex..all...Age..all...Variant..estimates, country_name = Entity, year = Year) %>% 
  glimpse() 

print("gdp_per_capita")
gdp_per_capita_dataset <- gdp_per_capita_dataset %>% 
  select(3,4,5,7) %>% 
  rename(country_name = Country.Name, country_code = Country.Code, year = Time, gdp_capita = Value) %>% 
  glimpse()

```

The next step is to select the study variables from the mortality dataset. We will exclude `Sex`, `Age.group.code` and `Age.group`.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# Select rows of interest in the mortality dataset

mortality_dataset <- mortality_dataset %>% 
  dplyr::filter(Sex == "All") 

# Delete age variables

mortality_dataset <- mortality_dataset %>% 
  select(1:5,9:12) %>% 
  glimpse()
```

Now, we can merge the remaining two datasets.

```{r, warning=FALSE, message=FALSE, echo= FALSE}
# joins

full_dataset <- mortality_dataset %>% 
  left_join(population_dataset, by=c("country_name", "year")) %>% 
  left_join(gdp_per_capita_dataset, by = c("country_code", "year")) %>% 
  dplyr::filter(region_code=="EU") %>% 
  select(1:10,12) %>% 
  rename(country_name = country_name.x) 

full_dataset %>% 
  glimpse()

```

## Chosen countries

First, we will define the criteria for dividing European countries into six distinct regions: North, South, West, East, Central, and the Balkans. The Balkans have been designated as a separate region due to their significant cultural differences from neighboring countries. We will add a new variable to the dataset that specifies the subregion to which each country belongs.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset <- full_dataset %>%
  mutate(subregion = case_when(
    country_name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    country_name %in% c("Spain", "Portugal", "Italy", "Malta", "Greece") ~ "S",
    country_name %in% c("Albania", "Bulgaria", "Romania", "Bosnia and Herzegovina", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    country_name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    country_name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~"E",
    country_name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C" ,TRUE ~ NA_character_), .after = region_name)

```

The map below shows the division that would be used from this point forward.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

# Load world map with country boundaries
world <- ne_countries(scale = "medium", returnclass = "sf")

# Filter only European countries
europe <- world %>% 
  filter(continent == "Europe")


# Define the classification
europe <- europe %>%
  mutate(Subregion = case_when(
    name %in% c("Iceland", "Norway", "Sweden", "Finland", "Denmark") ~ "N",
    name %in% c("Spain", "Portugal", "Italy", "Malta", 
                 "Greece") ~ "S",
    name %in% c("Albania", "Bulgaria", "Romania", "Kosovo", "Bosnia and Herz.", 
                "North Macedonia", "Croatia", "Serbia", "Montenegro", "Slovenia") ~ "B",
    name %in% c("France", "Netherlands", "Belgium", "United Kingdom", "Ireland") ~ "W",
    name %in% c("Russia", "Estonia", "Latvia", "Lithuania", "Belarus", "Ukraine", "Moldova") ~ "E",
    name %in% c("Germany", "Poland", "Czechia", "Slovakia", "Hungary", 
                "Switzerland", "Austria", "Luxembourg") ~ "C",
  ))


ggplot(data = europe) +
  geom_sf(aes(fill = Subregion), color = "black") +
  scale_fill_manual(values = c(
    "N" = "#F5BA6A",    
    "S" = "#4044A8",    
    "W" = "#CC4853",    
    "E" = "#5ED171",   
    "C" = "#F5E973",    
    "B" = "#66B0FA"    
  )) + scale_x_continuous(limits = c(-20, 35)) +
  scale_y_continuous(limits = c(35, 70)) +
  theme_minimal() +
  labs(
       fill = "Subregion") +
  theme(legend.position = "right")
```

We are considering Greece as part of the Southern region due to the cultural differences with the Balkan countries. Now, we would choose a country to represent each European subregion. We will select five European countries to analyze their trends in the number of tuberculosis-related deaths. The selection criteria will ensure that the chosen countries represent different regions of Europe (e.g., North, South, etc.) while also having a sufficient number of time observations to construct a reliable time series. Additionally, we aim to include countries that exhibit distinct trends in tuberculosis mortality, making the study more insightful by allowing for a comparative analysis and accurate forecasting of different patterns.

As a first step, we will address any missing values (NA) in the dataset for the variable Number_Deaths in each selected country. We are going to choose countries that at least have 40 years with data.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  dplyr::select(country_name, number_deaths) %>% 
  na.exclude() %>%  
  group_by(country_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  data.frame() %>% 
  filter(n >= 40)

```

```{r}

full_dataset %>%
  filter(subregion == "C") %>% 
  group_by(country_name) %>%
  summarise(
    number_deaths = sum(!is.na(number_deaths)),
    population  = sum(!is.na(population)),
    gdp_capita  = sum(!is.na(gdp_capita))
  ) %>%
  arrange(desc(number_deaths)) %>%
  data.frame() 

```

Lets study each subregion:

-   **Southern Europe**. Due to the geographical origin of the authors, we will choose Spain as the representative country of this region.

-   **Northern Europe**. We observe that Iceland has 72 out of 74 years with recorded values for the selected variable, making it a suitable choice to represent the North region of Europe.

-   **Western Europe**. As Netherlands is the country with a greatest number of values, it would be our choice for this specific region.

-   **Eastern Europe**. It is noticeable that eastern countries are the ones with a less number of recorded values (most of them have only 40 or less); then, it would be a special region to analyse. Lithuania will represent the Northeast region, with 40 recorded values. Even though there are nearby countries with longer recorded periods, the tendency of Lithuania stands out among the rest, which will make for an interesting analysis.

-   **Central Europe**. Switzerland will be the representative country of the central region. It has 71 recorded values, that will fit perfectly when modeling the time series.

-   **Balkans region**. For the Balkans region, we have selected Romania, which has 60 recorded values. It will be an interesting case of analysis due to its tendency, that is a bit different as the other countries.

The selection criteria prioritize minimizing the number of missing values (NA) while ensuring a diverse representation of different regions in Europe. As we have discussed trends, let's display the trend in tuberculosis-related deaths for the selected countries.

```{r, warning=FALSE, message=FALSE, echo= FALSE}

full_dataset %>% 
  filter(country_name %in% c( "Spain", "Sweden", "Netherlands", "Switzerland", "Estonia", "Bulgaria")) %>%  
  ggplot(aes(x = year, y = number_deaths, color = country_name)) +  
  geom_line() +
  coord_cartesian(ylim = c(0,2700)) +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries trends")+
  theme(legend.position = "right") +
  ylab("Number of deaths")


```

## Data partitioning utilities

To standardize the modeling process across multiple countries, we define helper structures that facilitate consistent data handling. Specifically, we construct a country_splits hashmap to store the full, training, and testing datasets for each selected country.

The first step is to initialize this structure with the full dataset filtered by country and ordered by year:

```{r, warning=FALSE, message=FALSE}
country_splits <- hashmap()
chosen_countries = c("Spain", "Netherlands", "Sweden", "Switzerland", "Bulgaria", "Estonia")

for (name in chosen_countries) {
  country_splits[[name]][["full"]] <- full_dataset %>% filter(country_name == name) %>%  arrange(year)
}


```

Next, we define the specific number of years to allocate to the testing set for each country. These values were chosen based on the total number of available observations, ensuring approximately 15–20% of the series is reserved for out-of-sample evaluation.

```{r, warning=FALSE, message=FALSE}
test_lengths_per_country = hashmap()

test_lengths_per_country[["Spain"]] = 11
test_lengths_per_country[["Switzerland"]] = 11
test_lengths_per_country[["Sweden"]] = 11
test_lengths_per_country[["Estonia"]] = 11
test_lengths_per_country[["Netherlands"]] = 12
test_lengths_per_country[["Bulgaria"]] = 10
```

Finally, we split the dataset for each country into a training and a testing subset based on the predefined test lengths. This setup is essential for subsequent model fitting and forecast evaluation.

```{r, warning=FALSE, message=FALSE}
for (country in chosen_countries) {
  country_dataset = country_splits[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country[[country]]
  country_splits[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  country_splits[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}

```



## ARIMA model utilities

In this section are presented the different methods for the ARIMA forecast. First of all, new functions to plot the ACF and PACF of the time series are defined, in order to get more visible plots (following the schema of python's library matplt.lib). 

```{r, warning=FALSE, message=FALSE}
custom_acf_plot <- function(ts_data, max_lag = 25) {
  acf_vals <- acf(ts_data, plot = FALSE)
  acf_df <- with(acf_vals, data.frame(
    Lag = lag,
    ACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  acf_df$UCL <- conf
  acf_df$LCL <- -conf
  
  ggplot(acf_df, aes(x = Lag, y = ACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(panel.grid = element_blank()) +
    labs(title = "", x = "Lag", y = "Value")
}

```

```{r, warning=FALSE, message=FALSE}
custom_pacf_plot <- function(ts_data, max_lag = 25) {
  pacf_vals <- pacf(ts_data, plot = FALSE)
  pacf_df <- with(pacf_vals, data.frame(
    Lag = lag,
    PACF_value = acf
  ))
  
  conf <- qnorm(0.975) / sqrt(length(ts_data))
  pacf_df$UCL <- conf
  pacf_df$LCL <- -conf
  
  ggplot(pacf_df, aes(x = Lag, y = PACF_value)) +
    geom_hline(yintercept = 0, color = "#1f77b4") +
    geom_ribbon(aes(ymin = LCL, ymax = UCL), fill = "#1f77b4", alpha = 0.2) +
    geom_segment(aes(xend = Lag, yend = 0), color = "#1f77b4") +
    geom_point(size = 1.5, color = "#1f77b4") +
    coord_cartesian(ylim = c(-0.5, 1.01)) +
    scale_y_continuous(breaks = seq(-0.5, 1.01, by = 0.25)) +
    scale_x_continuous(breaks = seq(0, max_lag, by = 2)) +
    theme_minimal() +
    theme(panel.grid = element_blank()) +
    labs(title = "", x = "Lag", y = "Value")
}

```

Then, a function to automate the selection of ARIMA models is created. This function systematically evaluates various parameter combinations and reports their corresponding Akaike Information Criterion (AIC) values. This approach allows for an informed and reproducible model selection process, particularly useful when the number of possible $(p,d,q)$ combinations is large and exhaustive testing is impractical.

```{r, warning=FALSE, message=FALSE}

try_all_arima <- function(ar_coef, d_coef, ma_coef, time_series) {
  for (p in ar_coef) {
    for(d in d_coef) {
      for (q in ma_coef) {
        arima_fit <- Arima(time_series, order = c(p, d, q))
        cat("ARIMA(", p, ",", d,"," ,q, ")\n", sep = "")
        print(arima_fit$coef)
        cat("AIC:", AIC(arima_fit), "\n\n")
      }
    }
  }
}
```

This function iterates over all specified combinations of autoregressive, differencing, and moving average orders. For each configuration, it fits an ARIMA model and outputs the estimated parameters along with the AIC value, which serves as the model selection criterion.

Next, we define the get_length function to facilitate quick retrieval of the number of non-missing observations in a specified dataset. Accessing time series lengths manually for each country and subset (full, train, or test) can be cumbersome and error-prone. This utility function simplifies the process by requiring only the country name, the desired subset, and the target variable. It returns the number of valid (non-NA) entries.

```{r, warning=FALSE, message=FALSE}
get_length <- function(country, set, variable) {
  return(length(na.omit(country_splits[[country]][[set]][[variable]])))
}

```

Now, we begin with the core functions defined for the rolling forecast methodology. We begin by defining two model constructors called `fitting_function()` and `fit_auto()`; the first, takes ARIMA orders $(p,d,q)$ as input and returns a function that fits a model with those parameters to any given time series. The second, fits the `auto.arima()` function, of the forecast package. 

```{r, warning=FALSE, message=FALSE}
fitting_function <- function(p, d, q) {
  function(y) Arima(y, order = c(p, d, q))
}

fit_auto <- function(y) auto.arima(y, stepwise = FALSE, approximation = FALSE)
```

The core of the forecasting mechanism is implemented in the function `rolling_forecast()`.

```{r, warning=FALSE, message=FALSE, echo=FALSE}

rolling_forecast <- function(train_series, test_series, fitting_function, max_steps = 5, horizons = c(1,3,5)) {
  
  test_len <- length(test_series)
  confidence_interval = 95
  outputs <- matrix(NA_real_, nrow = test_len, ncol = length(horizons), dimnames = list(NULL, paste0("h", horizons)))
  
  rolling_series <- train_series
  
  for (i in seq_len(test_len)) {
    
    model <- fitting_function(rolling_series)
    forecast  <- forecast(model, h = max_steps, level = confidence_interval)$mean
    
    for (h in horizons) {
      idx <- i + h - 1
      if (idx <= test_len)
        outputs[idx, paste0("h", h)] <- forecast[h]
    }
    
    rolling_series <- c(rolling_series, test_series[i])
  }
  return(outputs)
}
```

This function simulates a real-time prediction scenario by iteratively refitting the model to an expanding training set. At each iteration, it fits the model to the currently available data and generates forecasts up to a specified horizon (e.g., 1, 3, and 5 years ahead). These predictions are stored in a matrix with dimensions corresponding to the length of the test set and the number of horizons. Importantly, the function only retains the forecasted values that correspond to actual future observations in the test set, ensuring a fair comparison. The following table shows the main idea of the function:
  
```{r, warning=FALSE, message=FALSE, echo=FALSE}
example_tbl <- data.frame(
  Iteration = 1:3,
  Data_used_to_fit = c("1951–2010",
                       "1951–2011",
                       "1951–2012"),
  Forecast_block = c("2011–2015",
                     "2012–2016",
                     "2013–2017"),
  Data_stored = c("h1 → 2011, h3 → 2013, h5 → 2015",
                  "h1 → 2012, h3 → 2014, h5 → 2016",
                  "h1 → 2013, h3 → 2015, h5 → 2017"),
  stringsAsFactors = FALSE
)

print(example_tbl, row.names = FALSE)
```


To visualize the model behavior at different forecast horizons, the function `make_horizon_plots()` creates a series of time series plots. It takes as input the training and testing series, along with two fitting functions (one for the manually specified model and another using `auto.arima()`), and returns separate plots for each forecast horizon (1, 3, and 5 years). In each plot, the actual data are shown in the original scale, alongside the predictions from both models.

```{r, warning=FALSE, message=FALSE}
make_horizon_plots <- function(train_series, test_series, fit_fixed_fun, fit_auto_fun, horizons = c(1,3,5)) {
  
  pred_fixed <- rolling_forecast(train_series, test_series, fitting_function = fit_fixed_fun, 
                                 max_steps = max(horizons), horizons = horizons)
  
  pred_auto  <- rolling_forecast(train_series, test_series, fitting_function = fit_auto_fun,
                                 max_steps = max(horizons), horizons = horizons)
  
  df_fixed <- as.data.frame(pred_fixed) %>% 
    mutate(year = time(test_series)) %>%
    pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
    mutate(Value = exp(as.numeric(Value)), Model = "Fixed")
  
  df_auto  <- as.data.frame(pred_auto)  %>%
    mutate(year = time(test_series)) %>%
    pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
    mutate(Value = exp(as.numeric(Value)), Model = "Auto")
  
  df_actual <- data.frame(
    year    = time(test_series),
    Horizon = "Actual",
    Model   = "Actual",
    Value   = exp(as.numeric(test_series))
  )
  
  plot_df <- bind_rows(df_actual, df_fixed, df_auto) %>% 
    mutate(Horizon = factor(Horizon, levels = c("h1","h3","h5","Actual")))
  
  make_single_plot <- function(h) {
    ggplot(filter(plot_df, Horizon == h | Model == "Actual"),
           aes(x = year, y = Value, colour = Model, linetype = Model)) +
      geom_line(na.rm = TRUE) +
      scale_colour_manual(values = c(Actual = "#1f77b4", Auto   = "#6ba292", Fixed  = "#ff7f0e")) +
      scale_linetype_manual(values = c(Actual = "solid", Auto   = "dashed", Fixed  = "dashed")) +
      labs(title = , x = "Year", y = "Number of deaths", colour = "Model", linetype = "Model") +
      theme_minimal(base_size = 13)
  }
  
  plots <- lapply(paste0("h", horizons), make_single_plot)
  names(plots) <- paste0("h", horizons)
  plots
}

#paste("Horizon", substring(h, 2), "years")
```

To simplify the generation of plots across countries, we define `make_country_plots()`. This function handles the preprocessing steps, including log-transforming the input series and converting them into time series objects with appropriate start years. It then invokes the plotting function described above and returns a list of plots, one for each horizon.

```{r, warning=FALSE, message=FALSE}

make_country_plots <- function(country, p, d, q, start_year, horizons = c(1,3,5)) {
  
  train_raw <- country_splits[[country]]$train$number_deaths
  test_raw  <- country_splits[[country]]$test$number_deaths
  
  train_ts <- ts(log(train_raw), start= start_year, frequency = 1)
  test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)
  
  fit_fixed_fun <- fitting_function(p,d,q)
  fit_auto_fun  <- function(y) auto.arima(y, stepwise = FALSE, approximation = FALSE)
  
  make_horizon_plots(train_ts, test_ts, fit_fixed_fun, fit_auto_fun, horizons = horizons)
}

```

In addition to visual inspection, we provide quantitative tools to assess forecast accuracy. The function `print_error_summary_model()` computes key performance metrics such as Mean Error (ME), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Percentage Error (MPE) and Mean Absolute Percentage Error (MAPE).

```{r, warning=FALSE, message=FALSE}

print_error_summary_model <- function(test_series, predictions_list, horizons = c("h1", "h3", "h5")) {
  y_orig <- test_series                
  rows   <- list()
  
  for (model_name in names(predictions_list)) {
    pred_mat <- predictions_list[[model_name]]
    
    for (h in horizons) {
      yhat <- pred_mat[, h]            
      keep <- !is.na(yhat)
      
      rows[[paste(model_name, h, sep = "_")]] <-
        data.frame(
          Model = paste0(model_name, "-", h),
          ME    = mean(y_orig[keep] - yhat[keep]),
          RMSE  = rmse(y_orig[keep], yhat[keep]),
          MAE   = mae (y_orig[keep], yhat[keep]),
          MAPE  = mape(y_orig[keep], yhat[keep]) * 100,
          row.names = NULL
        )
    }
  }
  dplyr::bind_rows(rows)
}
```

The function `get_error_metrics()` helps getting the error measures faster.

```{r, warning=FALSE, message=FALSE}
get_error_metrics <- function(country, p, d, q, start_year, horizons = c(1, 3, 5)) {
  
  train_raw <- country_splits[[country]]$train$number_deaths
  test_raw  <- country_splits[[country]]$test$number_deaths
  
  train_log <- ts(log(train_raw), start = start_year, frequency = 1)
  test_log  <- ts(log(test_raw), start = end(train_log)[1] + 1, frequency = 1)
  
  fit_function_fixed <- function(y) Arima(y, order = c(p, d, q))
  fit_function_auto <- function(y) auto.arima(y, stepwise = FALSE, approximation = FALSE)
  
  max_steps <- max(horizons)
  horizons_char <- paste0("h", horizons)
  
  predicted_fixed_log <- rolling_forecast(train_log, test_log, fit_function_fixed, max_steps = max_steps, horizons = horizons)
  predicted_auto_log  <- rolling_forecast(train_log, test_log, fit_function_auto, max_steps = max_steps, horizons = horizons)
  
  error_summary_table <- print_error_summary_model(test_series = test_raw, 
                                                   predictions_list = list(Manual = exp(predicted_fixed_log), Auto   = exp(predicted_auto_log)),horizons  = horizons_char )
  
  return(error_summary_table)
}

```

If we wish to analyze the performance of one model only, the following functions should help:

```{r, warning=FALSE, message=FALSE}

rolling_predictions_single <- function(train_series, test_series, fitting_function, max_steps = 5, horizons = c(1, 3, 5)) {
  
  rolling_forecast(train_series, test_series, fitting_function, max_steps = max_steps, horizons = horizons)
}

plot_rolling_forecast_single <- function(test_series, predictions_log, horizon = 1) {
  
  horizon <- as.integer(horizon)
  predictions_raw <- exp(predictions_log[, paste0("h", horizon)])
  
  df <- data.frame(
    Year = time(test_series),
    Actual = exp(as.numeric(test_series)),
    Forecast = predictions_raw
  )
  
  ggplot(df, aes(x = Year)) +
    geom_line(aes(y = Actual, colour = "Actual")) +
    geom_line(aes(y = Forecast, colour = "Forecast"), linetype = "dashed", na.rm = TRUE) +
    scale_colour_manual(values = c(Actual = "#1f77b4", Forecast = "#ff7f0e")) +
    labs(title = "", y = "Number of deaths", colour = "") +
    theme_minimal(base_size = 13)
}
#paste("Rolling‑origin forecast – Horizon", horizon, "year(s)")
```

```{r, warning=FALSE, message=FALSE}


rolling_error_metrics_single <- function(test_series, predictions,
                                         horizons = c("h1", "h3", "h5")) {
  test_series <- as.numeric(test_series)
  rows <- list()
  
  for (h in horizons) {
    predicted_values <- predictions[, h]
    
    rows[[h]] <- data.frame(
      Horizon = h,
      ME    = mean(test_series - predicted_values, na.rm = TRUE),
      RMSE  = sqrt(mean((test_series - predicted_values)^2, na.rm = TRUE)),
      MAE   = mean(abs(test_series - predicted_values), na.rm = TRUE),
      MAPE  = mean(abs((test_series - predicted_values) / test_series), na.rm = TRUE) * 100,
      row.names = NULL
    )
  }
  
  dplyr::bind_rows(rows)
}
```

## ARIMAX model utilities

Same functions must be adapted for ARIMAX fitting study. 

```{r, warning=FALSE, message=FALSE}
fitting_function_arimax <- function(p, d, q, xreg_train) {
  function(y, xreg_y) {
    Arima(y, order = c(p, d, q), xreg = xreg_y)
  }
}

fit_auto_arimax <- function(y, xreg) {
  auto.arima(y, xreg = xreg)
}
```


```{r, warning=FALSE, message=FALSE}
rolling_forecast_arimax <- function(train_series, test_series, xreg_train, xreg_test, fitting_function, 
                                    max_steps = 5, horizons = c(1, 3, 5)) {
  
  test_len <- length(test_series)
  confidence_interval <- 95
  outputs <- matrix(NA_real_, nrow = test_len, ncol = length(horizons), dimnames = list(NULL, paste0("h", horizons)))
  
  rolling_series <- train_series
  rolling_xreg <- xreg_train
  
  for (i in seq_len(test_len)) {
    
    model <- fitting_function(rolling_series, rolling_xreg)

    xreg_forecasting <- xreg_test[i:min(i + max_steps - 1, nrow(xreg_test)), , drop = FALSE]
    
    forecast_values <- forecast(model, h = nrow(xreg_forecasting),  xreg = xreg_forecasting, level = confidence_interval)$mean
    
    for (h in horizons) {
      idx <- i + h - 1
      if (idx <= test_len)
        outputs[idx, paste0("h", h)] <- forecast_vals[h]
    }
    
    rolling_series <- c(rolling_series, test_series[i])
    rolling_xreg <- rbind(rolling_xreg, xreg_test[i, , drop = FALSE])
  }
  
  return(outputs)
}
```

```{r, warning=FALSE, message=FALSE}
make_horizon_plots_arimax <- function(train_series, test_series, xreg_train, xreg_test, fitting_fixed_function,
                                      fitting_auto_function,horizons = c(1,3,5)) {
  
  pred_fixed <- rolling_forecast_arimax(train_series, test_series, xreg_train, xreg_test, 
                                        fitting_function =fitting_fixed_function, max_steps = max(horizons), horizons = horizons)
  
  pred_auto <- rolling_forecast_arimax(train_series, test_series, xreg_train, xreg_test,
    fitting_function = fitting_auto_function, max_steps = max(horizons), horizons = horizons)
  
  df_fixed <- as.data.frame(pred_fixed) %>%
    mutate(year = time(test_series)) %>%
    pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
    mutate(Value = exp(as.numeric(Value)), Model = "Fixed")
  
  df_auto <- as.data.frame(pred_auto) %>%
    mutate(year = time(test_series)) %>%
    pivot_longer(-year, names_to = "Horizon", values_to = "Value") %>%
    mutate(Value = exp(as.numeric(Value)), Model = "Auto")
  
  df_actual <- data.frame(
    year = time(test_series),
    Horizon = "Actual",
    Model = "Actual",
    Value = exp(as.numeric(test_series))
  )
  
  plot_df <- bind_rows(df_actual, df_fixed, df_auto) %>%
    mutate(Horizon = factor(Horizon, levels = c("h1", "h3", "h5", "Actual")))
  
  make_single_plot <- function(h) {
    ggplot(filter(plot_df, Horizon == h | Model == "Actual"), aes(x = year, y = Value, colour = Model, linetype = Model)) +
      geom_line(na.rm = TRUE) +
      scale_colour_manual(values = c(Actual = "#1f77b4", Auto   = "#6ba292" , Fixed  = "#ff7f0e")) +
      scale_linetype_manual(values = c(Actual = "solid", Auto   = "dashed", Fixed  = "dashed")) +
      labs(title = "",  x = "Year", y = "Number of deaths", colour = "Model", linetype = "Model") +
      theme_minimal(base_size = 13)
  }
  
  plots <- lapply(paste0("h", horizons), make_single_plot)
  names(plots) <- paste0("h", horizons)
  return(plots)
}

#paste("Forecast horizon:", h)

```

```{r, warning=FALSE, message=FALSE}
make_country_plots_arimax <- function(country, p, d, q, start_year, horizons = c(1, 3, 5)) {
  
  train_raw <- countries_short[[country]]$train$number_deaths
  test_raw  <- countries_short[[country]]$test$number_deaths
  
  train_ts <- ts(log(train_raw), start = start_year, frequency = 1)
  test_ts  <- ts(log(test_raw),  start = end(train_ts)[1] + 1, frequency = 1)
  
  xreg_train <- data.frame(
    population  = ts(log(countries_short[[country]]$train$population),  start = start_year, frequency = 1),
    gdp_capita  = ts(log(countries_short[[country]]$train$gdp_capita),  start = start_year, frequency = 1)
  )
  
  xreg_test <- data.frame(
    population  = ts(log(countries_short[[country]]$test$population),  start = end(train_ts)[1] + 1, frequency = 1),
    gdp_capita  = ts(log(countries_short[[country]]$test$gdp_capita),  start = end(train_ts)[1] + 1, frequency = 1)
  )
  
  fit_fixed_fun <- function(y, xreg) Arima(y, order = c(p, d, q), xreg = xreg)
  fit_auto_fun  <- function(y, xreg) auto.arima(y, xreg = xreg, stepwise = FALSE, approximation = FALSE)
  
  make_horizon_plots_arimax(train_ts, test_ts, xreg_train = as.matrix(xreg_train),
                            xreg_test  = as.matrix(xreg_test), fitting_fixed_function, fitting_auto_function, horizons = horizons)
}
```

```{r}
rolling_arimax_predictions_single <- function(train_series, test_series, xreg_train, xreg_test, fitting_function, max_steps = 5, horizons = c(1, 3, 5)) {
  
  rolling_forecast_arimax(train_series, test_series, xreg_train, xreg_test, fitting_function, max_steps = max_steps, horizons = horizons)
}
```

## ARIMA models

In this section, we analyze the temporal dynamics of tuberculosis-related mortality across the selected European countries using ARIMA models. Each country will be studied individually, beginning with an exploratory analysis of the log-transformed mortality data. Model parameters (p,d,q) will be selected based on empirical diagnostics such as the ACF/PACF plots and the AIC. The adequacy of each model will be verified through residual analysis.

### Spain

We begin our analysis with the Spanish dataset, which spans from 1951 to 2021 and comprises 71 annual observations. Given the long time span and the observed declining trend in raw counts, a logarithmic transformation is applied to stabilize variance and linearize the trend. The figure below shows the log-transformed training time series for tuberculosis mortality in Spain.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain <- ts(log(country_splits[["Spain"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Spain"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Spain"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

In order to formally assess whether the series is stationary, we apply the Augmented Dickey-Fuller (ADF) test:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain)
```

As expected, the high $p$-value indicates that we fail to reject the null hypothesis, which suggests that the series is non-stationary. In this case, applying a first-order difference is recommended.

We can apply the ADF test to the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_spain %>% diff())
```

The test $p$-value ensures the stationarity of the time series. Now, we check the ACF and PACF of the differenced time series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_spain %>% diff())
custom_pacf_plot(train_spain %>% diff())

```

The ACF of the differenced series shows a strong spike at lag 0. Beyond that, no significant spikes appear—autocorrelations at higher lags lie well within the confidence bounds. This suggests there is no strong moving average (MA) structure in the differenced series.

Similarly, the PACF displays only minor fluctuations, with all values remaining inside the confidence intervals. This indicates no clear autoregressive (AR) component is present either.

We begin the model selection and the forecast step. First, the auto.arima model is applied.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain <- ts(log(country_splits[["Spain"]]$test$number_deaths), start = 2011,  frequency = 1)

fit_spain_auto <- auto.arima(train_spain)

summary(fit_spain_auto)

```

The ARIMA autogenerated is an ARIMA(0,2,1), meaning that it has differenced the series twice and has an MA component left. The AIC is quite low ($-100,25$), indicating that it can be a good model. Looking at the error measures of the training set, the model shows good performance, with an RMSE of $0.096$ and a MAPE below $1$% on the log-transformed training set. The low MAE and near-zero ACF1 ($-0.03$) indicate well-behaved residuals and a solid overall fit.

Before the forecast, we need to check on the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_auto %>% forecast::checkresiduals()

shapiro.test(residuals(fit_spain_auto))
```

The ARIMA($0,2,1$) passes both the Ljung-Box test and the Shapiro-Wilk normality test, indicating that the residuals do not present any temporal structure left.

We now proceed with the forecasting stage. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_spain,           
  test_spain,            
  fit_auto,     
  max_steps = 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_spain, pred_log, horizon = 1)
plot_rolling_forecast_single(test_spain, pred_log, horizon = 3)
plot_rolling_forecast_single(test_spain, pred_log, horizon = 5)


```
We check the error measures:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

preds_log <- rolling_predictions_single(train_spain, test_spain, fit_auto)
error_summary <- rolling_error_metrics_single( test_series = exp(test_spain), predictions = exp(preds_log))
error_summary
```
Over the one-, three-, and five-step horizons, forecast accuracy steadily deteriorates: RMSE rises from roughly 34.8 to 43.3, MAE from 25.4 to 34.0, and MAPE from 9.7 % to 14.6 %. At the same time, the mean error shifts from a modest negative bias (−5.6) at h1 to a small positive bias (+3.5) by h5, indicating the model moves from slight over-prediction to slight under-prediction as the horizon lengthens. 

We will now manually select another model usin the `try_all_arima` function. We choose a 1 order difference, as the series showed stationarity after the differencing.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ma_coef = c(0,1)
ar_coef = c(0,1)

try_all_arima(ar_coef, 1, ma_coef, train_spain)
```

The function shows that the two models with the smallest AIC is the ARIMA($2,1,2$).

We check the residuals of the models:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_spain_111 <- Arima(train_spain, order = c(1,1,1))

fit_spain_111 %>% 
  forecast::checkresiduals()

shapiro.test(residuals(fit_spain_111))
```

The residuals of the ARIMA($2,1,2$) do not satisfy normality hypothesis.

Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
pred_log <- rolling_predictions_single(
  train_spain,           
  test_spain,            
  fitting_function(1,1,1),     
  max_steps = 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_spain, pred_log, horizon = 1)
plot_rolling_forecast_single(test_spain, pred_log, horizon = 3)
plot_rolling_forecast_single(test_spain, pred_log, horizon = 5)

```
Let's check the error measures of the test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

preds_log <- rolling_predictions_single(train_spain, test_spain, fitting_function(1,1,1))
error_summary <- rolling_error_metrics_single(
  test_series = exp(test_spain),
  predictions  = exp(preds_log)
)


error_summary
```
At horizon h1, the forecast exhibits a moderate negative bias (ME = –9.6) with RMSE 36.2, MAE 26.4, and MAPE 10.5 %. For h3, the bias remains negative (ME = –7.4); the associated errors are RMSE 39.7, MAE 30.4, and MAPE 13.0 %. At h5, the bias is nearly neutral (ME = –0.6), while the error measures reach RMSE 44.5, MAE 32.5, and MAPE 13.9 %.

**Final conclusions**

Let's do a summary of the Spain models applied.

```{r, warning=FALSE, message=FALSE, echo = FALSE}


get_error_metrics("Spain",1,1,1,1951)

```

Across all short-range horizons, the auto ARIMA outperforms the manually specified model, but that advantage fades—and partially reverses—by the five-step forecast. At h1, auto’s error measures are uniformly lower: RMSE 34.8 versus 36.2, MAE 25.4 versus 26.4, and MAPE 9.7 % versus 10.5 %; its bias is also closer to zero (ME –5.6 compared with –9.6). At h3, the pattern holds, though the gap narrows: Auto trims RMSE to 36.7 (vs 39.7) and improves percentage error to 12.4 % (vs 13.0 %), while the two models’ MAE values differ by only a few tenths.

By h5, the balance changes slightly. Auto still records the lower RMSE (43.3 vs 44.5), indicating a marginally tighter spread of errors, but the manual model now posts the smaller absolute and percentage errors (MAE 32.5 vs 34.0; MAPE 13.9 % vs 14.6 %) and its bias (ME –0.6) sits nearer to zero than auto’s positive 3.5. In sum, the Auto ARIMA is the safer, more accurate option for one- to three-step horizons, whereas the manual specification yields marginally better point-estimate accuracy at five steps, albeit with a slightly wider overall error dispersion.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

make_country_plots("Spain",1,1,1,1951)
```

### The Netherlands

We study the Netherlands.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_netherlands <- ts(log(country_splits[["Netherlands"]]$train$number_deaths), start = 1950,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Netherlands"]]$full$number_deaths), start = 1950,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Netherlands"]]$full$number_deaths, start = 1950, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_netherlands)
```

The training series is not stationary.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_netherlands %>% diff())
custom_pacf_plot(train_netherlands %>% diff())
```

After apply a first order difference, the series ACF plot shows a significant spike at lag 4, and the PACF plot shows significant spikes at lags 4 and 7. We will begin studying the simplest model and the autogenerate model of auto.arima().

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto <- auto.arima(train_netherlands )
summary(fit_netherlands_auto)
```
The auto generated model is the ARIMA(0,1,0).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_auto))
```

The residuals for the autogenerate model do not satisfy the hypothesis.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
ar_coef = c(2,3,4)
ma_coef = c(2,3)
try_all_arima(ar_coef , 1, ma_coef, train_netherlands)

fit_netherlands_213 <- Arima(train_netherlands, order = c(2,1,3))
fit_netherlands_213
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_netherlands_213 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_netherlands_213))
```

The residuals of the 2,1,3 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Netherlands", 2,1,3, 1950)
get_error_metrics("Netherlands", 2,1,3, 1950)
```

### Switzerland

We study Switzerland.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_switzerland <- ts(log(country_splits[["Switzerland"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Switzerland"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Switzerland"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2011, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ACF and PACF of the log-transformed series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
custom_acf_plot(train_switzerland)
custom_pacf_plot(train_switzerland)
```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_switzerland)
kpss.test(train_switzerland %>% diff())
```

Notably, the series passes the ADF test without differencing, suggesting stationarity. However, the visual inspection reveals a clear downward trend, which contradicts this result and raises concerns about potential non-stationarity. To clarify this discrepancy, we applied the KPSS test, which assumes stationarity as the null hypothesis. The KPSS result ($p$-value of $0.01$) leads us to reject stationarity, thereby supporting the use of first-order differencing before model fitting. 

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto <- auto.arima(train_switzerland )
summary(fit_switzerland_auto)
```
The auto generated model is the ARIMA(0,1,1).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_auto))
```

The residuals for the autogenerate model do not satisfy the normality hypothesis.

```{r}
custom_acf_plot(train_switzerland %>% diff())
custom_pacf_plot(train_switzerland %>% diff())
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}

p <- c(0,1)
q <- c(0,1)

try_all_arima(p,1,q,train_switzerland)
fit_switzerland_111 <- Arima(train_switzerland, order = c(1,1,1))
fit_switzerland_111
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_switzerland_111 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_switzerland_111))
```

The residuals of the 1,0,0 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Switzerland", 1,1,1, 1951)
get_error_metrics("Switzerland", 1,1,1, 1951)
```
At every horizon the Auto specification outclasses the Manual one, and the gap widens as you look further ahead.

h1 (one-step). Auto posts lower errors across the board—RMSE 6.30 vs 7.22, MAE 5.25 vs 6.04, MAPE 37 % vs 45 %. Its mean error flips sign to a small positive (+0.39) while Manual shows a larger negative bias (–1.25), so Auto is both more accurate and less biased.

h3 (three-step). The advantage grows markedly. Auto trims RMSE by almost two points (7.20 vs 9.12) and cuts MAE from 8.15 to 5.91. Most striking is the percentage error: MAPE plunges from 62.6 % to 42.1 %. Bias virtually disappears in Auto (ME ≈ +0.07) but remains strongly negative in Manual (–4.58), confirming that the Manual model keeps under-predicting while Auto stays close to the mark.

h5 (five-step). Auto’s lead becomes decisive. RMSE falls to 5.02 (vs 6.99) and MAE to 3.64 (vs 6.00); MAPE is slashed to 18.4 %, less than half the Manual model’s 41.2 %. Manual still carries a large negative bias (–4.75), whereas Auto shows a moderate positive one (+2.20). Even allowing for that tilt, Auto’s absolute bias is smaller than Manual’s and its overall errors are dramatically lower.

Bottom line: The Manual model systematically under-predicts and accumulates large relative errors, especially beyond the first step, while the Auto ARIMA remains much closer to zero bias and delivers substantially tighter error metrics at all horizons—most dramatically at three and five steps. For both near-term and longer-range forecasting, Auto is the clearly preferable choice.
### Sweden

We study Sweden

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_sweden<- ts(log(country_splits[["Sweden"]]$train$number_deaths), start = 1951,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Sweden"]]$full$number_deaths), start = 1951,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Sweden"]]$full$number_deaths, start = 1951, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2

```

ACF and PACF of the log-transformed series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(train_sweden)
pacf(train_sweden)
```

ADF test to study stationarity.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_sweden %>% diff())
```

The training series is not stationary. 

We need to difference the series.
```{r, warning=FALSE, message=FALSE, echo = FALSE}

custom_acf_plot(train_sweden %>% diff())
custom_pacf_plot(train_sweden %>% diff())

```

The series ACF plot a significant first lag, and the PACF plot shows significant spikes at lag 1 and 8.  We will study an ARIMA(1,1,1)

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto <- auto.arima(train_sweden )
summary(fit_sweden_auto)
```
The auto generated model is the ARIMA(0,1,1).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_auto %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_auto))
```

The residuals for the autogenerate model satisfy the hypothesis.

```{r}
p <- c(0,1,8)
q <- c(0,1,8)
  
try_all_arima(p,1,q, train_sweden)
```


```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_sweden_810 <- Arima(train_sweden, order = c(8,1,0))
fit_sweden_810
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_sweden_810 %>% forecast:: checkresiduals()
shapiro.test(residuals(fit_sweden_810))
```

The residuals of the 1,0,0 model pass the Ljung-Box test but not the normality one.

```{r}
make_country_plots("Sweden", 8,1,0, 1951)
get_error_metrics("Sweden", 8,1,0, 1951)
```
### Bulgaria

Now, we study Bulgaria data. As seen in the introduction, Bulgaria has a different trend for number_deaths series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_bulgaria <- ts(log(country_splits[["Bulgaria"]]$train$number_deaths), start = 1964, end = 2011,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Bulgaria"]]$full$number_deaths), start = 1964,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Bulgaria"]]$full$number_deaths, start = 1964, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

We will work with the logarithmic data. We check both ACF and PACF plots:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(train_bulgaria)
pacf(train_bulgaria)

```

The ACF shows an exponential decay, while the PACF shows a single significant spike at lag 1. This suggest an AR($1$) process. However, the series is not stationary (as seen in the plot, and justified by the ADF test, with a $p$-value of 0.05173).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria %>% diff(differences = 2))
```

Let's see which ARIMA order proposes the auto.arima() function.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto <- auto.arima(train_bulgaria)

summary(fit_bulgaria_auto)
```

The model proposed is an ARIMA(0,1,0) with drift. We need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_auto))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_bulgaria,          
  test_bulgaria,            
  fit_auto,     
  max_steps = 5,
  horizons  = c(1,3,5)
)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 1)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 3)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 5)
```

Let's check the error measures of the test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_bulgaria <- log(country_splits[["Bulgaria"]][["test"]][["number_deaths"]])

preds_log <- rolling_predictions_single(train_bulgaria, test_bulgaria, fit_auto)
error_summary <- rolling_error_metrics_single(
  test_series = exp(test_bulgaria),
  predictions = exp(preds_log)
)

error_summary
```

At the one-step horizon (h1), the model shows a moderate negative bias (ME = –6.3) and error levels of RMSE 12.8, MAE 11.4, and MAPE 12.5 %. By the three-step horizon (h3), bias deepens to –16.8 and all error measures rise noticeably: RMSE 20.5, MAE 17.1, MAPE 19.2 %. At the five-step horizon (h5), the downward drift continues—bias reaches –25.0, while RMSE expands to 28.6, MAE to 25.0, and MAPE to 31.4 %.

Overall: forecast accuracy deteriorates steadily with longer lead times, and the model increasingly under-predicts the target variable, as reflected in the growing negative mean error and the sharp escalation in RMSE, MAE, and MAPE.

To improve accuracy, we will explore an AR(1) structure: the ACF/PACF of the series both suggest a significant lag‐1 dependence, so fitting ARIMA(1,1,0) may better track the curvature in the decline.

```{r}
custom_acf_plot(train_bulgaria %>% diff())
custom_pacf_plot(train_bulgaria %>% diff())

custom_acf_plot(train_bulgaria %>% diff(differences = 2))
custom_pacf_plot(train_bulgaria %>% diff(differences = 2))
```

```{r}
ar_coef = c(0,1)
ma_coef = c(1)
try_all_arima(ar_coef, 2, ma_coef, train_bulgaria)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_021 <- Arima(train_bulgaria, order = c(0,2,1))

summary(fit_bulgaria_021)
```

The AIC has a value of $-72.35$, meaning it could be a good fit. We check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_bulgaria_021 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_bulgaria_021))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}


pred_log <- rolling_predictions_single(
  train_bulgaria,          
  test_bulgaria,            
  fitting_function(0,2,1),     
  max_steps = 5,
  horizons  = c(1,3,5)
)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 1)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 3)
plot_rolling_forecast_single(test_bulgaria, pred_log, horizon = 5)


```


Let's check the error measures of the logarithmic test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

preds_log <- rolling_predictions_single(train_bulgaria, test_bulgaria, fitting_function(0,2,1))

error_summary <- rolling_error_metrics_single(
  test_series = exp(test_bulgaria),
  predictions  = exp(preds_log)
)
error_summary
```

**Final conclusions**

Let's do a summary of the Bulgarian models applied.

```{r}
make_country_plots("Bulgaria", 0,2,1, 1964)
```


```{r}
get_error_metrics("Bulgaria", 0,2,1, 1964)
```


### Estonia

Now, we study Estonia data.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
country_splits[["Estonia"]]$train

train_estonia <- ts(log(country_splits[["Estonia"]]$train$number_deaths), start = 1981, end = 2011,  frequency = 1)

p1 <- plot_ts(ts(log(country_splits[["Estonia"]]$full$number_deaths), start = 1981,  frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Log-transformed time series",
    x = "Year",
    y = "Logarithm of the number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p2 <- plot_ts(ts(country_splits[["Estonia"]]$full$number_deaths, start = 1981, frequency = 1)) +
  geom_vline(xintercept = 2012, linetype = "dashed", color = "#1f77b4") +
  theme_minimal() +
  labs(
    #title = "Original time series",
    x = "Year",
    y = "Number of deaths"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 13)
  )

p1
p2
```

In order to stabilize the variance of the series, we will work with the logarithmic data.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia)
```

The $p$-value of the ADF test is higher than $0,05$, so the series is non-stationary. We check both ACF and PACF plots.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(train_estonia)
pacf(train_estonia)

```

The ACF shows an exponential decay, while the PACF shows a single significant spike at lag 1. This suggest an AR($1$) process. However, the series is not stationary (as seen in the plot, and justified by the ADF test, with a $p$-value of $0.543$).

Let's see which ARIMA order proposes the auto.arima() function.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_auto <- auto.arima(train_estonia)

summary(fit_estonia_auto)
```

The model proposed is an ARIMA(1,0,0) with non-zero mean. We need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_auto %>% forecast::checkresiduals()
shapiro.test(residuals(fit_estonia_auto))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_estonia,           
  test_estonia,            
  fit_auto,    
  max_steps= 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_estonia, pred_log, horizon = 1)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 3)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 5)



```


Let's check the error measures of the test data:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_estonia <- ts(log(country_splits[["Estonia"]][["test"]][["number_deaths"]]), start = 2012, frequency = 1)

preds_log <- rolling_predictions_single(train_estonia, test_estonia, fit_auto)

error_summary <- rolling_error_metrics_single(
  test_series = exp(test_estonia),
  predictions  = exp(preds_log)
)
error_summary
```
Let's propose a different model. Based on the ADF test, the log-transformed series is not stationary. We begin by checking the ACF and PACF plots of the differenced time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_estonia %>% diff(differences = 2))

custom_acf_plot(train_estonia %>% diff())
custom_pacf_plot(train_estonia %>% diff())

custom_acf_plot(train_estonia %>% diff(differences = 2))
custom_pacf_plot(train_estonia %>% diff(differences = 2))

```

```{r}
ar_coef = c(1)
d = c(1,2)
ma_coef = c(0,1)

try_all_arima(ar_coef,d,ma_coef, train_estonia)
```

Once differenced, the time series does not present any temporal structure left. We study the ARIMA(1,1,0).

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_110 <- Arima(train_estonia, order = c(1,1,0))

summary(fit_estonia_110)
```

Let's check the residuals of the model

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_estonia_110 %>% forecast::checkresiduals()
shapiro.test(residuals(fit_estonia_110))
```

The residuals seem to pass both Ljung-Box test and Shapiro-Wilk normality test. Now, we can forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

pred_log <- rolling_predictions_single(
  train_estonia,           
  test_estonia,            
  fitting_function(1,1,0),    
  max_steps = 5,
  horizons  = c(1,3,5)
)

plot_rolling_forecast_single(test_estonia, pred_log, horizon = 1)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 3)
plot_rolling_forecast_single(test_estonia, pred_log, horizon = 5)


```

```{r}
preds_log <- rolling_predictions_single(train_estonia, test_estonia, fitting_function(1,1,0))

error_summary <- rolling_error_metrics_single(
  test_series = exp(test_estonia),
  predictions  = exp(preds_log)
)

error_summary
```

Comparison:

```{r}
make_country_plots("Estonia", 1,1,0, 1981)
get_error_metrics("Estonia", 1,1,0, 1981)
```


## ARIMAX models

We have seen that ARIMA models are quite simple in order to do a well-suited forecast for our studied series. In this section we will study ARIMAX models; ARIMAX models are ARIMA models that include some exogenous variables in order to get better forecastings rather than basic ARIMA. In our study, we will consider two exogenous variables: Gross Domestic Product per capita and the country population.

First, we visualize these series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables <- full_dataset %>% 
  filter(country_name %in% c("Spain", "Switzerland", "Sweden", "Netherlands", "Estonia", "Bulgaria")) %>% 
  select(year, country_name, population,  gdp_capita) %>% 
  arrange(year)

```

We begin analysing the Population variable.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

exogenous_variables %>%  
  ggplot(aes(x = year, y = population/1000000, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries population trends")+
  theme(legend.position = "right") +
  ylab("Population (in millions)")

```

In stark contrast with the other countries, Spain population has a strong increasing trend, climbing from around 28 million in 1950 to nearly 48 million by 2020. The Netherlands also grows steadily, from about 10 million to roughly 18 million. Sweden’s population increases more modestly, moving from approximately 7 million to just over 10 million, while Switzerland rises from about 5 million to nearly 9 million over the same period.

In contrast, Bulgaria peaks near 9 million in the 1980s before gradually declining to about 7 million by 2020, and Estonia remains the smallest, hovering around 1.7 million in 1980 but falling slightly to around 1.3 million by 2020. The plot clearly highlights Spain’s large and sustained growth, moderate increases for Northern and Western European countries, and population declines in Eastern Europe.

Now, let's visualize the GDP per capita tendencies:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
exogenous_variables %>%  
  ggplot(aes(x = year, y = gdp_capita, color = country_name)) +  
  geom_line() +
  scale_color_manual(values = c(
    "Bulgaria" = "#04A3BDFF",    
    "Switzerland" = "#F0BE3DFF",    
    "Estonia" = "#931E18FF",    
    "Sweden" = "#DA7901FF",   
    "Spain" = "#247D3FFF",    
    "Netherlands" = "#20235BFF"    
  )) + 
  theme_minimal() +
  ggtitle("Chosen countries GDP per capita trends")+
  theme(legend.position = "right") +
  ylab("GDP per capita (in current U.S. dollars)")
```

Now, the outlook is quite different; Switzerland leads the list, climbing from around \$2,000 in 1960 to over \$90,000 by 2020, with sharp surges in the late 1990s and post-2005. Following Switzerland, the Netherlands and Sweden follow a similar upward trajectory. Spain increases more modestly, from under \$1,000 to a peak of around \$35,000 by 2008, then levels out in the \$25,000–\$30,000 range.Estonia lags until independence—remaining near zero through the Soviet era—then surges after 1992 from around \$2,000 to approximately \$25,000 by 2020. Bulgaria also starts below \$1,000, grows gradually through the 1980s, dips in the 1990s, and then climbs to roughly \$12,000 by 2020.

Overall, Switzerland, Sweden, and the Netherlands display long-term, high-income growth; Spain shows moderate growth with a plateau post-2008; and the Eastern European countries (Estonia and Bulgaria) demonstrate rapid catch-up following post-1990 transitions.

Before beginning the ARIMAX section, it is important to give special attention to the length of each of the variables, just to ensure that the studied variable (number_deaths) length coincides with the covariables length.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

get_all_lengths <- function(countries) {
  data.frame(
    Country = countries,
    number_deaths_length = sapply(countries, function(cn) get_length(cn, "full", "number_deaths")),
    population_length = sapply(countries, function(cn) get_length(cn, "full", "population")),
    gdp_capita_length = sapply(countries, function(cn) get_length(cn, "full", "gdp_capita")),
    row.names = NULL
  )
}

lengths_df <- get_all_lengths(chosen_countries)

lengths_df

```

It is necessary that all variable have the same length; we create a function in order to automate this step.

```{r}

slice_country_data <- function(country, start_year) {
  df_full <- country_splits[[country]][["full"]]
  df_filtered <- df_full %>%
    filter(year >= start_year) %>%
    arrange(year)  

  return(df_filtered)
}

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short <- hashmap()

countries_short[["Spain"]][["full"]] <- slice_country_data("Spain", 1960)
countries_short[["Netherlands"]][["full"]] <- slice_country_data("Netherlands", 1960)
countries_short[["Sweden"]][["full"]] <- slice_country_data("Sweden", 1960)
countries_short[["Switzerland"]][["full"]] <- slice_country_data("Switzerland", 1960)
countries_short[["Estonia"]][["full"]] <- slice_country_data("Estonia", 1993)
countries_short[["Bulgaria"]][["full"]] <- slice_country_data("Bulgaria", 1980)


```

Now, we need to divide these new series into a training and a testing set. We will do the split, ensuring that the 80% of the data is used for training.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
test_lengths_per_country_short = hashmap()

test_lengths_per_country_short[["Spain"]] = 12
test_lengths_per_country_short[["Switzerland"]] = 12
test_lengths_per_country_short[["Sweden"]] = 12
test_lengths_per_country_short[["Estonia"]] = 6
test_lengths_per_country_short[["Netherlands"]] = 12
test_lengths_per_country_short[["Bulgaria"]] = 8
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
for (country in chosen_countries) {
  country_dataset = countries_short[[country]]$full
  total_len = nrow(country_dataset)
  test_len = test_lengths_per_country_short[[country]]
  countries_short[[country]][["train"]] = country_dataset[1:(total_len - test_len ),]
  countries_short[[country]][["test"]] = country_dataset[(total_len - test_len + 1):total_len,]
}


```

Now that we have prepared the dataset, we can begin the ARIMAX study.

### Spain

We begin studying Spain data. First, let's plot all three variables (number_deaths, population and gdp_capita) in the same plot.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_spain_arimax_plot <- data.frame(
  Year = countries_short[["Spain"]][["full"]]$year,
  number_deaths = countries_short[["Spain"]][["full"]]$number_deaths,
  population = countries_short[["Spain"]][["full"]]$population,
  gdp_capita = countries_short[["Spain"]][["full"]]$gdp_capita
)

ggplot(df_spain_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  geom_vline(xintercept = 2010, linetype = "dashed", color = "black") +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Spain",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain_short <- ts(log(countries_short[["Spain"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_spain_train <- data.frame(
  population = ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)


make_country_plots("Spain", 1,1,1, 1960, TRUE)

fit_arimax_spain <- auto.arima(train_spain_short, xreg= as.matrix(xreg_spain_train ))

summary(fit_arimax_spain)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_spain %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_spain))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain_short <- ts(log(countries_short[["Spain"]][["test"]][["number_deaths"]]), start = 2010, frequency = 1)

xreg_spain_test <- data.frame(
  population = ts(log(countries_short[["Spain"]][["test"]][["population"]]), start = 2010, frequency = 1),
  gdp_capita = ts(log(countries_short[["Spain"]][["test"]][["gdp_capita"]]), start = 2010, frequency = 1)
)

forecastx_spain_200 <- forecast(fit_arimax_spain, level = c(95), h = length(test_lengths_per_country_short[["Spain"]]), xreg = as.matrix(xreg_spain_test))

forecastx_spain_200
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_spain_200) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMAX(2,0,0)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_spain_200) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(2,0,0)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_spain_log_200 <- data.frame(
  Year = seq_along(test_spain_short),
  Actual = test_spain_short,
  Predicted_arimax = forecastx_spain_200$mean
)


ggplot(plot_spain_log_200, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(2,0,0)",
  ME = mean(test_spain_short - forecastx_spain_200$mean),
  RMSE = rmse(test_spain_short ,forecastx_spain_200$mean),
  MPE = mean((test_spain_short - forecastx_spain_200$mean) / test_spain_short) * 100,
  MAE = mae(test_spain_short, forecastx_spain_200$mean),
  MAPE = mape(test_spain_short ,forecastx_spain_200$mean) * 100
)


error_summary
```

The ARIMAX(2,0,0) model exhibits a slight overestimation bias (ME = $–0.36$) and moderate overall error (RMSE = $0.40$, MAE = $0.37$) on the log‐transformed series. Its MPE of $–6.57$% and MAPE of $6.76$% indicate that, on average, forecasts overshoot actual logarithmic values by around $6.8$%, suggesting that while the exogenous variables help, there remains room for improvement in capturing the downward trajectory of TB deaths.

In order to improve our ARIMAX model beyond what `auto.arima()` suggested, we will now inspect each differenced series manually (the response and both regressors) and choose orders $p$ and $q$ based on the ACF/PACF patterns, rather than relying on automatic selection. Recall that all three series (log(number_deaths), log(population) and log(gdp_capita)) are non‐stationary, so we first take first differences.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_spain_short_diff <- train_spain_short %>% diff()

acf(train_spain_short_diff)
pacf(train_spain_short_diff)
```

The ACF plot shows a large, significant spike at lag 1, and then quickly dies off. In the same way, the PACF plot shows a significant spike at lag 1, with all higher partial autocorrelations inside the confidence bounds. These patterns suggest an ARIMA($p,1,q$) where one of $p$ or $q$ should be 1.

Next, we difference the log⁡(population) series over the same short training period:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
population_spain_diff <- ts(log(countries_short[["Spain"]][["train"]][["population"]]), start = 1960, frequency = 1) %>% diff()

acf(population_spain_diff)
pacf(population_spain_diff)
```

TH ACF plot shows a slow exponential decay over the first few lags. In contrast, the PACF shows a single large spike at lag 1, and then subsequent lags are essentially within the confidence bounds. This pattern is characteristic of an AR($1$) process.

Finally, we difference the log(gdp_capita) series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
gdp_capita_spain_diff <- ts(log(countries_short[["Spain"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1) %>% diff()

acf(gdp_capita_spain_diff)
pacf(gdp_capita_spain_diff)
```

The ACF plot shows a large spike at lag 1 and smaller but non-negligible negative values at lags 3-7 and 9-11. On the other hand, the PACF also shows a strong negative spike at lag 5, and samller spikes between lags 6 and 15, but the dominant feature is the large positive spike at lag 1.

This may suggest that the series may require both an AR($1$) and possibly an MA component to capture the very strong lag-1 autocorrelation.

Putting all together, we propose the ARIMA($1,1,1$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_spain_111 <- Arima(train_spain_short, order = c(1,1,1), xreg = as.matrix(xreg_spain_train))
fit_arimax_spain_111
```

The value of the AIC ($-107.89$) indicates a well-suited fit. Now, we need to check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_spain_111 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_spain_111))
```

The model's residuals pass both normality and Ljung-Box tests. Now, we do the forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
forecastx_spain_111 <- forecast(fit_arimax_spain_111, level = c(95), h = length(test_lengths_per_country_short[["Spain"]]), xreg = as.matrix(xreg_spain_test))

forecastx_spain_111

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_spain_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMAX(1,1,1)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_spain_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Spain using ARIMA(1,1,1)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_spain_log_111 <- data.frame(
  Year = seq_along(test_spain_short),
  Actual = test_spain_short,
  Predicted_arimax = forecastx_spain_111$mean
)


ggplot(plot_spain_log_111, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,1,1)",
  ME = mean(test_spain_short - forecastx_spain_111$mean),
  RMSE = rmse(test_spain_short ,forecastx_spain_111$mean),
  MPE = mean((test_spain_short - forecastx_spain_111$mean) / test_spain_short) * 100,
  MAE = mae(test_spain_short, forecastx_spain_111$mean),
  MAPE = mape(test_spain_short ,forecastx_spain_111$mean) * 100
)


error_summary
```

The ARIMAX($1,1,1$) model yields a small overestimation bias (ME = $–0.35$) and moderate error magnitude (RMSE = $0.396$, MAE = $0.362$) on the log‐transformed series. Its MPE of $–6.42$% and MAPE of $6.64$% indicate that forecasts tend to overshoot actual values by roughly $6.6$%, reflecting improved but still imperfect tracking of the downward TB‐death trend.

**Final conclusions**

Let's do a summary of the Spain models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_spain_real_short <- exp(test_spain_short)
predx_spain_auto <- exp(forecastx_spain_200$mean)
predx_spain_111 <- exp(forecastx_spain_111$mean)


plot_spain_arimax <- data.frame(
  Year = seq_along(test_spain_real_short),
  Actual = test_spain_real_short,
  Predicted_auto= predx_spain_auto,
  Predicted_111 = predx_spain_111
)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
arimax_error_summary_spain <- data.frame(
  Model = c("ARIMA(2,0,0)", "ARIMA(1,1,1)"),
  ME = c(mean(test_spain_real_short - predx_spain_auto),
         mean(test_spain_real_short - predx_spain_111)),
  
  RMSE = c(rmse(test_spain_real_short, predx_spain_auto),
           rmse(test_spain_real_short, predx_spain_111)),
  
  MPE = c(mean((test_spain_real_short - predx_spain_auto) / test_spain_real_short) * 100,
          mean((test_spain_real_short - predx_spain_111) / test_spain_real_short) * 100),
  
  MAE = c(mae(test_spain_real_short, predx_spain_auto),
          mae(test_spain_real_short, predx_spain_111)),
  
  MAPE = c(mape(test_spain_real_short, predx_spain_auto) * 100,
           mape(test_spain_real_short, predx_spain_111) * 100)
)

arimax_error_summary_spain

```

The out‐of‐sample comparison on the original scale shows that ARIMA($1,1,1$) slightly outperforms ARIMA($2,0,0$). Although both models exhibit a modest overestimation bias (ME ≈ $–105$ for (2,0,0) versus $–102$ for (1,1,1)), ARIMA($1,1,1$) achieves a lower RMSE ($113.57$ vs. $116.45$), a lower MAE ($106.59$ vs. $108.95$), and a lower MAPE ($45.44$% vs. $46.50$%). In percentage terms, ARIMA($1,1,1$) also has a smaller average bias ($–44.15$% vs. $–45.41$%). Taken together, these results indicate that ARIMA($1,1,1$) provides a marginally better fit to the actual TB‐death trajectory than ARIMA($2,0,0$), making it the preferred model for forecasting.

Finally, we plot both approaches for the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

ggplot(plot_spain_arimax, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_auto, color = "Predicted_auto"), linetype = "dashed") +
  geom_line(aes(y = Predicted_111, color = "Predicted_111"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_auto" = "purple", "Predicted_111" = "red")) +
  labs(title = "Actual vs Predicted TB Deaths",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

### The Netherlands

Let's continue with the Netherlands.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_netherlands_arimax_plot <- data.frame(
  Year = countries_short[["Netherlands"]][["full"]]$year,
  number_deaths = countries_short[["Netherlands"]][["full"]]$number_deaths,
  population = countries_short[["Netherlands"]][["full"]]$population,
  gdp_capita = countries_short[["Netherlands"]][["full"]]$gdp_capita
)


ggplot(df_netherlands_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = number_deaths, color = "number_deaths")) +
  geom_line(aes(y = population/10000, color = "population")) +
  geom_line(aes(y = gdp_capita/1000, color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "The Netherlands",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()


ggplot(df_netherlands_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "The Netherlands",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Netherlands"]][["train"]]
train_netherlands_short <- ts(log(countries_short[["Netherlands"]][["train"]][["number_deaths"]]), start = 1960, frequency = 1)

xreg_netherlands_train <- data.frame(
  population = ts(log(countries_short[["Netherlands"]][["train"]][["population"]]), start = 1960, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["train"]][["gdp_capita"]]), start = 1960, frequency = 1)
)


fit_arimax_netherlands <- auto.arima(train_netherlands_short, xreg= as.matrix(xreg_netherlands_train ))

summary(fit_arimax_netherlands)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_netherlands %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_netherlands))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Netherlands"]][["test"]]
test_netherlands_short <- ts(log(countries_short[["Netherlands"]][["test"]][["number_deaths"]]), start = 2011, frequency = 1)

xreg_netherlands_test <- data.frame(
  population = ts(log(countries_short[["Netherlands"]][["test"]][["population"]]), start = 2011, frequency = 1),
  gdp_capita = ts(log(countries_short[["Netherlands"]][["test"]][["gdp_capita"]]), start = 2011, frequency = 1)
)

forecastx_netherlands_auto <- forecast(fit_arimax_netherlands, level = c(95), h = length(test_lengths_per_country_short[["Netherlands"]]), xreg = as.matrix(xreg_netherlands_test))

forecastx_netherlands_auto
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_netherlands_auto) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in the Netherlands using ARIMAX(1,0,3)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_netherlands_auto) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in the Netherlands using ARIMA(1,0,3)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_netherlands_log_auto <- data.frame(
  Year = seq_along(test_netherlands_short),
  Actual = test_netherlands_short,
  Predicted_arimax = forecastx_netherlands_auto$mean
)


ggplot(plot_netherlands_log_auto, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,0,3)",
  ME = mean(test_netherlands_short - forecastx_netherlands_auto$mean),
  RMSE = rmse(test_netherlands_short ,forecastx_netherlands_auto$mean),
  MPE = mean((test_netherlands_short - forecastx_netherlands_auto$mean) / test_netherlands_short) * 100,
  MAE = mae(test_netherlands_short, forecastx_netherlands_auto$mean),
  MAPE = mape(test_netherlands_short ,forecastx_netherlands_auto$mean) * 100
)


error_summary
```

The ARIMAX(1,0,3) model yields an ME of –0.66 and an RMSE of 0.70 on the log‐scale, indicating a modest overprediction bias and moderate overall error. Its MPE of –20.53% and MAPE of 20.53% show that predicted values typically exceed actual deaths by around 20% on average, reflecting a reasonably accurate but slightly optimistic fit.

Now, let's try to adjust another ARIMAX model, just to try to improve the error measures. The auto.arima() function does not apply any difference to the series; let's check the stationarity of the three series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_netherlands_short)

adf.test(train_netherlands_short %>% diff())
```

Yet the series is not stationary, when we apply a first order difference it passes the ADF test of stationarity. We an plot the ACf and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(train_netherlands_short %>% diff())
pacf(train_netherlands_short %>% diff())
```

Both the ACF and PACF show a significant spike at lag 2.

Now, we difference the other series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(xreg_netherlands_train$population %>% diff(differences = 2))
adf.test(xreg_netherlands_train$gdp_capita %>% diff(differences = 2))

acf(xreg_netherlands_train$population %>% diff(differences = 2))
pacf(xreg_netherlands_train$population %>% diff(differences = 2))

```

```{r}
fit_arimax_netherlands_222 <- Arima(train_netherlands_short, order = c(2,2,2), xreg = as.matrix(xreg_netherlands_train))
summary(fit_arimax_netherlands_222)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_netherlands_222 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_netherlands_222))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}

forecastx_netherlands_222 <- forecast(fit_arimax_netherlands_222, level = c(95), h = length(test_lengths_per_country_short[["Netherlands"]]), xreg = as.matrix(xreg_netherlands_test))

forecastx_netherlands_222
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_netherlands_222) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in the Netherlands using ARIMAX(2,2,2)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_netherlands_222) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in the Netherlands using ARIMA(2,2,2)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_netherlands_log_222 <- data.frame(
  Year = seq_along(test_netherlands_short),
  Actual = test_netherlands_short,
  Predicted_arimax = forecastx_netherlands_222$mean
)


ggplot(plot_netherlands_log_222, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(2,2,2)",
  ME = mean(test_netherlands_short - forecastx_netherlands_222$mean),
  RMSE = rmse(test_netherlands_short ,forecastx_netherlands_222$mean),
  MPE = mean((test_netherlands_short - forecastx_netherlands_222$mean) / test_netherlands_short) * 100,
  MAE = mae(test_netherlands_short, forecastx_netherlands_222$mean),
  MAPE = mape(test_netherlands_short ,forecastx_netherlands_222$mean) * 100
)


error_summary
```

**Final conclusions**

Let's do a summary of the Netherlands models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_netherlands_real_short <- exp(test_netherlands_short)
predx_netherlands_auto <- exp(forecastx_netherlands_auto$mean)
predx_netherlands_222 <- exp(forecastx_netherlands_222$mean)


plot_netherlands_arimax <- data.frame(
  Year = seq_along(test_netherlands_real_short),
  Actual = test_netherlands_real_short,
  Predicted_auto= predx_netherlands_auto,
  Predicted_222 = predx_netherlands_222
)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
arimax_error_summary_netherlands <- data.frame(
  Model = c("ARIMA(1,0,3)", "ARIMA(2,2,2)"),
  ME = c(mean(test_netherlands_real_short - predx_netherlands_auto),
         mean(test_netherlands_real_short - predx_netherlands_222)),
  
  RMSE = c(rmse(test_netherlands_real_short, predx_netherlands_auto),
           rmse(test_netherlands_real_short, predx_netherlands_222)),
  
  MPE = c(mean((test_netherlands_real_short - predx_netherlands_auto) / test_netherlands_real_short) * 100,
          mean((test_netherlands_real_short - predx_netherlands_222) / test_netherlands_real_short) * 100),
  
  MAE = c(mae(test_netherlands_real_short, predx_netherlands_auto),
          mae(test_netherlands_real_short, predx_netherlands_222)),
  
  MAPE = c(mape(test_netherlands_real_short, predx_netherlands_auto) * 100,
           mape(test_netherlands_real_short, predx_netherlands_222) * 100)
)

arimax_error_summary_netherlands

```

Finally, we plot both approaches for the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

ggplot(plot_netherlands_arimax, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_auto, color = "Predicted_auto"), linetype = "dashed") +
  geom_line(aes(y = Predicted_222, color = "Predicted_222"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_auto" = "purple", "Predicted_222" = "red")) +
  labs(title = "Actual vs Predicted TB Deaths",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

### Bulgaria

Now, we study the Bulgarian time series. We begin, as in Spain, by studying the regressor variables.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_bulgaria_arimax_plot <- data.frame(
  Year = countries_short[["Bulgaria"]][["full"]]$year,
  number_deaths = countries_short[["Bulgaria"]][["full"]]$number_deaths,
  population = countries_short[["Bulgaria"]][["full"]]$population,
  gdp_capita = countries_short[["Bulgaria"]][["full"]]$gdp_capita
)


ggplot(df_bulgaria_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = number_deaths, color = "number_deaths")) +
  geom_line(aes(y = population/10000, color = "population")) +
  geom_line(aes(y = gdp_capita, color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Bulgaria",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()


ggplot(df_bulgaria_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Bulgaria",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Bulgaria"]][["train"]]
train_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["train"]][["number_deaths"]]), start = 1980, frequency = 1)

xreg_bulgaria_train <- data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["train"]][["population"]]), start = 1980, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["train"]][["gdp_capita"]]), start = 1980, frequency = 1)
)


fit_arimax_bulgaria <- auto.arima(train_bulgaria_short, xreg= as.matrix(xreg_bulgaria_train ))

summary(fit_arimax_bulgaria)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Bulgaria"]][["test"]]
test_bulgaria_short <- ts(log(countries_short[["Bulgaria"]][["test"]][["number_deaths"]]), start = 2014, frequency = 1)

xreg_bulgaria_test <- data.frame(
  population = ts(log(countries_short[["Bulgaria"]][["test"]][["population"]]), start = 2014, frequency = 1),
  gdp_capita = ts(log(countries_short[["Bulgaria"]][["test"]][["gdp_capita"]]), start = 2014, frequency = 1)
)

forecastx_bulgaria_100 <- forecast(fit_arimax_bulgaria, level = c(95), h = length(test_lengths_per_country_short[["Bulgaria"]]), xreg = as.matrix(xreg_bulgaria_test))

forecastx_bulgaria_100
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_bulgaria_100) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Bulgaria using ARIMAX(1,0,0)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_bulgaria_100) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Bulgaria using ARIMA(1,0,0)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_bulgaria_log_100 <- data.frame(
  Year = seq_along(test_bulgaria_short),
  Actual = test_bulgaria_short,
  Predicted_arimax = forecastx_bulgaria_100$mean
)


ggplot(plot_bulgaria_log_100, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,0,0)",
  ME = mean(test_bulgaria_short - forecastx_bulgaria_100$mean),
  RMSE = rmse(test_bulgaria_short ,forecastx_bulgaria_100$mean),
  MPE = mean((test_bulgaria_short - forecastx_bulgaria_100$mean) / test_bulgaria_short) * 100,
  MAE = mae(test_bulgaria_short, forecastx_bulgaria_100$mean),
  MAPE = mape(test_bulgaria_short ,forecastx_bulgaria_100$mean) * 100
)


error_summary
```

The ARIMAX($1,0,0$) model shows a modest overprediction bias (ME = –0.59) and a moderate overall error (RMSE = 0.65, MAE = 0.59) on the log scale. Its MPE of –13.32% and MAPE of 13.32% indicate that forecasts typically exceed actual values by about 13%, reflecting reasonable fit but still room for improvement.

As we see in the plot, the auto.arima function has not fully capture the structure of the series. Let's try to adjust manually another ARIMAX model. First, we need to check if the time series are stationary in the lof-transformed scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
adf.test(train_bulgaria_short)
```

The main series is not stationary. We difference this series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
train_bulgaria_short_diff <- train_bulgaria_short %>% diff()

acf(train_bulgaria_short_diff)
pacf(train_bulgaria_short_diff)
```

The ACF and PACF plots do not show any significant spikes after differencing once the series.

Next, we difference the log(populatioin) time series over the same short training period:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
population_bulgaria_diff <- ts(log(countries_short[["Bulgaria"]][["train"]][["population"]]), start = 1980, frequency = 1) %>% diff()

acf(population_bulgaria_diff)
pacf(population_bulgaria_diff)
```

The ACF plot shows a slow exponential decay over the first few lags. In contrast, the PACF shows two large spikes at lags 1 and 2, and then subsequent lags are essentially within the confidence bounds. This pattern is characteristic of an AR($2$) process.

Finally, we difference the log(gdp_capita) series:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
gdp_capita_bulgaria_diff <- ts(log(countries_short[["Bulgaria"]][["train"]][["gdp_capita"]]), start = 1980, frequency = 1) %>% diff()

acf(gdp_capita_bulgaria_diff)
pacf(gdp_capita_bulgaria_diff)
```

It is noticeable that both ACF and PACF show a single spike at lag 4. This pattern may suggest a high MA component for this series.

Putting all together, we propose the ARIMA($1,1,1$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arimax_bulgaria_111 <- Arima(train_bulgaria_short, order = c(1,1,1), xreg = as.matrix(xreg_bulgaria_train))
fit_arimax_bulgaria_111
```

The value of the AIC ($-50.02$) indicates a well-suited fit. Now, we need to check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_bulgaria_111 %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_bulgaria_111))
```

The model's residuals pass both normality and Ljung-Box tests. Now, we do the forecast.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
forecastx_bulgaria_111 <- forecast(fit_arimax_bulgaria_111, level = c(95), h = length(test_lengths_per_country_short[["Bulgaria"]]), xreg = as.matrix(xreg_bulgaria_test))

forecastx_bulgaria_111

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_bulgaria_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Bulgaria using ARIMAX(1,1,1)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_bulgaria_111) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Bulgaria using ARIMA(1,1,1)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_bulgaria_log_111 <- data.frame(
  Year = seq_along(test_bulgaria_short),
  Actual = test_bulgaria_short,
  Predicted_arimax = forecastx_bulgaria_111$mean
)


ggplot(plot_bulgaria_log_111, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,1,1)",
  ME = mean(test_bulgaria_short - forecastx_bulgaria_111$mean),
  RMSE = rmse(test_bulgaria_short ,forecastx_bulgaria_111$mean),
  MPE = mean((test_bulgaria_short - forecastx_bulgaria_111$mean) / test_bulgaria_short) * 100,
  MAE = mae(test_bulgaria_short, forecastx_bulgaria_111$mean),
  MAPE = mape(test_bulgaria_short ,forecastx_bulgaria_111$mean) * 100
)


error_summary
```

The ARIMAX($1,1,1$) model reduces bias (ME ≈ –0.38) and yields an RMSE of 0.44 on the log‐scale, corresponding to about 8.7% average percentage error (MAPE). These results suggest that including both AR(1) and MA(1) terms alongside population and GDP significantly improves fit over simpler specifications, though there remains a small tendency to overpredict.

**Final conclusions**

Let's do a summary of the Bulgarian models applied; we are going to change the scale into the original one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

test_bulgaria_real_short <- exp(test_bulgaria_short)
predx_bulgaria_auto <- exp(forecastx_bulgaria_100$mean)
predx_bulgaria_111 <- exp(forecastx_bulgaria_111$mean)


plot_bulgaria_arimax <- data.frame(
  Year = seq_along(test_bulgaria_real_short),
  Actual = test_bulgaria_real_short,
  Predicted_auto= predx_bulgaria_auto,
  Predicted_111 = predx_bulgaria_111
)

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
arimax_error_summary_bulgaria <- data.frame(
  Model = c("ARIMA(1,0,0)", "ARIMA(1,1,1)"),
  ME = c(mean(test_bulgaria_real_short - predx_bulgaria_auto),
         mean(test_bulgaria_real_short - predx_bulgaria_111)),
  
  RMSE = c(rmse(test_bulgaria_real_short, predx_bulgaria_auto),
           rmse(test_bulgaria_real_short, predx_bulgaria_111)),
  
  MPE = c(mean((test_bulgaria_real_short - predx_bulgaria_auto) / test_bulgaria_real_short) * 100,
          mean((test_bulgaria_real_short - predx_bulgaria_111) / test_bulgaria_real_short) * 100),
  
  MAE = c(mae(test_bulgaria_real_short, predx_bulgaria_auto),
          mae(test_bulgaria_real_short, predx_bulgaria_111)),
  
  MAPE = c(mape(test_bulgaria_real_short, predx_bulgaria_auto) * 100,
           mape(test_bulgaria_real_short, predx_bulgaria_111) * 100)
)

arimax_error_summary_bulgaria

```

Comparing the two ARIMA models on the orginal scale, ARIMA($1,1,1$) clearly outperforms ARIMA($1,0,0$). The ARIMA(1,1,1) model cuts RMSE nearly in half (43.88 vs. 76.28) and reduces MAE from 71.58 to 40.61. In percentage terms, its MAPE of 50.28% is substantially better than 87.34% for ARIMA(1,0,0). Both models slightly overpredict (negative ME/MPE), but ARIMA(1,1,1) exhibits much lower bias (ME = –40.61 vs. –71.58). In short, adding one difference and an MA(1) term yields a markedly more accurate fit.

Finally, we plot both approaches for the test set.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

ggplot(plot_bulgaria_arimax, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_auto, color = "Predicted_auto"), linetype = "dashed") +
  geom_line(aes(y = Predicted_111, color = "Predicted_111"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_auto" = "purple", "Predicted_111" = "red")) +
  labs(title = "Actual vs Predicted TB Deaths",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

### Estonia

Let's begin the study for Estonia data. Remember that Estonia is the country that has shorter time series.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
df_estonia_arimax_plot <- data.frame(
  Year = countries_short[["Estonia"]][["full"]]$year,
  number_deaths = countries_short[["Estonia"]][["full"]]$number_deaths,
  population = countries_short[["Estonia"]][["full"]]$population,
  gdp_capita = countries_short[["Estonia"]][["full"]]$gdp_capita
)


ggplot(df_estonia_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = number_deaths, color = "number_deaths")) +
  geom_line(aes(y = population/100, color = "population")) +
  geom_line(aes(y = gdp_capita, color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Estonia",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()


ggplot(df_estonia_arimax_plot, aes(x = Year)) +
  geom_line(aes(y = log(number_deaths), color = "number_deaths")) +
  geom_line(aes(y = log(population), color = "population")) +
  geom_line(aes(y = log(gdp_capita), color = "gdp_capita")) +
  scale_color_manual(values = c("number_deaths" = "#1f77b4", "population" = "purple", "gdp_capita" = "red")) +
  labs(title = "Estonia",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()

```

In this case, as the gdp_capita time series increases over time, both number of deaths and population seem to decay, specially the TB deaths series.

Let's fit the auto.arima() first:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Estonia"]][["train"]]
train_estonia_short <- ts(log(countries_short[["Estonia"]][["train"]][["number_deaths"]]), start = 1993, frequency = 1)

xreg_estonia_train <- data.frame(
  population = ts(log(countries_short[["Estonia"]][["train"]][["population"]]), start = 1993, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["train"]][["gdp_capita"]]), start = 1993, frequency = 1)
)


fit_arimax_estonia <- auto.arima(train_estonia_short, xreg= as.matrix(xreg_estonia_train ))

summary(fit_arimax_estonia)
```

The auto.arima has selected the ARIMA(1,0,0) as the model with the AIC coefficient minimized. Let's check the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arimax_estonia %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arimax_estonia))
```

The residuals of the ARIMAX model satisfy both normality and non autocorrelation hypothesis. Now, we begin the forecast:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
countries_short[["Estonia"]][["test"]]
test_estonia_short <- ts(log(countries_short[["Estonia"]][["test"]][["number_deaths"]]), start = 2017, frequency = 1)

xreg_estonia_test <- data.frame(
  population = ts(log(countries_short[["Estonia"]][["test"]][["population"]]), start = 2017, frequency = 1),
  gdp_capita = ts(log(countries_short[["Estonia"]][["test"]][["gdp_capita"]]), start = 2017, frequency = 1)
)

forecastx_estonia_100 <- forecast(fit_arimax_estonia, level = c(95), h = length(test_lengths_per_country_short[["Estonia"]]), xreg = as.matrix(xreg_estonia_test))

forecastx_estonia_100
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
autoplot(forecastx_estonia_100) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Estonia using ARIMAX(1,0,0)",
    subtitle = "95% confidence interval for forecasted values",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )


autoplot(forecastx_bulgaria_100) +
  theme_minimal() +
  labs(
    title = "Forecast of TB deaths in Bulgaria using ARIMA(1,0,0)",
    subtitle = "Zoomed-in from 2000 to 2021",
    x = "Year",
    y = "Log(Number of deaths)"
  ) +
  coord_cartesian(xlim = c(2000, 2021)) +
  theme(
    plot.title = element_text(face = "bold", size = 16),
    plot.subtitle = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )
```

Let's plot the predicted versus the actual logarithmic values:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_estonia_log_100 <- data.frame(
  Year = seq_along(test_estonia_short),
  Actual = test_estonia_short,
  Predicted_arimax = forecastx_estonia_100$mean
)


ggplot(plot_estonia_log_100, aes(x = Year)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predicted_arimax, color = "Predicted_arimax"), linetype = "dashed") +
  scale_color_manual(values = c("Actual" = "#1f77b4", "Predicted_arimax" = "#ff7f0e")) +
  labs(title = "Actual vs Predicted TB deaths (logarithmic scale)",
       x = "Year (Test Set)",
       y = "Number of Deaths",
       color = "Legend") +
  theme_minimal()
```

Finally, we can check the error measures in order to analyze the accuracy of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
error_summary <- data.frame(
  Model = "ARIMAX(1,0,0)",
  ME = mean(test_estonia_short - forecastx_estonia_100$mean),
  RMSE = rmse(test_estonia_short ,forecastx_estonia_100$mean),
  MPE = mean((test_estonia_short - forecastx_estonia_100$mean) / test_estonia_short) * 100,
  MAE = mae(test_estonia_short, forecastx_estonia_100$mean),
  MAPE = mape(test_estonia_short ,forecastx_estonia_100$mean) * 100
)


error_summary
```

Summary:

## Logarithmic regression

We have proved that ARIMA and ARIMAX models do not fit well the time series. The final option, is to apply a logarithmic regression. We will apply two different regressions: the simple regression log(number_deaths) \~ year, and a more complex one, log(number_deaths) \~ year + log(population) + log(gdp_capita).

### Spain

#### Simple regression

In this first regression, we will use the complete data, not the shorter one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_spain_df <- country_splits[["Spain"]][["train"]] 

lm_trend_simple_spain <- lm(train_spain ~ year, data = train_spain_df)
summary(lm_trend_simple_spain)

```

The linear regression of log(number_deaths) on year yields an intercept of 137.93 and a slope of –0.0658 (both highly significant, $p<2\mathrm{e}{-16}$), indicating a strong, steady annual decline in log‐deaths. The model explains 98.07% of the variance ($R^2=0.9807$), with residuals showing a low standard error (0.1626), confirming an excellent fit during 1960–2000.

Now, we need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

lm_trend_simple_spain %>% forecast::checkresiduals()

simple_spain_residuals <- ts(residuals(lm_trend_simple_spain), start = 1951, frequency = 1)

```

As we see in the plot, the model has not fully capture the structure of the series, meaning we will need to determine an ARIMA structure for the residuals. We begin by plotting the ACF and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(simple_spain_residuals)
pacf(simple_spain_residuals)

```

The ACF plot shows an exponential decaying trend, whereas the PACF shows a significant spike at lag 1. This pattern may suggest an AR($1$) component for the residuals.

Let's fit an ARMA($1,0$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arima_simple_spain_residuals <- Arima(simple_spain_residuals, order = c(1, 0, 0))
summary(fit_arima_simple_spain_residuals)
```

It seems a well-fitted model (AIC value of $-103.8$). Now, we check the residuals of the model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_simple_spain_residuals %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arima_simple_spain_residuals))
```

The residuals have checked the Ljung-Box text; however, they do not pass the normality test.

We begin the forecast phase. The forecast is divided into two steps: 1. The trend pronostic 2. The residuals pronostic

The final pronostic is given by the sum of the above ones.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_simple_spain_trend <- predict(
  lm_trend_simple_spain,
  newdata = data.frame(year = country_splits[["Spain"]][["test"]]$year)
)

predicted_simple_spain_residuals <- forecast(fit_arima_simple_spain_residuals, h = get_length("Spain", "test", "number_deaths"))

forecast_simple_spain_log <- predicted_simple_spain_trend + predicted_simple_spain_residuals$mean


forecast_simple_spain <- exp(forecast_simple_spain_log)
forecast_simple_spain
```

Finally, we plot the forecasted time series versus the real values, on the original scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

plot_simple_spain <- data.frame(
  Year     = country_splits[["Spain"]][["test"]]$year,
  Actual   = country_splits[["Spain"]][["test"]]$number_deaths,
  Forecast = forecast_simple_spain
)

ggplot(plot_simple_spain, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#ff7f0e")
  ) +
  labs(
    title    = "Actual vs. Predicted TB deaths",
    subtitle = "Model: log(number_deaths) ~ year + ARMA(1,0) in residuals",
    x        = "Year (Test Set)",
    y        = "Number of Deaths",
    color    = "Serie"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

It is clear that the model have given a more adjusted prediction that all the models tried before. Finally, we need to analyze the error measures.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
actual_spain <- country_splits[["Spain"]][["test"]]$number_deaths


error_summary_simple_spain <- data.frame(
  Model = "log(number_deaths) ~ year",
  ME = mean(actual_spain - forecast_simple_spain),
  RMSE = rmse(actual_spain, forecast_simple_spain),
  MPE = mean((actual_spain - forecast_simple_spain) / actual_spain) * 100,
  MAE = mae(actual_spain, forecast_simple_spain),
  MAPE = mape(actual_spain, forecast_simple_spain) * 100
)


error_summary_simple_spain
```

The trend‐plus‐AR(1) model on $\log(\text{number_deaths}) \sim \text{year}$ delivers a modest bias (ME = $–4.82$ deaths) and a low RMSE of $28.11$, corresponding to an average absolute error of $20.55$ deaths. Its MAPE of $7.93$% indicates that forecasts typically deviate by less than $8$%, a substantial improvement over earlier ARIMA‐only approaches. Overall, this specification captures the downward TB mortality trend very effectively.

#### Complete regression

Now, as we have the population and gdp per capita regressors, we will define a regression model with those variables. Note that in this approach, the shorter dataset will be used, in order to asses the discrepancies on variables' lengths.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
spain_short_train_df <- countries_short[["Spain"]][["train"]]
log_population_spain <- log(spain_short_train_df$population)
log_gdp_capita_spain <- log(spain_short_train_df$gdp_capita)

lm_trend_complete_spain <- lm(train_spain_short ~ year + log_population_spain + log_gdp_capita_spain, data = spain_short_train_df)

summary(lm_trend_complete_spain)
```

The multiple regression of $\log(\text{deaths})$ on year, $\log(\text{population})$, and $\log(\text{GDP per capita})$ explains 98.9% of the variance ($R^2 = 0.9889$) with a very small residual error (0.102). Holding population and GDP constant, the coefficient for year is $-0.0328$ ($p < 10^{-6}$), indicating a significant annual decline in log‐deaths. While $\log(\text{GDP per capita})$ also has a significant negative effect ($\beta = -0.2249,\;p = 0.0005$), $\log(\text{population})$ shows a marginally non‐significant negative association ($\beta = -1.5083,\;p = 0.0707$).

Now, we need to check the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
lm_trend_complete_spain %>% forecast::checkresiduals()

complete_spain_residuals <- residuals(lm_trend_complete_spain)

```

As the simple regression, the residuals for this more complex model do not satisfy any of the conditions, meaning that the regression still not capture all the interal structure.

We need to further study the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(complete_spain_residuals)
pacf(complete_spain_residuals)

```

The ACF plot shows a very large spike at lag 1 followed by a gradual decay over lags 2-7, where it begins to increase again. The PACF plot exhibits a single dominant spike at lag 1 with all higher-lag partial autocorrelations inside the confidence boundaries. This pattern may suggest, as the simple regression model, an AR($1$) process.

We fit this model on the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_spain_residuals <- Arima(complete_spain_residuals, order = c(1, 0, 0))
summary(fit_arima_complete_spain_residuals)

```

The low AIC value indicates a good fit. We check now the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_spain_residuals %>% forecast::checkresiduals()
shapiro.test(residuals(fit_arima_complete_spain_residuals))
```

Now the residuals satisfy the necessary hypothesis. We begin the pronostics.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_complete_spain_trend <- predict(
  lm_trend_complete_spain,
  newdata = data.frame(
    year = countries_short[["Spain"]][["test"]][["year"]],
    log_population_spain = log(countries_short[["Spain"]][["test"]][["population"]]),
    log_gdp_capita_spain = log(countries_short[["Spain"]][["test"]][["gdp_capita"]])
  )
)

predicted_complete_spain_log_residuals <- forecast(fit_arima_complete_spain_residuals, h = length(countries_short[["Spain"]][["test"]][["year"]]))

forecast_complete_spain_log <- predicted_complete_spain_trend + predicted_complete_spain_log_residuals$mean


forecast_complete_spain <- exp(forecast_complete_spain_log)
forecast_complete_spain
```

Finally, let's plot the new regression:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_complete_spain <- data.frame(
  Year     = countries_short[["Spain"]][["test"]][["year"]],
  Actual   = countries_short[["Spain"]][["test"]][["number_deaths"]],
  Forecast = forecast_complete_spain
)

plot_complete_spain

ggplot(plot_complete_spain, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#2ca02c")
  ) +
  labs(
    title    = "Actual vs. Forecast TB Deaths (Trend + Pop + GDP)",
    subtitle = "Model: log_deaths ~ year + log_population + log_gdp + ARMA(1,0)",
    x        = "Year (Test Set)",
    y        = "Number of Deaths",
    color    = "Series"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

error_summary_complete_spain <- data.frame(
  Model = "log(number_deaths) ~ year + log(population) + log(gdp_capita)",
  ME = mean(actual_spain - forecast_complete_spain),
  RMSE = rmse(actual_spain, forecast_complete_spain),
  MPE = mean((actual_spain - forecast_complete_spain) / actual_spain) * 100,
  MAE = mae(actual_spain, forecast_complete_spain),
  MAPE = mape(actual_spain, forecast_complete_spain) * 100
)

error_summary_complete_spain
```

### Bulgaria

#### Simple regression

In this first regression, we will use the complete data, not the shorter one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_bulgaria_df <- country_splits[["Bulgaria"]][["train"]] 
country_splits[["Bulgaria"]][["train"]] 

lm_trend_simple_bulgaria <- lm(train_bulgaria ~ year, data = train_bulgaria_df)
summary(lm_trend_simple_bulgaria)

```

The linear regression of log(number_deaths) on year yields an intercept of 71.57 and a slope of –0.033 (both highly significant, $p<2\mathrm{e}{-16}$), indicating a strong, steady annual decline in log‐deaths. The model explains 98.07% of the variance ($R^2=0.9807$), with residuals showing a low standard error (0.1626), confirming an excellent fit during 1960–2000.

Now, we need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

lm_trend_simple_bulgaria %>% forecast::checkresiduals()

simple_bulgaria_residuals <- ts(residuals(lm_trend_simple_bulgaria), start = 1980, frequency = 1)

```

As we see in the plot, the model has not fully capture the structure of the series, meaning we will need to determine an ARIMA structure for the residuals. We begin by plotting the ACF and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(simple_bulgaria_residuals)
pacf(simple_bulgaria_residuals)

```

The ACF plot shows an exponential decaying trend, whereas the PACF shows a significant spike at lag 1. This pattern may suggest an AR($1$) component for the residuals.

Let's fit an ARMA($1,0$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arima_simple_bulgaria_residuals <- Arima(simple_bulgaria_residuals, order = c(1, 0, 0))
summary(fit_arima_simple_bulgaria_residuals)
```

It seems a well-fitted model (AIC value of $-77.76$). Now, we check the residuals of the model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_simple_bulgaria_residuals %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arima_simple_bulgaria_residuals))
```

The residuals have checked the Ljung-Box text; however, they do not pass the normality test.

We begin the forecast phase. The forecast is divided into two steps: 1. The trend pronostic 2. The residuals pronostic

The final pronostic is given by the sum of the above ones.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_simple_bulgaria_trend <- predict(
  lm_trend_simple_bulgaria,
  newdata = data.frame(year = country_splits[["Bulgaria"]][["test"]]$year)
)

predicted_simple_bulgaria_residuals <- forecast(fit_arima_simple_bulgaria_residuals, h = get_length("Bulgaria", "test", "number_deaths"))

forecast_simple_bulgaria_log <- predicted_simple_bulgaria_trend + predicted_simple_bulgaria_residuals$mean


forecast_simple_bulgaria <- exp(forecast_simple_bulgaria_log)
forecast_simple_bulgaria
```

Finally, we plot the forecasted time series versus the real values, on the original scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

plot_simple_bulgaria <- data.frame(
  Year     = country_splits[["Bulgaria"]][["test"]]$year,
  Actual   = country_splits[["Bulgaria"]][["test"]]$number_deaths,
  Forecast = forecast_simple_bulgaria
)

ggplot(plot_simple_bulgaria, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#ff7f0e")
  ) +
  labs(
    title    = "Actual vs. Predicted TB deaths",
    subtitle = "Model: log(number_deaths) ~ year + ARMA(1,0) in residuals",
    x        = "Year (Test Set: 2001–2010)",
    y        = "Number of Deaths",
    color    = "Serie"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
actual_bulgaria <- country_splits[["Bulgaria"]][["test"]]$number_deaths


error_summary_simple_bulgaria <- data.frame(
  Model = "log(number_deaths) ~ year",
  ME = mean(actual_bulgaria - forecast_simple_bulgaria),
  RMSE = rmse(actual_bulgaria, forecast_simple_bulgaria),
  MPE = mean((actual_bulgaria - forecast_simple_bulgaria) / actual_bulgaria) * 100,
  MAE = mae(actual_bulgaria, forecast_simple_bulgaria),
  MAPE = mape(actual_bulgaria, forecast_simple_bulgaria) * 100
)


error_summary_simple_bulgaria
```

The trend‐only regression (log deaths \~ year) achieves ME = –37.21, RMSE = 42.85, and MAPE ≈ 44.97%, slightly outperforming ARIMA(1,1,1) on RMSE (43.88 vs. 42.85) and MAPE (50.28% vs. 44.97%). Although both models overpredict modestly, the simple linear trend captures most of the series’ dynamics with comparable or better average error than the more complex ARIMA.

#### Complete regression

Now, as we have the population and gdp per capita regressors, we will define a regression model with those variables. Note that in this approach, the shorter dataset will be used, in order to asses the discrepancies on variables' lengths.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
bulgaria_short_train_df <- countries_short[["Bulgaria"]][["train"]]
log_population_bulgaria <- log(bulgaria_short_train_df$population)
log_gdp_capita_bulgaria <- log(bulgaria_short_train_df$gdp_capita)

lm_trend_complete_bulgaria <- lm(train_bulgaria_short ~ year + log_population_bulgaria + log_gdp_capita_bulgaria, data = bulgaria_short_train_df)

summary(lm_trend_complete_bulgaria)
```

The multiple regression of $\log(\text{deaths})$ on year, $\log(\text{population})$, and $\log(\text{GDP per capita})$ explains 64.03% of the variance ($R^2 = 0.6403$) with a very small residual error (0.1431). Holding population and GDP constant, the coefficient for year is $-0.04583$, indicating a significant annual decline in log‐deaths.

Now, we need to check the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
lm_trend_complete_bulgaria %>% forecast::checkresiduals()

complete_bulgaria_residuals <- residuals(lm_trend_complete_bulgaria)

```

In contrast with the simple regression, the residuals of the regression do not capture all the temporal structure. We need to further study the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(complete_bulgaria_residuals)
pacf(complete_bulgaria_residuals)

```

The ACF plot shows a spike at lag 1 followed by a gradual decay over lags 2-5, where it begins to increase again and has significant spikes at lags 4-5. The PACF plot exhibits a single dominant spike at lag 1 with all higher-lag partial autocorrelations inside the confidence boundaries. This pattern may suggest a more complex model for the residuals. We will study the ARMA(1,1).

We fit this model on the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_bulgaria_residuals <- Arima(complete_bulgaria_residuals, order = c(1, 0, 0))
summary(fit_arima_complete_bulgaria_residuals)

```

The low AIC value indicates a good fit. We check now the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_bulgaria_residuals %>% forecast::checkresiduals()
shapiro.test(residuals(fit_arima_complete_bulgaria_residuals))
```

Now the residuals satisfy the necessary hypothesis. We begin the pronostics.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_complete_bulgaria_trend <- predict(
  lm_trend_complete_bulgaria,
  newdata = data.frame(
    year = countries_short[["Bulgaria"]][["test"]][["year"]],
    log_population_bulgaria = log(countries_short[["Bulgaria"]][["test"]][["population"]]),
    log_gdp_capita_bulgaria = log(countries_short[["Bulgaria"]][["test"]][["gdp_capita"]])
  )
)

predicted_complete_bulgaria_log_residuals <- forecast(fit_arima_complete_bulgaria_residuals, h = length(countries_short[["Bulgaria"]][["test"]][["year"]]))

forecast_complete_bulgaria_log <- predicted_complete_bulgaria_trend + predicted_complete_bulgaria_log_residuals$mean


forecast_complete_bulgaria <- exp(forecast_complete_bulgaria_log)
forecast_complete_bulgaria
```

Finally, let's plot the new regression:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_complete_bulgaria <- data.frame(
  Year     = countries_short[["Bulgaria"]][["test"]][["year"]],
  Actual   = countries_short[["Bulgaria"]][["test"]][["number_deaths"]],
  Forecast = forecast_complete_bulgaria
)

plot_complete_bulgaria

ggplot(plot_complete_bulgaria, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#2ca02c")
  ) +
  labs(
    title    = "Actual vs. Forecast TB Deaths (Trend + Pop + GDP)",
    subtitle = "Model: log_deaths ~ year + log_population + log_gdp + ARMA(1,4)",
    x        = "Year (Test Set)",
    y        = "Number of Deaths",
    color    = "Series"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

actual_bulgaria <- countries_short[["Bulgaria"]][["test"]][["number_deaths"]]

error_summary_complete_bulgaria <- data.frame(
  Model = "log(number_deaths) ~ year + log(population) + log(gdp_capita)",
  ME = mean(actual_bulgaria - forecast_complete_bulgaria),
  RMSE = rmse(actual_bulgaria, forecast_complete_bulgaria),
  MPE = mean((actual_bulgaria - forecast_complete_bulgaria) / actual_bulgaria) * 100,
  MAE = mae(actual_bulgaria, forecast_complete_bulgaria),
  MAPE = mape(actual_bulgaria, forecast_complete_bulgaria) * 100
)

error_summary_complete_bulgaria
```

### The Netherlands

#### Simple regression

In this first regression, we will use the complete data, not the shorter one.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

train_netherlands_df <- country_splits[["Netherlands"]][["train"]] 
country_splits[["Netherlands"]][["train"]] 

lm_trend_simple_netherlands <- lm(train_netherlands ~ year, data = train_netherlands_df)
summary(lm_trend_simple_netherlands)

```

The linear regression of log(number_deaths) on year yields an intercept of 85.84 and a slope of –0.04 (both highly significant, $p<2\mathrm{e}{-16}$), indicating a strong, steady annual decline in log‐deaths. The model explains 79.92% of the variance ($R^2=0.7992$), with residuals showing a moderate standard error (0.3616).

Now, we need to further study the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

lm_trend_simple_netherlands %>% forecast::checkresiduals()

simple_netherlands_residuals <- ts(residuals(lm_trend_simple_netherlands), start = 1950, frequency = 1)

```

As we see in the plot, the model has not fully capture the structure of the series, meaning we will need to determine an ARIMA structure for the residuals. We begin by plotting the ACF and PACF.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
acf(simple_netherlands_residuals )
pacf(simple_netherlands_residuals )

```

The ACF plot shows an exponential decaying trend, whereas the PACF shows a significant spike at lag 1. This pattern may suggest an AR($1$) component for the residuals.

Let's fit an ARMA($1,0$).

```{r, warning=FALSE, message=FALSE, echo = FALSE}

fit_arima_simple_netherlands_residuals <- Arima(simple_netherlands_residuals, order = c(1,0,0))
summary(fit_arima_simple_netherlands_residuals)
```

It seems a well-fitted model (AIC value of $-43.4$). Now, we check the residuals of the model:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_simple_netherlands_residuals %>% forecast::checkresiduals()

shapiro.test(residuals(fit_arima_simple_netherlands_residuals))
```

The residuals have checked the Ljung-Box text; however, they do not pass the normality test.

We begin the forecast phase. The forecast is divided into two steps: 1. The trend pronostic 2. The residuals pronostic

The final pronostic is given by the sum of the above ones.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_simple_netherlands_trend <- predict(
  lm_trend_simple_netherlands,
  newdata = data.frame(year = country_splits[["Netherlands"]][["test"]]$year)
)

predicted_simple_netherlands_residuals <- forecast(fit_arima_simple_netherlands_residuals, h = get_length("Netherlands", "test", "number_deaths"))

forecast_simple_netherlands_log <- predicted_simple_netherlands_trend + predicted_simple_netherlands_residuals$mean


forecast_simple_netherlands <- exp(forecast_simple_netherlands_log)
forecast_simple_netherlands
```

Finally, we plot the forecasted time series versus the real values, on the original scale.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

plot_simple_netherlands <- data.frame(
  Year     = country_splits[["Netherlands"]][["test"]]$year,
  Actual   = country_splits[["Netherlands"]][["test"]]$number_deaths,
  Forecast = forecast_simple_netherlands

)

ggplot(plot_simple_netherlands, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#ff7f0e")
  ) +
  labs(
    title    = "Actual vs. Predicted TB deaths",
    subtitle = "Model: log(number_deaths) ~ year + ARMA(1,0) in residuals",
    x        = "Year (Test Set: 2001–2010)",
    y        = "Number of Deaths",
    color    = "Serie"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
actual_netherlands <- country_splits[["Netherlands"]][["test"]]$number_deaths


error_summary_simple_netherlands <- data.frame(
  Model = "log(number_deaths) ~ year",
  ME = mean(actual_netherlands - forecast_simple_netherlands),
  RMSE = rmse(actual_netherlands, forecast_simple_netherlands),
  MPE = mean((actual_netherlands - forecast_simple_netherlands) / actual_netherlands) * 100,
  MAE = mae(actual_netherlands, forecast_simple_netherlands),
  MAPE = mape(actual_netherlands, forecast_simple_netherlands) * 100
)


error_summary_simple_netherlands
```

#### Complete regression

Now, as we have the population and gdp per capita regressors, we will define a regression model with those variables. Note that in this approach, the shorter dataset will be used, in order to asses the discrepancies on variables' lengths.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
netherlands_short_train_df <- countries_short[["Netherlands"]][["train"]]

log_population_netherlands <- log(netherlands_short_train_df$population)
log_gdp_capita_netherlands <- log(netherlands_short_train_df$gdp_capita)

lm_trend_complete_netherlands <- lm(train_netherlands_short ~ year + log_population_netherlands + log_gdp_capita_netherlands, data = netherlands_short_train_df)

summary(lm_trend_complete_netherlands)
```

The multiple regression of $\log(\text{deaths})$ on year, $\log(\text{population})$, and $\log(\text{GDP per capita})$ explains 81.68% of the variance ($R^2 = 0.8168$) with a very small residual error (0.1941). Holding population and GDP constant, the coefficient for year is $-0.0369$, indicating a significant annual decline in log‐deaths.

Now, we need to check the residuals of the model.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
lm_trend_complete_netherlands %>% forecast::checkresiduals()

complete_netherlands_residuals <- residuals(lm_trend_complete_netherlands)

```

In contrast with the simple regression, the residuals of the regression do not capture all the temporal structure. We need to further study the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

acf(complete_netherlands_residuals)
pacf(complete_netherlands_residuals)


acf(complete_netherlands_residuals %>% diff())
pacf(complete_netherlands_residuals %>% diff())
```

The ACF plot shows a spike at lag 1 followed by a gradual decay. The PACF plot exhibits a single dominant spike at lag 1 with all higher-lag partial autocorrelations inside the confidence boundaries. This pattern may suggest a more complex model for the residuals. We will study the ARMA(1,3).

We fit this model on the residuals.

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_netherlands_residuals <- Arima(complete_netherlands_residuals, order = c(2, 1, 2))
summary(fit_arima_complete_netherlands_residuals)

```

The low AIC value indicates a good fit. We check now the residuals:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
fit_arima_complete_netherlands_residuals %>% forecast::checkresiduals()
shapiro.test(residuals(fit_arima_complete_netherlands_residuals))
```

Now the residuals satisfy the necessary hypothesis. We begin the pronostics.

```{r, warning=FALSE, message=FALSE, echo = FALSE}

predicted_complete_netherlands_trend <- predict(
  lm_trend_complete_netherlands,
  newdata = data.frame(
    year = countries_short[["Netherlands"]][["test"]][["year"]],
    log_population_netherlands = log(countries_short[["Netherlands"]][["test"]][["population"]]),
    log_gdp_capita_netherlands = log(countries_short[["Netherlands"]][["test"]][["gdp_capita"]])
  )
)

predicted_complete_netherlands_log_residuals <- forecast(fit_arima_complete_netherlands_residuals, h = length(countries_short[["Netherlands"]][["test"]][["year"]]))

forecast_complete_netherlands_log <- predicted_complete_netherlands_trend + predicted_complete_netherlands_log_residuals$mean


forecast_complete_netherlands <- exp(forecast_complete_netherlands_log)
forecast_complete_netherlands
```

Finally, let's plot the new regression:

```{r, warning=FALSE, message=FALSE, echo = FALSE}
plot_complete_netherlands <- data.frame(
  Year     = countries_short[["Netherlands"]][["test"]][["year"]],
  Actual   = countries_short[["Netherlands"]][["test"]][["number_deaths"]],
  Forecast = forecast_complete_netherlands
)

ggplot(plot_complete_netherlands, aes(x = Year)) +
  geom_line(aes(y = Actual,   color = "Actual")) +
  geom_line(aes(y = Forecast, color = "Forecast"), linetype = "dashed") +
  scale_color_manual(
    values = c("Actual" = "#1f77b4", "Forecast" = "#2ca02c")
  ) +
  labs(
    title    = "Actual vs. Forecast TB Deaths (Trend + Pop + GDP)",
    subtitle = "Model: log_deaths ~ year + log_population + log_gdp + ARIMA(2,1,2)",
    x        = "Year (Test Set)",
    y        = "Number of Deaths",
    color    = "Series"
  ) +
  theme_minimal() +
  theme(
    plot.title        = element_text(face = "bold", size = 16),
    plot.subtitle     = element_text(size = 13),
    axis.text         = element_text(size = 11),
    axis.title        = element_text(size = 12),
    legend.position   = "right"
  )

```

```{r, warning=FALSE, message=FALSE, echo = FALSE}

actual_netherlands <- countries_short[["Netherlands"]][["test"]][["number_deaths"]]

error_summary_complete_netherlands <- data.frame(
  Model = "log(number_deaths) ~ year + log(population) + log(gdp_capita)",
  ME = mean(actual_netherlands - forecast_complete_netherlands),
  RMSE = rmse(actual_netherlands, forecast_complete_netherlands),
  MPE = mean((actual_netherlands - forecast_complete_netherlands) / actual_netherlands) * 100,
  MAE = mae(actual_netherlands, forecast_complete_netherlands),
  MAPE = mape(actual_netherlands, forecast_complete_netherlands) * 100
)

error_summary_complete_netherlands
```
